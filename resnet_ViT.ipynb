{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/resnet_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2kQGpnynh2oQ"
      },
      "outputs": [],
      "source": [
        "# @title download\n",
        "# original 10k\n",
        "# # https://drive.google.com/file/d/1NkCNecLpFG3i7bo3Vl9RQSwzBpSRQ29q/view?usp=sharing\n",
        "# !gdown 1NkCNecLpFG3i7bo3Vl9RQSwzBpSRQ29q -O gsv.zip\n",
        "# !unzip /content/gsv.zip -d /content\n",
        "# import shutil\n",
        "# shutil.rmtree('/content/google_street_view/meta_data', ignore_errors=True) # delete the meta_data folder\n",
        "\n",
        "# # clip cleaned\n",
        "# # https://drive.google.com/file/d/1-xcHyVAMeTkY7SUdUyQRVAn_FFXPSDGB/view?usp=share_link\n",
        "# !gdown 1-xcHyVAMeTkY7SUdUyQRVAn_FFXPSDGB -O gsv.zip\n",
        "# !unzip /content/gsv.zip -d /\n",
        "# !rm -R /content/gsv/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/01/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/02/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/03/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/04/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/05/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/06/.ipynb_checkpoints\n",
        "\n",
        "# # gsv 70k\n",
        "# # https://drive.google.com/file/d/1-7ZC29k4VxXQkpnOuLfj7Ag_SFTM4LV8/view?usp=share_link\n",
        "# !gdown 1-7ZC29k4VxXQkpnOuLfj7Ag_SFTM4LV8 -O gsv.zip\n",
        "# !unzip /content/gsv.zip -d /\n",
        "\n",
        "# # # !ls\n",
        "# !ls -a /content/gsv70k\n",
        "# !rm -R /content/gsv70k/.ipynb_checkpoints\n",
        "# # # !rm -R /content/gsv/06/.ipynb_checkpoints\n",
        "\n",
        "# # 70k+gmap\n",
        "# # https://drive.google.com/file/d/1-CZp7TbhJLeRQpbKQCyT8ofGg89Yt137/view?usp=sharing\n",
        "!gdown 1-CZp7TbhJLeRQpbKQCyT8ofGg89Yt137 -O gsv.zip\n",
        "!unzip /content/gsv.zip -d /\n",
        "!rm -R /content/gsv70kg/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/01/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/02/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/03/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/04/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/05/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/06/.ipynb_checkpoints\n",
        "\n",
        "# # https://bestasoff.medium.com/how-to-fine-tune-very-large-model-if-it-doesnt-fit-on-your-gpu-3561e50859af\n",
        "!pip install bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hEUffQ24mkRY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title torch augment\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        # self.transform = transforms.RandomApply([transforms.Compose([\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                transforms.RandomResizedCrop((400,640), scale=(0.7, 1.0), ratio=(0.8, 1.25), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(p=0.5), # 0.5\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,), # brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8\n",
        "                transforms.RandomGrayscale(p=0.2), # 0.2\n",
        "                # transforms.RandomChoice(transforms.ColorJitter , transforms.RandomGrayscale(p=1.)\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.5)\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "                transforms.RandomErasing(p=1., scale=(0.1, 0.11), ratio=(1,1), value=0., inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "                # transforms.ToTensor(), # ToTensored at dataset level, no need to ToTensor again\n",
        "                # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalised at dataset level. default 0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225\n",
        "                ])\n",
        "            # ], p=1.)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "        x1 = self.transform(sample)\n",
        "        return x1\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(nan)\n",
        "from torch.utils.checkpoint import checkpoint, checkpoint_sequential\n",
        "\n",
        "trs=TrainTransform() # for image augmentation during train time\n",
        "# train function with automatic mixed precision\n",
        "# def strain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "size = len(train_loader.dataset)\n",
        "model.train()\n",
        "loss_list = []\n",
        "c=0\n",
        "for batch, (x, y) in enumerate(train_loader):\n",
        "    print(\"##############\", batch)\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "        print(\"1: \",x)\n",
        "        x = trs(x) # image augmentation during train time to use gpu\n",
        "        print(\"2: \",x)\n",
        "        # pred = model(x) # default\n",
        "        modules = [module for k, module in model._modules.items()]\n",
        "        pred = checkpoint_sequential(functions=modules, segments=1, input=x) # gradient checkpointing for resnet and inception only\n",
        "        # # pred = checkpoint_sequential(functions=model.mods, segments=1, input=x)\n",
        "        print(\"train\",pred[0])\n",
        "\n",
        "        print((pred.argmax(1)==y).sum().item(), pred.argmax(1).tolist(), y.tolist())\n",
        "        loss = loss_fn(pred, y)\n",
        "    scaler.scale(loss).backward()\n",
        "    if ((batch + 1) % 4 == 0) or (batch + 1 == len(train_loader)): # gradient accumulation\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        # if scheduler is not None:\n",
        "        #     scheduler.step()\n",
        "        #     print(\"### lr: \", optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "    print(model.state_dict()['_orig_mod.bn1.running_mean'][0])\n",
        "\n",
        "    c+=1\n",
        "    if c>3: break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ4y6Qdo7KWa",
        "outputId": "aaad5e53-bd18-4f00-90d5-7ecdb88b2f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############## 0\n",
            "1:  tensor([[[[-0.3712, -0.3541, -0.3541,  ...,  0.3994,  0.3994,  0.3994],\n",
            "          [-0.3198, -0.3198, -0.3198,  ...,  0.3994,  0.3994,  0.3994],\n",
            "          [-0.2856, -0.2856, -0.2856,  ...,  0.3994,  0.3994,  0.3994],\n",
            "          ...,\n",
            "          [ 1.4098,  1.3413,  1.3584,  ..., -1.0904, -1.2788, -1.2103],\n",
            "          [ 1.3755,  1.4098,  1.4098,  ..., -1.5528, -1.3987, -1.4672],\n",
            "          [ 1.4098,  1.5297,  1.5810,  ..., -1.3130, -1.3815, -1.3644]],\n",
            "\n",
            "         [[ 0.5728,  0.5903,  0.5903,  ...,  1.2381,  1.2381,  1.2381],\n",
            "          [ 0.6254,  0.6254,  0.6254,  ...,  1.2381,  1.2381,  1.2381],\n",
            "          [ 0.6604,  0.6604,  0.6604,  ...,  1.2381,  1.2381,  1.2381],\n",
            "          ...,\n",
            "          [ 1.2731,  1.2031,  1.2031,  ..., -1.0028, -1.1954, -1.1253],\n",
            "          [ 1.2381,  1.2556,  1.2556,  ..., -1.4755, -1.3179, -1.3880],\n",
            "          [ 1.2731,  1.3782,  1.3782,  ..., -1.2304, -1.3004, -1.2829]],\n",
            "\n",
            "         [[ 2.0125,  2.0300,  2.0300,  ...,  2.3437,  2.3437,  2.3437],\n",
            "          [ 2.0648,  2.0648,  2.0648,  ...,  2.3437,  2.3437,  2.3437],\n",
            "          [ 2.0997,  2.0997,  2.0997,  ...,  2.3437,  2.3437,  2.3437],\n",
            "          ...,\n",
            "          [ 1.1411,  1.0714,  1.0365,  ..., -0.8458, -1.0376, -0.9678],\n",
            "          [ 1.1411,  1.1237,  1.0888,  ..., -1.3164, -1.1596, -1.2293],\n",
            "          [ 1.1759,  1.2457,  1.2282,  ..., -1.0898, -1.1596, -1.1421]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2899, -0.2856, -1.6384,  ...,  1.7009,  1.6838,  1.6667],\n",
            "          [ 0.7933, -0.5767, -1.5014,  ...,  1.7180,  1.7180,  1.7009],\n",
            "          [ 1.6324,  0.0569, -1.2788,  ...,  1.7523,  1.7523,  1.7523],\n",
            "          ...,\n",
            "          [ 0.3652,  0.4508,  0.4337,  ..., -1.0904, -1.3130, -1.2445],\n",
            "          [ 0.0056,  0.0912,  0.2796,  ..., -1.3473, -1.2617, -1.3815],\n",
            "          [-0.4397, -0.0629,  0.6221,  ..., -1.4500, -1.3987, -1.1589]],\n",
            "\n",
            "         [[ 1.7283,  0.1176, -1.3179,  ...,  1.9209,  1.9034,  1.8859],\n",
            "          [ 1.2206, -0.1800, -1.1779,  ...,  1.9384,  1.9384,  1.9209],\n",
            "          [ 2.0959,  0.4678, -0.9503,  ...,  1.9734,  1.9734,  1.9734],\n",
            "          ...,\n",
            "          [ 0.4153,  0.5028,  0.5203,  ..., -0.8978, -1.1253, -1.0553],\n",
            "          [ 0.0476,  0.1352,  0.3102,  ..., -1.1604, -1.0728, -1.1954],\n",
            "          [-0.4076, -0.0224,  0.6604,  ..., -1.2654, -1.2129, -0.9678]],\n",
            "\n",
            "         [[ 1.7511,  0.1651, -1.2119,  ...,  2.2566,  2.2391,  2.2217],\n",
            "          [ 1.2108, -0.1487, -1.1073,  ...,  2.2740,  2.2740,  2.2566],\n",
            "          [ 2.0300,  0.4614, -0.8981,  ...,  2.3088,  2.3088,  2.3088],\n",
            "          ...,\n",
            "          [ 0.3045,  0.3916,  0.4439,  ..., -0.6018, -0.8284, -0.7587],\n",
            "          [-0.0615,  0.0256,  0.2522,  ..., -0.8284, -0.7413, -0.8633],\n",
            "          [-0.5147, -0.1312,  0.6008,  ..., -0.9330, -0.8807, -0.6367]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9303,  0.9988,  1.0331,  ...,  1.2385,  1.3242,  1.4440],\n",
            "          [ 0.9474,  0.9988,  1.0844,  ...,  1.2728,  1.3242,  1.4269],\n",
            "          [ 1.1872,  1.0844,  0.9646,  ...,  1.3413,  1.3413,  1.3755],\n",
            "          ...,\n",
            "          [ 0.4508,  0.4679,  0.4679,  ...,  1.3070,  1.2728,  1.2728],\n",
            "          [ 0.2796,  0.5193,  0.7419,  ...,  1.2728,  1.2557,  1.2728],\n",
            "          [ 0.4679,  0.4679,  0.4851,  ...,  1.1872,  1.2043,  1.2214]],\n",
            "\n",
            "         [[ 1.3957,  1.4657,  1.5007,  ...,  1.7633,  1.8683,  1.9909],\n",
            "          [ 1.4132,  1.4657,  1.5532,  ...,  1.7983,  1.8683,  1.9384],\n",
            "          [ 1.6232,  1.5182,  1.3957,  ...,  1.8859,  1.8508,  1.9034],\n",
            "          ...,\n",
            "          [ 0.5028,  0.5203,  0.5203,  ...,  1.4307,  1.3957,  1.3957],\n",
            "          [ 0.3277,  0.5728,  0.8004,  ...,  1.3957,  1.3782,  1.3957],\n",
            "          [ 0.5203,  0.5203,  0.5378,  ...,  1.3081,  1.3256,  1.3431]],\n",
            "\n",
            "         [[ 1.8208,  1.8905,  1.9254,  ...,  2.4483,  2.5006,  2.6051],\n",
            "          [ 1.8383,  1.8905,  1.9777,  ...,  2.4831,  2.4831,  2.5703],\n",
            "          [ 2.0648,  1.9603,  1.8383,  ...,  2.5180,  2.4831,  2.4831],\n",
            "          ...,\n",
            "          [ 0.6182,  0.6356,  0.6356,  ...,  1.4374,  1.4025,  1.4025],\n",
            "          [ 0.4439,  0.6879,  0.9145,  ...,  1.4025,  1.3851,  1.4025],\n",
            "          [ 0.6356,  0.6356,  0.6531,  ...,  1.3154,  1.3328,  1.3502]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0673,  1.0673,  1.0673,  ...,  1.1529,  1.1529,  1.1529],\n",
            "          [ 1.0673,  1.0673,  1.0673,  ...,  1.1358,  1.1358,  1.1529],\n",
            "          [ 1.0673,  1.0673,  1.0673,  ...,  1.1358,  1.1358,  1.1358],\n",
            "          ...,\n",
            "          [ 0.6221,  0.5022,  0.2624,  ..., -0.9705, -1.0219, -0.9534],\n",
            "          [-0.0287,  0.2111,  0.4166,  ..., -0.8849, -0.9192, -1.4158],\n",
            "          [ 1.1700,  1.3070,  1.1700,  ..., -1.2274, -1.0048, -0.8335]],\n",
            "\n",
            "         [[ 1.3431,  1.3431,  1.3431,  ...,  1.4482,  1.4482,  1.4482],\n",
            "          [ 1.3431,  1.3431,  1.3431,  ...,  1.4307,  1.4307,  1.4482],\n",
            "          [ 1.3431,  1.3431,  1.3431,  ...,  1.4307,  1.4307,  1.4307],\n",
            "          ...,\n",
            "          [ 0.6954,  0.5728,  0.3277,  ..., -0.8627, -0.9153, -0.8452],\n",
            "          [ 0.0301,  0.2752,  0.4853,  ..., -0.7752, -0.8102, -1.3179],\n",
            "          [ 1.2381,  1.3782,  1.2381,  ..., -1.1253, -0.8978, -0.7227]],\n",
            "\n",
            "         [[ 1.6988,  1.6988,  1.6640,  ...,  1.7163,  1.7163,  1.7163],\n",
            "          [ 1.6988,  1.6640,  1.6640,  ...,  1.6988,  1.6988,  1.7163],\n",
            "          [ 1.6640,  1.6640,  1.6640,  ...,  1.6988,  1.6988,  1.6988],\n",
            "          ...,\n",
            "          [ 0.4091,  0.2871,  0.0431,  ..., -0.6715, -0.7238, -0.6541],\n",
            "          [-0.1835,  0.0605,  0.2696,  ..., -0.5844, -0.6193, -1.1247],\n",
            "          [ 1.0714,  1.2108,  1.0714,  ..., -0.9330, -0.7064, -0.5321]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8379,  1.7865,  1.7694,  ..., -0.9020, -0.8335, -1.2617],\n",
            "          [ 1.8893,  1.8379,  1.7865,  ..., -1.2445, -0.8164, -0.3541],\n",
            "          [ 1.9749,  1.9064,  1.8379,  ..., -1.1247, -1.1418, -0.7479],\n",
            "          ...,\n",
            "          [-1.3987, -1.4158, -1.3987,  ..., -1.5528, -2.1179, -1.8610],\n",
            "          [-1.3815, -1.3987, -1.3987,  ..., -1.6213, -1.8953, -1.9124],\n",
            "          [-1.3815, -1.3987, -1.3987,  ..., -1.7925, -1.7583, -2.0494]],\n",
            "\n",
            "         [[ 2.1485,  2.0959,  2.0784,  ..., -0.6527, -0.6001, -1.0378],\n",
            "          [ 2.2010,  2.1485,  2.0959,  ..., -1.0028, -0.6001, -0.1099],\n",
            "          [ 2.2885,  2.2185,  2.1485,  ..., -0.8803, -0.8803, -0.4776],\n",
            "          ...,\n",
            "          [-0.9853, -1.0028, -0.9853,  ..., -1.4230, -2.0007, -1.7381],\n",
            "          [-0.9678, -0.9853, -0.9853,  ..., -1.4930, -1.7731, -1.7906],\n",
            "          [-0.9678, -0.9853, -0.9853,  ..., -1.6681, -1.6331, -1.9307]],\n",
            "\n",
            "         [[ 2.3960,  2.3437,  2.3263,  ..., -0.8458, -0.9156, -1.3861],\n",
            "          [ 2.4483,  2.3960,  2.3437,  ..., -1.1944, -0.8633, -0.4624],\n",
            "          [ 2.5354,  2.4657,  2.3960,  ..., -1.0724, -1.1596, -0.7936],\n",
            "          ...,\n",
            "          [-1.0027, -1.0201, -1.0027,  ..., -1.3861, -1.8044, -1.6999],\n",
            "          [-0.9853, -1.0027, -1.0027,  ..., -1.4559, -1.7347, -1.7522],\n",
            "          [-0.9853, -1.0027, -1.0027,  ..., -1.6302, -1.5953, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-0.9192, -1.3130, -1.3473,  ...,  2.2318,  0.3309, -0.9020],\n",
            "          [-0.8507, -1.0390, -1.2959,  ...,  2.1462,  0.2796, -0.7479],\n",
            "          [-0.6109, -0.6965, -0.5424,  ...,  2.0092,  0.1768, -0.6623],\n",
            "          ...,\n",
            "          [-0.1486, -0.0972, -0.0801,  ..., -1.0904, -1.2445, -1.2959],\n",
            "          [-0.0458, -0.0801, -0.1314,  ..., -1.3302, -1.2274, -1.5185],\n",
            "          [ 0.0569, -0.0458, -0.1486,  ..., -1.4158, -1.3815, -1.3473]],\n",
            "\n",
            "         [[-1.0028, -1.4055, -1.4405,  ...,  2.3585,  0.4153, -0.8627],\n",
            "          [-0.9853, -1.1779, -1.4405,  ...,  2.2710,  0.3627, -0.7052],\n",
            "          [-0.7577, -0.8452, -0.6877,  ...,  2.1310,  0.2577, -0.6176],\n",
            "          ...,\n",
            "          [-0.1450, -0.0924, -0.0749,  ..., -0.9503, -1.1078, -1.1604],\n",
            "          [-0.0399, -0.0749, -0.1275,  ..., -1.1954, -1.0903, -1.3880],\n",
            "          [ 0.0651, -0.0399, -0.1450,  ..., -1.2829, -1.2479, -1.2129]],\n",
            "\n",
            "         [[-0.8458, -1.2467, -1.2816,  ...,  2.6400,  1.1759,  0.0082],\n",
            "          [-0.8110, -1.0027, -1.2641,  ...,  2.6400,  1.1237,  0.1651],\n",
            "          [-0.6193, -0.7064, -0.5495,  ...,  2.6400,  1.0191,  0.2522],\n",
            "          ...,\n",
            "          [-0.0615, -0.0092,  0.0082,  ..., -0.7761, -0.9330, -0.9853],\n",
            "          [ 0.0431,  0.0082, -0.0441,  ..., -1.0201, -0.9156, -1.2119],\n",
            "          [ 0.1476,  0.0431, -0.0615,  ..., -1.1073, -1.0724, -1.0376]]]],\n",
            "       device='cuda:0')\n",
            "2:  tensor([[[[0.5229, 0.5239, 0.5264,  ..., 0.4519, 0.4509, 0.4504],\n",
            "          [0.5220, 0.5229, 0.5259,  ..., 0.4519, 0.4509, 0.4504],\n",
            "          [0.5176, 0.5186, 0.5210,  ..., 0.4519, 0.4509, 0.4504],\n",
            "          ...,\n",
            "          [0.6255, 0.6255, 0.6255,  ..., 0.2786, 0.2878, 0.2937],\n",
            "          [0.6255, 0.6255, 0.6255,  ..., 0.3020, 0.3130, 0.3198],\n",
            "          [0.6255, 0.6255, 0.6255,  ..., 0.3035, 0.3184, 0.3254]],\n",
            "\n",
            "         [[0.5229, 0.5239, 0.5264,  ..., 0.4519, 0.4509, 0.4504],\n",
            "          [0.5220, 0.5229, 0.5259,  ..., 0.4519, 0.4509, 0.4504],\n",
            "          [0.5176, 0.5186, 0.5210,  ..., 0.4519, 0.4509, 0.4504],\n",
            "          ...,\n",
            "          [0.6255, 0.6255, 0.6255,  ..., 0.2786, 0.2878, 0.2937],\n",
            "          [0.6255, 0.6255, 0.6255,  ..., 0.3020, 0.3130, 0.3198],\n",
            "          [0.6255, 0.6255, 0.6255,  ..., 0.3035, 0.3184, 0.3254]],\n",
            "\n",
            "         [[0.5229, 0.5239, 0.5264,  ..., 0.4519, 0.4509, 0.4504],\n",
            "          [0.5220, 0.5229, 0.5259,  ..., 0.4519, 0.4509, 0.4504],\n",
            "          [0.5176, 0.5186, 0.5210,  ..., 0.4519, 0.4509, 0.4504],\n",
            "          ...,\n",
            "          [0.6255, 0.6255, 0.6255,  ..., 0.2786, 0.2878, 0.2937],\n",
            "          [0.6255, 0.6255, 0.6255,  ..., 0.3020, 0.3130, 0.3198],\n",
            "          [0.6255, 0.6255, 0.6255,  ..., 0.3035, 0.3184, 0.3254]]],\n",
            "\n",
            "\n",
            "        [[[0.2211, 0.2122, 0.1711,  ..., 0.4424, 0.4204, 0.4106],\n",
            "          [0.1986, 0.1886, 0.1488,  ..., 0.4363, 0.4180, 0.4094],\n",
            "          [0.1473, 0.1559, 0.1549,  ..., 0.4202, 0.4070, 0.4004],\n",
            "          ...,\n",
            "          [0.0201, 0.0201, 0.0204,  ..., 0.3179, 0.3093, 0.3064],\n",
            "          [0.0202, 0.0202, 0.0209,  ..., 0.3110, 0.3000, 0.2954],\n",
            "          [0.0203, 0.0203, 0.0210,  ..., 0.3047, 0.2925, 0.2871]],\n",
            "\n",
            "         [[0.2211, 0.2122, 0.1711,  ..., 0.4424, 0.4204, 0.4106],\n",
            "          [0.1986, 0.1886, 0.1488,  ..., 0.4363, 0.4180, 0.4094],\n",
            "          [0.1473, 0.1559, 0.1549,  ..., 0.4202, 0.4070, 0.4004],\n",
            "          ...,\n",
            "          [0.0201, 0.0201, 0.0204,  ..., 0.3179, 0.3093, 0.3064],\n",
            "          [0.0202, 0.0202, 0.0209,  ..., 0.3110, 0.3000, 0.2954],\n",
            "          [0.0203, 0.0203, 0.0210,  ..., 0.3047, 0.2925, 0.2871]],\n",
            "\n",
            "         [[0.2211, 0.2122, 0.1711,  ..., 0.4424, 0.4204, 0.4106],\n",
            "          [0.1986, 0.1886, 0.1488,  ..., 0.4363, 0.4180, 0.4094],\n",
            "          [0.1473, 0.1559, 0.1549,  ..., 0.4202, 0.4070, 0.4004],\n",
            "          ...,\n",
            "          [0.0201, 0.0201, 0.0204,  ..., 0.3179, 0.3093, 0.3064],\n",
            "          [0.0202, 0.0202, 0.0209,  ..., 0.3110, 0.3000, 0.2954],\n",
            "          [0.0203, 0.0203, 0.0210,  ..., 0.3047, 0.2925, 0.2871]]],\n",
            "\n",
            "\n",
            "        [[[0.6211, 0.6211, 0.6211,  ..., 0.2664, 0.2822, 0.2808],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.2795, 0.3096, 0.3181],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.3447, 0.4062, 0.4358],\n",
            "          ...,\n",
            "          [0.6152, 0.6133, 0.6099,  ..., 0.6211, 0.6211, 0.6211],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.6211, 0.6211, 0.6211],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.6211, 0.6211, 0.6211]],\n",
            "\n",
            "         [[0.6211, 0.6211, 0.6211,  ..., 0.2664, 0.2822, 0.2808],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.2795, 0.3096, 0.3181],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.3447, 0.4062, 0.4358],\n",
            "          ...,\n",
            "          [0.6152, 0.6133, 0.6099,  ..., 0.6211, 0.6211, 0.6211],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.6211, 0.6211, 0.6211],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.6211, 0.6211, 0.6211]],\n",
            "\n",
            "         [[0.6211, 0.6211, 0.6211,  ..., 0.2664, 0.2822, 0.2808],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.2795, 0.3096, 0.3181],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.3447, 0.4062, 0.4358],\n",
            "          ...,\n",
            "          [0.6152, 0.6133, 0.6099,  ..., 0.6211, 0.6211, 0.6211],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.6211, 0.6211, 0.6211],\n",
            "          [0.6211, 0.6211, 0.6211,  ..., 0.6211, 0.6211, 0.6211]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.5483, 0.5303, 0.4792,  ..., 0.6284, 0.6284, 0.6284],\n",
            "          [0.5581, 0.5435, 0.5020,  ..., 0.6284, 0.6284, 0.6284],\n",
            "          [0.4912, 0.4785, 0.4482,  ..., 0.6284, 0.6284, 0.6284],\n",
            "          ...,\n",
            "          [0.4128, 0.4119, 0.4019,  ..., 0.0655, 0.0342, 0.0342],\n",
            "          [0.5410, 0.5405, 0.5264,  ..., 0.0621, 0.0342, 0.0342],\n",
            "          [0.6235, 0.6235, 0.6094,  ..., 0.0615, 0.0342, 0.0342]],\n",
            "\n",
            "         [[0.5483, 0.5303, 0.4792,  ..., 0.6284, 0.6284, 0.6284],\n",
            "          [0.5581, 0.5435, 0.5020,  ..., 0.6284, 0.6284, 0.6284],\n",
            "          [0.4912, 0.4785, 0.4482,  ..., 0.6284, 0.6284, 0.6284],\n",
            "          ...,\n",
            "          [0.4128, 0.4119, 0.4019,  ..., 0.0655, 0.0342, 0.0342],\n",
            "          [0.5410, 0.5405, 0.5264,  ..., 0.0621, 0.0342, 0.0342],\n",
            "          [0.6235, 0.6235, 0.6094,  ..., 0.0615, 0.0342, 0.0342]],\n",
            "\n",
            "         [[0.5483, 0.5303, 0.4792,  ..., 0.6284, 0.6284, 0.6284],\n",
            "          [0.5581, 0.5435, 0.5020,  ..., 0.6284, 0.6284, 0.6284],\n",
            "          [0.4912, 0.4785, 0.4482,  ..., 0.6284, 0.6284, 0.6284],\n",
            "          ...,\n",
            "          [0.4128, 0.4119, 0.4019,  ..., 0.0655, 0.0342, 0.0342],\n",
            "          [0.5410, 0.5405, 0.5264,  ..., 0.0621, 0.0342, 0.0342],\n",
            "          [0.6235, 0.6235, 0.6094,  ..., 0.0615, 0.0342, 0.0342]]],\n",
            "\n",
            "\n",
            "        [[[0.6304, 0.6304, 0.6304,  ..., 0.0362, 0.0362, 0.0362],\n",
            "          [0.6304, 0.6304, 0.6304,  ..., 0.0529, 0.0412, 0.0371],\n",
            "          [0.6304, 0.6304, 0.6304,  ..., 0.0624, 0.0437, 0.0376],\n",
            "          ...,\n",
            "          [0.0362, 0.0362, 0.0362,  ..., 0.3821, 0.3914, 0.3965],\n",
            "          [0.0362, 0.0362, 0.0362,  ..., 0.3757, 0.3855, 0.3916],\n",
            "          [0.0362, 0.0362, 0.0362,  ..., 0.3723, 0.3828, 0.3894]],\n",
            "\n",
            "         [[0.6304, 0.6304, 0.6304,  ..., 0.0362, 0.0362, 0.0362],\n",
            "          [0.6304, 0.6304, 0.6304,  ..., 0.0529, 0.0412, 0.0371],\n",
            "          [0.6304, 0.6304, 0.6304,  ..., 0.0624, 0.0437, 0.0376],\n",
            "          ...,\n",
            "          [0.0362, 0.0362, 0.0362,  ..., 0.3821, 0.3914, 0.3965],\n",
            "          [0.0362, 0.0362, 0.0362,  ..., 0.3757, 0.3855, 0.3916],\n",
            "          [0.0362, 0.0362, 0.0362,  ..., 0.3723, 0.3828, 0.3894]],\n",
            "\n",
            "         [[0.6304, 0.6304, 0.6304,  ..., 0.0362, 0.0362, 0.0362],\n",
            "          [0.6304, 0.6304, 0.6304,  ..., 0.0529, 0.0412, 0.0371],\n",
            "          [0.6304, 0.6304, 0.6304,  ..., 0.0624, 0.0437, 0.0376],\n",
            "          ...,\n",
            "          [0.0362, 0.0362, 0.0362,  ..., 0.3821, 0.3914, 0.3965],\n",
            "          [0.0362, 0.0362, 0.0362,  ..., 0.3757, 0.3855, 0.3916],\n",
            "          [0.0362, 0.0362, 0.0362,  ..., 0.3723, 0.3828, 0.3894]]],\n",
            "\n",
            "\n",
            "        [[[0.0225, 0.0225, 0.0225,  ..., 0.3743, 0.3813, 0.3762],\n",
            "          [0.0225, 0.0225, 0.0225,  ..., 0.4019, 0.4082, 0.4036],\n",
            "          [0.0255, 0.0251, 0.0242,  ..., 0.4827, 0.4863, 0.4836],\n",
            "          ...,\n",
            "          [0.4478, 0.4424, 0.4346,  ..., 0.4541, 0.4492, 0.4480],\n",
            "          [0.4644, 0.4609, 0.4553,  ..., 0.4463, 0.4370, 0.4338],\n",
            "          [0.4666, 0.4648, 0.4617,  ..., 0.4419, 0.4309, 0.4268]],\n",
            "\n",
            "         [[0.0225, 0.0225, 0.0225,  ..., 0.3743, 0.3813, 0.3762],\n",
            "          [0.0225, 0.0225, 0.0225,  ..., 0.4019, 0.4082, 0.4036],\n",
            "          [0.0255, 0.0251, 0.0242,  ..., 0.4827, 0.4863, 0.4836],\n",
            "          ...,\n",
            "          [0.4478, 0.4424, 0.4346,  ..., 0.4541, 0.4492, 0.4480],\n",
            "          [0.4644, 0.4609, 0.4553,  ..., 0.4463, 0.4370, 0.4338],\n",
            "          [0.4666, 0.4648, 0.4617,  ..., 0.4419, 0.4309, 0.4268]],\n",
            "\n",
            "         [[0.0225, 0.0225, 0.0225,  ..., 0.3743, 0.3813, 0.3762],\n",
            "          [0.0225, 0.0225, 0.0225,  ..., 0.4019, 0.4082, 0.4036],\n",
            "          [0.0255, 0.0251, 0.0242,  ..., 0.4827, 0.4863, 0.4836],\n",
            "          ...,\n",
            "          [0.4478, 0.4424, 0.4346,  ..., 0.4541, 0.4492, 0.4480],\n",
            "          [0.4644, 0.4609, 0.4553,  ..., 0.4463, 0.4370, 0.4338],\n",
            "          [0.4666, 0.4648, 0.4617,  ..., 0.4419, 0.4309, 0.4268]]]],\n",
            "       device='cuda:0')\n",
            "train tensor([3.4272e-02, 5.1649e-03, 9.5759e-01, 1.6603e-03, 5.8055e-04, 7.3531e-04],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "11 [2, 2, 3, 0, 1, 3, 4, 0, 0, 1, 3, 0, 2, 2, 2, 2] [2, 2, 3, 4, 1, 2, 4, 4, 0, 1, 3, 0, 3, 2, 2, 0]\n",
            "tensor(-0.0547, device='cuda:0')\n",
            "############## 1\n",
            "1:  tensor([[[[ 0.7591,  0.9646,  0.0056,  ...,  1.3584,  1.3584,  1.3584],\n",
            "          [-1.6213, -0.2342,  1.6495,  ...,  1.3584,  1.3584,  1.3584],\n",
            "          [-0.7308,  1.7180,  1.6153,  ...,  1.3755,  1.3755,  1.3584],\n",
            "          ...,\n",
            "          [-0.2342,  0.2453,  0.2796,  ..., -1.2103, -1.4158, -1.4158],\n",
            "          [-0.5253, -0.8335,  0.0569,  ..., -1.2617, -1.1760, -1.4329],\n",
            "          [-0.9192, -0.7137,  0.0227,  ..., -1.2617, -1.2445, -1.1932]],\n",
            "\n",
            "         [[ 1.3782,  1.6057,  0.5903,  ...,  1.6408,  1.6408,  1.6408],\n",
            "          [-1.0728,  0.3452,  2.2185,  ...,  1.6408,  1.6408,  1.6408],\n",
            "          [-0.2150,  2.2535,  2.1134,  ...,  1.6583,  1.6583,  1.6408],\n",
            "          ...,\n",
            "          [ 0.2227,  0.7129,  0.7129,  ..., -1.1078, -1.3179, -1.3179],\n",
            "          [-0.0224, -0.3375,  0.5728,  ..., -1.1604, -1.0728, -1.3354],\n",
            "          [-0.3901, -0.1800,  0.5378,  ..., -1.1604, -1.1429, -1.0903]],\n",
            "\n",
            "         [[ 1.4374,  1.6117,  0.6182,  ...,  1.9951,  1.9951,  1.9951],\n",
            "          [-1.0027,  0.4091,  2.2914,  ...,  1.9951,  1.9951,  1.9951],\n",
            "          [-0.0964,  2.3786,  2.2566,  ...,  2.0125,  2.0125,  1.9951],\n",
            "          ...,\n",
            "          [-0.3578,  0.1302,  0.1651,  ..., -0.9156, -1.1247, -1.1247],\n",
            "          [-0.6541, -0.9678, -0.0092,  ..., -0.9678, -0.8807, -1.1421],\n",
            "          [-1.0724, -0.8284, -0.0615,  ..., -0.9678, -0.9504, -0.8981]]],\n",
            "\n",
            "\n",
            "        [[[-1.3473, -1.5357, -1.7240,  ...,  1.1015,  1.0673,  1.0844],\n",
            "          [-1.2445, -2.1008, -1.4500,  ...,  1.1872,  1.2214,  1.1872],\n",
            "          [-1.7583, -1.3473, -0.8507,  ...,  1.1872,  1.3242,  1.2043],\n",
            "          ...,\n",
            "          [-0.2342, -0.1486, -0.1143,  ..., -1.3473, -1.5699, -1.5699],\n",
            "          [-0.5253, -0.3541, -0.1657,  ..., -1.8097, -1.6384, -1.7069],\n",
            "          [ 0.1083,  0.0056, -0.1143,  ..., -1.5870, -1.6384, -1.6042]],\n",
            "\n",
            "         [[-1.0553, -1.2829, -1.5455,  ...,  1.2906,  1.2731,  1.2906],\n",
            "          [-0.9503, -1.8431, -1.2479,  ...,  1.3782,  1.4307,  1.3957],\n",
            "          [-1.4930, -1.0903, -0.6527,  ...,  1.3782,  1.5357,  1.4132],\n",
            "          ...,\n",
            "          [-0.2500, -0.1450, -0.1099,  ..., -1.2654, -1.4930, -1.4930],\n",
            "          [-0.5301, -0.3550, -0.1099,  ..., -1.7381, -1.5630, -1.6331],\n",
            "          [ 0.1527,  0.0476, -0.0574,  ..., -1.5105, -1.5630, -1.5280]],\n",
            "\n",
            "         [[-0.7238, -0.9678, -1.2467,  ...,  1.4200,  1.3677,  1.3502],\n",
            "          [-0.6541, -1.5779, -1.0201,  ...,  1.5071,  1.4897,  1.4548],\n",
            "          [-1.2816, -0.9156, -0.4973,  ...,  1.5071,  1.5942,  1.4722],\n",
            "          ...,\n",
            "          [-0.0790, -0.0267, -0.0267,  ..., -1.0724, -1.2990, -1.2990],\n",
            "          [-0.4101, -0.2358, -0.0441,  ..., -1.5430, -1.3687, -1.4384],\n",
            "          [ 0.2696,  0.1651,  0.0082,  ..., -1.3164, -1.3687, -1.3339]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1462,  2.1462,  2.1462,  ...,  1.5639,  1.5639,  1.5639],\n",
            "          [ 2.1462,  2.1462,  2.1462,  ...,  1.5639,  1.5639,  1.5639],\n",
            "          [ 2.1462,  2.1462,  2.1462,  ...,  1.5639,  1.5639,  1.5639],\n",
            "          ...,\n",
            "          [ 0.8961,  0.8447,  0.7762,  ..., -1.8439, -1.9980, -1.8439],\n",
            "          [ 0.8618,  0.8104,  0.7591,  ..., -2.0494, -2.0152, -2.0323],\n",
            "          [ 0.8276,  0.8447,  0.8961,  ..., -1.8782, -1.8953, -1.7583]],\n",
            "\n",
            "         [[ 2.3235,  2.3235,  2.3235,  ...,  1.9734,  1.9734,  1.9734],\n",
            "          [ 2.3235,  2.3235,  2.3235,  ...,  1.9734,  1.9734,  1.9734],\n",
            "          [ 2.3235,  2.3235,  2.3235,  ...,  1.9734,  1.9734,  1.9734],\n",
            "          ...,\n",
            "          [ 1.0630,  1.0105,  0.9405,  ..., -1.8606, -2.0182, -1.8606],\n",
            "          [ 1.0280,  0.9755,  0.9230,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 0.9930,  1.0105,  1.0630,  ..., -1.8957, -1.9132, -1.7731]],\n",
            "\n",
            "         [[ 2.5703,  2.5703,  2.5703,  ...,  2.3786,  2.3786,  2.3786],\n",
            "          [ 2.5703,  2.5703,  2.5703,  ...,  2.3786,  2.3786,  2.3786],\n",
            "          [ 2.5703,  2.5703,  2.5703,  ...,  2.3786,  2.3786,  2.3786],\n",
            "          ...,\n",
            "          [ 1.3154,  1.2631,  1.1934,  ..., -1.5604, -1.7173, -1.5604],\n",
            "          [ 1.2805,  1.2282,  1.1759,  ..., -1.7696, -1.7347, -1.7522],\n",
            "          [ 1.2457,  1.2631,  1.3154,  ..., -1.5953, -1.6127, -1.4733]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0048, -0.5938, -0.8507,  ...,  2.2489,  2.2147,  2.2147],\n",
            "          [-0.9534, -1.3130, -0.9363,  ...,  2.2489,  2.2489,  2.2489],\n",
            "          [-1.2274, -0.8164, -0.9534,  ...,  2.2489,  2.2489,  2.2489],\n",
            "          ...,\n",
            "          [-1.1589, -1.0048, -0.9192,  ..., -1.0048, -0.9534, -1.1247],\n",
            "          [-1.0733, -0.8678, -0.7479,  ..., -0.9363, -0.8849, -1.2445],\n",
            "          [-1.0562, -0.9534, -0.8678,  ..., -1.1418, -1.2617, -0.8335]],\n",
            "\n",
            "         [[-1.0903, -0.6176, -0.7752,  ...,  2.2710,  2.2885,  2.2885],\n",
            "          [-1.0028, -1.3354, -0.8627,  ...,  2.3410,  2.3585,  2.3585],\n",
            "          [-1.2479, -0.7752, -0.8627,  ...,  2.3936,  2.3936,  2.3761],\n",
            "          ...,\n",
            "          [-1.1253, -0.9678, -0.8803,  ..., -0.8803, -0.8277, -1.0028],\n",
            "          [-1.0378, -0.8277, -0.6527,  ..., -0.8102, -0.7577, -1.1253],\n",
            "          [-1.0203, -0.9153, -0.7752,  ..., -1.0203, -1.1429, -0.7052]],\n",
            "\n",
            "         [[-1.1770, -0.7587, -0.9853,  ...,  2.5703,  2.5703,  2.5354],\n",
            "          [-1.0376, -1.4210, -1.0376,  ...,  2.6226,  2.6051,  2.6051],\n",
            "          [-1.1596, -0.7587, -0.9504,  ...,  2.6226,  2.6226,  2.6051],\n",
            "          ...,\n",
            "          [-1.3339, -1.1770, -1.0898,  ..., -0.7413, -0.6890, -0.8633],\n",
            "          [-1.2816, -1.0724, -0.9156,  ..., -0.6715, -0.6193, -0.9853],\n",
            "          [-1.2990, -1.1944, -1.0724,  ..., -0.8981, -1.0201, -0.5844]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1358,  0.7248,  0.5364,  ..., -1.5870, -1.4158, -1.1075],\n",
            "          [ 1.4612,  1.2557,  1.2899,  ..., -1.6727, -1.6555, -1.4672],\n",
            "          [ 1.2214,  1.5125,  1.6838,  ..., -1.5357, -0.9363, -0.2856],\n",
            "          ...,\n",
            "          [-1.2959, -1.2959, -1.1247,  ..., -1.5699, -1.6213, -1.5014],\n",
            "          [-1.2617, -1.2617, -1.0390,  ..., -1.7754, -1.7069, -1.7754],\n",
            "          [-1.1589, -1.1760, -0.9877,  ..., -1.7069, -1.8439, -1.6213]],\n",
            "\n",
            "         [[ 1.3431,  0.9230,  0.7479,  ..., -1.3004, -1.1253, -0.8102],\n",
            "          [ 1.6758,  1.4657,  1.5357,  ..., -1.3880, -1.3704, -1.1779],\n",
            "          [ 1.4482,  1.7458,  1.9384,  ..., -1.3004, -0.6877, -0.0224],\n",
            "          ...,\n",
            "          [-0.9153, -0.9328, -0.8277,  ..., -1.4755, -1.5280, -1.4055],\n",
            "          [-0.8803, -0.8978, -0.7402,  ..., -1.6681, -1.5980, -1.6681],\n",
            "          [-0.7752, -0.8102, -0.6877,  ..., -1.5980, -1.7381, -1.5105]],\n",
            "\n",
            "         [[ 1.7163,  1.2980,  1.1585,  ..., -1.3164, -1.1421, -0.8284],\n",
            "          [ 1.9777,  1.8034,  1.8557,  ..., -1.4036, -1.3861, -1.1944],\n",
            "          [ 1.6465,  1.9777,  2.2043,  ..., -1.2990, -0.6890, -0.0267],\n",
            "          ...,\n",
            "          [-0.7064, -0.7587, -0.6715,  ..., -1.2816, -1.3339, -1.2119],\n",
            "          [-0.6541, -0.7238, -0.5844,  ..., -1.5256, -1.4559, -1.5256],\n",
            "          [-0.5670, -0.6367, -0.5670,  ..., -1.4559, -1.5953, -1.3687]]],\n",
            "\n",
            "\n",
            "        [[[-1.5014, -1.1589, -1.1075,  ...,  0.9817,  0.9988, -0.0972],\n",
            "          [-1.6555, -1.3644, -1.2274,  ...,  0.9303, -0.3712, -1.8953],\n",
            "          [-1.2274, -1.2788, -1.2274,  ..., -0.0116, -0.4568,  0.5364],\n",
            "          ...,\n",
            "          [ 0.2796,  0.2282,  0.2282,  ..., -1.5357, -1.7583, -1.6898],\n",
            "          [ 0.2453,  0.1939,  0.2111,  ..., -1.9809, -1.7754, -1.7754],\n",
            "          [ 0.2111,  0.1768,  0.1939,  ..., -1.8268, -1.8439, -1.7240]],\n",
            "\n",
            "         [[-1.2304, -0.8803, -0.8277,  ...,  1.1331,  1.1506,  0.0301],\n",
            "          [-1.3880, -1.0903, -0.9503,  ...,  1.0980, -0.2500, -1.8081],\n",
            "          [-0.9503, -1.0028, -0.9503,  ...,  0.1352, -0.3200,  0.6779],\n",
            "          ...,\n",
            "          [ 0.5728,  0.5203,  0.5203,  ..., -1.4405, -1.6681, -1.5980],\n",
            "          [ 0.5378,  0.4853,  0.5028,  ..., -1.8957, -1.6856, -1.6856],\n",
            "          [ 0.5028,  0.4678,  0.4853,  ..., -1.7381, -1.7556, -1.6331]],\n",
            "\n",
            "         [[-1.1944, -0.8458, -0.7936,  ...,  1.4897,  1.5071,  0.3916],\n",
            "          [-1.3513, -1.0550, -0.9156,  ...,  1.4025,  0.1128, -1.4384],\n",
            "          [-0.9156, -0.9678, -0.9156,  ...,  0.4439, -0.0092,  1.0365],\n",
            "          ...,\n",
            "          [ 0.7751,  0.7228,  0.7228,  ..., -1.2119, -1.4384, -1.3687],\n",
            "          [ 0.7402,  0.6879,  0.7054,  ..., -1.6650, -1.4559, -1.4559],\n",
            "          [ 0.7054,  0.6705,  0.6879,  ..., -1.5081, -1.5256, -1.4036]]]],\n",
            "       device='cuda:0')\n",
            "2:  tensor([[[[-1.1797, -1.2090, -1.2344,  ...,  2.1523,  2.1211,  2.1094],\n",
            "          [-1.2568, -1.2705, -1.2754,  ...,  2.1426,  2.1035,  2.0898],\n",
            "          [-1.3906, -1.3838, -1.3594,  ...,  2.1250,  2.0781,  2.0586],\n",
            "          ...,\n",
            "          [ 0.4990,  0.4934,  0.4978,  ...,  0.7466,  0.7593,  0.7656],\n",
            "          [ 0.2605,  0.2861,  0.3572,  ...,  0.6567,  0.6694,  0.6738],\n",
            "          [ 0.1242,  0.1674,  0.2771,  ...,  0.6328,  0.6455,  0.6479]],\n",
            "\n",
            "         [[-0.9380, -1.0039, -1.1191,  ...,  2.3711,  2.3457,  2.3379],\n",
            "          [-1.0088, -1.0596, -1.1523,  ...,  2.3594,  2.3281,  2.3164],\n",
            "          [-1.1270, -1.1553, -1.2178,  ...,  2.3418,  2.3008,  2.2852],\n",
            "          ...,\n",
            "          [ 0.5708,  0.5654,  0.5698,  ...,  0.7056,  0.7271,  0.7368],\n",
            "          [ 0.3259,  0.3518,  0.4246,  ...,  0.6313,  0.6528,  0.6606],\n",
            "          [ 0.1864,  0.2306,  0.3428,  ...,  0.6128,  0.6343,  0.6401]],\n",
            "\n",
            "         [[-1.2402, -1.2686, -1.2900,  ...,  2.5645,  2.5410,  2.5312],\n",
            "          [-1.2979, -1.3096, -1.3076,  ...,  2.5547,  2.5234,  2.5117],\n",
            "          [-1.3779, -1.3672, -1.3320,  ...,  2.5371,  2.4961,  2.4805],\n",
            "          ...,\n",
            "          [ 0.7490,  0.7456,  0.7529,  ...,  0.7319,  0.7573,  0.7681],\n",
            "          [ 0.5146,  0.5435,  0.6191,  ...,  0.6782,  0.7017,  0.7100],\n",
            "          [ 0.3792,  0.4258,  0.5405,  ...,  0.6665,  0.6890,  0.6953]]],\n",
            "\n",
            "\n",
            "        [[[-0.7070, -0.6729, -0.5947,  ..., -0.5322, -0.6274, -0.6772],\n",
            "          [-0.6182, -0.5659, -0.4761,  ..., -0.4988, -0.6084, -0.6675],\n",
            "          [-0.5439, -0.4441, -0.2864,  ..., -0.4373, -0.5698, -0.6450],\n",
            "          ...,\n",
            "          [-0.3491, -0.3494, -0.3462,  ..., -0.6157, -0.5991, -0.5859],\n",
            "          [-0.4136, -0.4153, -0.4082,  ..., -0.5635, -0.5615, -0.5596],\n",
            "          [-0.4353, -0.4385, -0.4319,  ..., -0.5439, -0.5483, -0.5513]],\n",
            "\n",
            "         [[-0.3301, -0.2969, -0.2196,  ..., -0.8628, -1.0029, -1.0713],\n",
            "          [-0.2654, -0.2136, -0.1239,  ..., -0.8184, -0.9751, -1.0547],\n",
            "          [-0.2568, -0.1559,  0.0047,  ..., -0.7285, -0.9136, -1.0117],\n",
            "          ...,\n",
            "          [-0.2930, -0.2935, -0.2905,  ..., -0.4067, -0.4092, -0.4043],\n",
            "          [-0.3386, -0.3403, -0.3337,  ..., -0.3416, -0.3582, -0.3643],\n",
            "          [-0.3535, -0.3567, -0.3503,  ..., -0.3174, -0.3394, -0.3506]],\n",
            "\n",
            "         [[-0.8120, -0.7749, -0.6880,  ..., -0.6875, -0.7695, -0.8130],\n",
            "          [-0.7373, -0.6812, -0.5820,  ..., -0.6465, -0.7446, -0.7983],\n",
            "          [-0.7021, -0.5967, -0.4268,  ..., -0.5674, -0.6899, -0.7603],\n",
            "          ...,\n",
            "          [-0.3438, -0.3394, -0.3240,  ..., -0.4233, -0.3591, -0.3269],\n",
            "          [-0.3777, -0.3745, -0.3555,  ..., -0.3699, -0.3206, -0.2996],\n",
            "          [-0.3882, -0.3865, -0.3677,  ..., -0.3501, -0.3066, -0.2908]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1445,  2.1445,  2.1445,  ..., -0.3201, -0.2336, -0.1948],\n",
            "          [ 2.1445,  2.1445,  2.1445,  ..., -0.3369, -0.2839, -0.2588],\n",
            "          [ 2.1445,  2.1445,  2.1445,  ..., -0.3420, -0.3464, -0.3450],\n",
            "          ...,\n",
            "          [ 0.7236,  0.7197,  0.7104,  ...,  0.4919,  0.4768,  0.4707],\n",
            "          [ 0.7236,  0.7192,  0.7085,  ...,  0.4885,  0.4746,  0.4692],\n",
            "          [ 0.7236,  0.7188,  0.7080,  ...,  0.4871,  0.4734,  0.4683]],\n",
            "\n",
            "         [[ 2.3223,  2.3223,  2.3223,  ..., -0.1028, -0.0110,  0.0306],\n",
            "          [ 2.3223,  2.3223,  2.3223,  ..., -0.1106, -0.0537, -0.0264],\n",
            "          [ 2.3223,  2.3223,  2.3223,  ..., -0.0892, -0.0931, -0.0910],\n",
            "          ...,\n",
            "          [ 0.9395,  0.9355,  0.9258,  ...,  0.6904,  0.6748,  0.6685],\n",
            "          [ 0.9390,  0.9346,  0.9238,  ...,  0.6826,  0.6685,  0.6626],\n",
            "          [ 0.9390,  0.9346,  0.9233,  ...,  0.6797,  0.6655,  0.6606]],\n",
            "\n",
            "         [[ 2.5684,  2.5684,  2.5684,  ...,  0.1151,  0.1907,  0.2225],\n",
            "          [ 2.5684,  2.5684,  2.5684,  ...,  0.0847,  0.1267,  0.1451],\n",
            "          [ 2.5684,  2.5684,  2.5684,  ...,  0.0437,  0.0286,  0.0241],\n",
            "          ...,\n",
            "          [ 1.1748,  1.1709,  1.1611,  ...,  0.9854,  0.9697,  0.9634],\n",
            "          [ 1.1748,  1.1699,  1.1592,  ...,  0.9858,  0.9717,  0.9663],\n",
            "          [ 1.1748,  1.1699,  1.1582,  ...,  0.9858,  0.9722,  0.9668]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1099, -0.0224, -0.2920,  ...,  0.2944,  0.2634,  0.2510],\n",
            "          [-0.0499, -0.1786, -0.4021,  ...,  0.2825,  0.2429,  0.2273],\n",
            "          [-0.4534, -0.5342, -0.5908,  ...,  0.2378,  0.1858,  0.1677],\n",
            "          ...,\n",
            "          [-0.2473, -0.3384, -0.5474,  ..., -0.8706, -0.8594, -0.8555],\n",
            "          [-0.6074, -0.6841, -0.8706,  ..., -0.9209, -0.9082, -0.9038],\n",
            "          [-0.7856, -0.8564, -1.0361,  ..., -0.9263, -0.9077, -0.9014]],\n",
            "\n",
            "         [[ 0.7295,  0.5864,  0.2981,  ...,  0.4587,  0.4294,  0.4158],\n",
            "          [ 0.5610,  0.4216,  0.1801,  ...,  0.4500,  0.4131,  0.3972],\n",
            "          [ 0.1357,  0.0459, -0.0250,  ...,  0.4153,  0.3704,  0.3540],\n",
            "          ...,\n",
            "          [ 0.0797, -0.0255, -0.2673,  ..., -0.6069, -0.6118, -0.6147],\n",
            "          [-0.3647, -0.4490, -0.6514,  ..., -0.6357, -0.6387, -0.6406],\n",
            "          [-0.5771, -0.6533, -0.8423,  ..., -0.6328, -0.6304, -0.6304]],\n",
            "\n",
            "         [[ 1.9121,  1.7676,  1.4756,  ...,  0.3901,  0.4290,  0.4475],\n",
            "          [ 1.7520,  1.6133,  1.3711,  ...,  0.4177,  0.4480,  0.4634],\n",
            "          [ 1.3438,  1.2568,  1.1934,  ...,  0.4824,  0.5010,  0.5132],\n",
            "          ...,\n",
            "          [-0.7061, -0.7695, -0.9077,  ..., -0.2485, -0.2468, -0.2471],\n",
            "          [-1.0000, -1.0410, -1.1377,  ..., -0.2686, -0.2661, -0.2661],\n",
            "          [-1.1533, -1.1855, -1.2686,  ..., -0.2627, -0.2551, -0.2529]]],\n",
            "\n",
            "\n",
            "        [[[-0.7861, -0.4443,  0.2761,  ..., -0.6284, -0.5156, -0.4485],\n",
            "          [-0.8345, -0.5347,  0.1154,  ..., -0.6270, -0.5142, -0.4521],\n",
            "          [-0.9121, -0.7070, -0.2307,  ..., -0.5728, -0.4878, -0.4468],\n",
            "          ...,\n",
            "          [-0.8452, -0.7432, -0.5039,  ..., -0.7134, -0.7212, -0.7246],\n",
            "          [-0.8291, -0.7173, -0.4678,  ..., -0.7524, -0.7573, -0.7578],\n",
            "          [-0.8228, -0.7065, -0.4519,  ..., -0.7715, -0.7754, -0.7749]],\n",
            "\n",
            "         [[-0.1956,  0.1492,  0.8774,  ..., -0.4585, -0.3525, -0.2861],\n",
            "          [-0.2443,  0.0598,  0.7197,  ..., -0.4431, -0.3372, -0.2756],\n",
            "          [-0.3223, -0.1122,  0.3757,  ..., -0.3528, -0.2754, -0.2357],\n",
            "          ...,\n",
            "          [-0.6284, -0.5171, -0.2559,  ..., -0.4949, -0.5029, -0.5068],\n",
            "          [-0.6118, -0.4910, -0.2188,  ..., -0.5352, -0.5396, -0.5405],\n",
            "          [-0.6055, -0.4800, -0.2023,  ..., -0.5542, -0.5581, -0.5576]],\n",
            "\n",
            "         [[-0.3130,  0.0266,  0.7451,  ..., -0.7759, -0.6719, -0.6089],\n",
            "          [-0.3650, -0.0674,  0.5801,  ..., -0.7988, -0.6968, -0.6392],\n",
            "          [-0.4500, -0.2480,  0.2240,  ..., -0.8052, -0.7363, -0.7021],\n",
            "          ...,\n",
            "          [-0.1957, -0.0916,  0.1504,  ..., -0.0617, -0.0695, -0.0732],\n",
            "          [-0.1790, -0.0656,  0.1859,  ..., -0.1016, -0.1062, -0.1068],\n",
            "          [-0.1724, -0.0546,  0.2017,  ..., -0.1208, -0.1246, -0.1240]]],\n",
            "\n",
            "\n",
            "        [[[-1.5293, -1.5273, -1.5361,  ...,  0.1680,  0.2153,  0.2820],\n",
            "          [-1.4795, -1.4736, -1.4707,  ...,  0.1744,  0.2120,  0.2725],\n",
            "          [-1.3242, -1.3066, -1.2734,  ...,  0.0808,  0.0948,  0.1429],\n",
            "          ...,\n",
            "          [ 0.4827,  0.4819,  0.4812,  ...,  0.9185,  0.9385,  0.9385],\n",
            "          [ 0.4451,  0.4470,  0.4529,  ...,  0.9297,  0.9375,  0.9336],\n",
            "          [ 0.4294,  0.4316,  0.4397,  ...,  0.9360,  0.9404,  0.9360]],\n",
            "\n",
            "         [[-1.2402, -1.2383, -1.2471,  ...,  0.5137,  0.5659,  0.6362],\n",
            "          [-1.1865, -1.1807, -1.1768,  ...,  0.5166,  0.5591,  0.6230],\n",
            "          [-1.0234, -1.0039, -0.9702,  ...,  0.4114,  0.4292,  0.4800],\n",
            "          ...,\n",
            "          [ 0.7280,  0.7271,  0.7266,  ...,  1.0918,  1.1064,  1.1055],\n",
            "          [ 0.6895,  0.6914,  0.6973,  ...,  1.1035,  1.1055,  1.1006],\n",
            "          [ 0.6733,  0.6758,  0.6836,  ...,  1.1094,  1.1084,  1.1035]],\n",
            "\n",
            "         [[-1.3096, -1.3105, -1.3203,  ...,  0.3301,  0.3577,  0.4172],\n",
            "          [-1.2646, -1.2598, -1.2588,  ...,  0.3311,  0.3481,  0.4014],\n",
            "          [-1.1211, -1.1045, -1.0732,  ...,  0.2200,  0.2128,  0.2529],\n",
            "          ...,\n",
            "          [ 0.8882,  0.8877,  0.8872,  ...,  1.3418,  1.3584,  1.3584],\n",
            "          [ 0.8418,  0.8438,  0.8496,  ...,  1.3535,  1.3574,  1.3535],\n",
            "          [ 0.8228,  0.8252,  0.8330,  ...,  1.3604,  1.3604,  1.3555]]]],\n",
            "       device='cuda:0')\n",
            "train tensor([9.9961e-01, 3.0652e-04, 1.2553e-05, 5.3006e-05, 5.8492e-06, 7.6436e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "7 [0, 2, 2, 0, 2, 3, 4, 4, 4, 0, 2, 2, 4, 3, 3, 2] [0, 2, 0, 4, 3, 1, 5, 4, 4, 2, 2, 0, 3, 4, 3, 2]\n",
            "tensor(-0.0453, device='cuda:0')\n",
            "############## 2\n",
            "1:  tensor([[[[ 1.4098,  1.4098,  1.4098,  ..., -0.6623, -0.4054, -1.6384],\n",
            "          [ 1.4098,  1.4098,  1.4098,  ...,  0.2967, -1.1075, -1.3644],\n",
            "          [ 1.4098,  1.4098,  1.4098,  ...,  1.9064,  0.0741, -1.5014],\n",
            "          ...,\n",
            "          [ 0.8961,  1.2043,  1.1187,  ..., -1.2617, -1.5014, -1.4329],\n",
            "          [ 0.5022,  0.4679,  0.3481,  ..., -1.5014, -1.4500, -1.6042],\n",
            "          [ 0.2967,  0.6906,  0.7248,  ..., -1.6898, -1.7069, -1.5185]],\n",
            "\n",
            "         [[ 1.7283,  1.7283,  1.7283,  ..., -0.3901, -0.0924, -1.3179],\n",
            "          [ 1.7283,  1.7283,  1.7283,  ...,  0.5903, -0.8102, -1.0378],\n",
            "          [ 1.7283,  1.7283,  1.7283,  ...,  2.2535,  0.4153, -1.1429],\n",
            "          ...,\n",
            "          [ 0.8529,  1.1681,  1.0805,  ..., -1.1604, -1.4055, -1.3354],\n",
            "          [ 0.4853,  0.4503,  0.3277,  ..., -1.4055, -1.3529, -1.5105],\n",
            "          [ 0.2752,  0.6779,  0.7129,  ..., -1.5980, -1.6155, -1.4230]],\n",
            "\n",
            "         [[ 2.2043,  2.2043,  2.2043,  ..., -0.2184,  0.0256, -1.2467],\n",
            "          [ 2.2043,  2.2043,  2.2043,  ...,  0.7576, -0.6541, -0.9330],\n",
            "          [ 2.2043,  2.2043,  2.2043,  ...,  2.4831,  0.6008, -0.9678],\n",
            "          ...,\n",
            "          [ 0.7576,  1.0714,  0.9842,  ..., -0.9330, -1.1770, -1.1073],\n",
            "          [ 0.4091,  0.3742,  0.2522,  ..., -1.1770, -1.1247, -1.2816],\n",
            "          [ 0.2348,  0.6008,  0.6356,  ..., -1.3687, -1.3861, -1.1944]]],\n",
            "\n",
            "\n",
            "        [[[-0.4911, -0.5253, -0.1828,  ..., -0.6965, -0.7137, -1.0562],\n",
            "          [ 0.5022,  0.0227, -0.3369,  ..., -0.8164, -1.1932, -1.1589],\n",
            "          [ 0.9132,  1.2899, -0.4226,  ..., -0.3198, -1.0390, -1.1418],\n",
            "          ...,\n",
            "          [-0.9877, -1.0219, -1.6727,  ..., -1.1075, -1.3302, -1.2617],\n",
            "          [-0.9705, -1.1418, -1.8097,  ..., -1.3644, -1.2788, -1.3987],\n",
            "          [-0.8849, -1.1589, -1.8610,  ..., -1.4672, -1.4158, -1.1932]],\n",
            "\n",
            "         [[ 0.0126, -0.0224,  0.3627,  ..., -0.2500, -0.1800, -0.4951],\n",
            "          [ 0.9930,  0.5028,  0.1702,  ..., -0.3725, -0.6702, -0.5651],\n",
            "          [ 1.3782,  1.7633,  0.0126,  ...,  0.1527, -0.5126, -0.5301],\n",
            "          ...,\n",
            "          [-0.9328, -1.0028, -1.7031,  ..., -1.0028, -1.2304, -1.1604],\n",
            "          [-0.9153, -1.0903, -1.7906,  ..., -1.2654, -1.1779, -1.3004],\n",
            "          [-0.8277, -1.1078, -1.8431,  ..., -1.3704, -1.3179, -1.0903]],\n",
            "\n",
            "         [[ 0.6531,  0.6182,  1.0017,  ..., -0.4101, -0.3753, -0.7064],\n",
            "          [ 1.6291,  1.1411,  0.7925,  ..., -0.5321, -0.8633, -0.7761],\n",
            "          [ 1.9428,  2.3263,  0.5834,  ..., -0.0615, -0.7413, -0.7936],\n",
            "          ...,\n",
            "          [-0.7936, -0.8807, -1.5779,  ..., -0.7761, -1.0027, -0.9330],\n",
            "          [-0.8110, -0.9853, -1.7173,  ..., -1.0376, -0.9504, -1.0724],\n",
            "          [-0.7238, -1.0027, -1.7696,  ..., -1.1421, -1.0898, -0.8633]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9578,  1.8550,  1.8037,  ...,  0.6049,  0.5878,  0.5878],\n",
            "          [ 1.9920,  1.9235,  1.8379,  ...,  0.6221,  0.6049,  0.6049],\n",
            "          [ 2.0434,  1.9920,  1.9064,  ...,  0.6221,  0.6221,  0.6049],\n",
            "          ...,\n",
            "          [ 0.2624, -0.4397, -0.3541,  ..., -1.4500, -1.6898, -1.6555],\n",
            "          [-0.4739,  0.3138,  0.2453,  ..., -1.7925, -1.5699, -1.6555],\n",
            "          [ 1.1872,  1.7865, -0.3883,  ..., -1.7240, -1.7069, -1.6213]],\n",
            "\n",
            "         [[ 2.3235,  2.2710,  2.2185,  ...,  1.2906,  1.2731,  1.2731],\n",
            "          [ 2.4111,  2.3410,  2.2535,  ...,  1.3081,  1.2906,  1.2906],\n",
            "          [ 2.4286,  2.4111,  2.3235,  ...,  1.3081,  1.3081,  1.2906],\n",
            "          ...,\n",
            "          [ 0.7654,  0.0476,  0.1176,  ..., -1.2304, -1.4755, -1.4405],\n",
            "          [-0.0049,  0.7829,  0.7304,  ..., -1.5805, -1.3354, -1.4230],\n",
            "          [ 1.7108,  2.3060,  0.0826,  ..., -1.4930, -1.4755, -1.3880]],\n",
            "\n",
            "         [[ 2.5703,  2.5006,  2.4831,  ...,  2.3088,  2.2914,  2.2914],\n",
            "          [ 2.6400,  2.5703,  2.5180,  ...,  2.3263,  2.3088,  2.3088],\n",
            "          [ 2.6400,  2.6400,  2.5877,  ...,  2.3263,  2.3263,  2.3088],\n",
            "          ...,\n",
            "          [-0.3578, -1.0376, -0.8981,  ..., -1.5779, -1.8044, -1.7870],\n",
            "          [-0.9853, -0.1487, -0.1487,  ..., -1.8044, -1.7522, -1.8044],\n",
            "          [ 0.7925,  1.4200, -0.7587,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2342, -0.2171, -0.1999,  ...,  1.4954,  1.4954,  1.4954],\n",
            "          [-0.5938, -0.6109, -0.5938,  ...,  1.4954,  1.4954,  1.4954],\n",
            "          [-0.4397, -0.4911, -0.5424,  ...,  1.4954,  1.4954,  1.4954],\n",
            "          ...,\n",
            "          [ 0.9303,  0.9132,  0.8961,  ..., -1.1075, -1.1760, -0.9192],\n",
            "          [ 0.9303,  0.8961,  0.9132,  ..., -1.0219, -1.0733, -1.3815],\n",
            "          [ 1.0331,  1.0331,  1.0502,  ..., -1.3815, -1.2959, -0.9877]],\n",
            "\n",
            "         [[-0.1975, -0.1800, -0.1099,  ...,  1.7983,  1.7983,  1.7983],\n",
            "          [-0.5651, -0.5301, -0.5126,  ...,  1.7983,  1.7983,  1.7983],\n",
            "          [-0.3550, -0.3725, -0.4251,  ...,  1.7983,  1.7983,  1.7983],\n",
            "          ...,\n",
            "          [ 1.0805,  1.0630,  1.0455,  ..., -1.0203, -1.0903, -0.8277],\n",
            "          [ 1.0805,  1.0455,  1.0630,  ..., -0.9153, -0.9678, -1.2829],\n",
            "          [ 1.1856,  1.1856,  1.2031,  ..., -1.2829, -1.1954, -0.8803]],\n",
            "\n",
            "         [[ 0.1302,  0.1476,  0.1999,  ...,  2.0648,  2.0648,  2.0648],\n",
            "          [-0.2358, -0.2184, -0.2010,  ...,  2.0648,  2.0648,  2.0648],\n",
            "          [-0.0790, -0.1138, -0.1661,  ...,  2.0648,  2.0648,  2.0648],\n",
            "          ...,\n",
            "          [ 1.4374,  1.4200,  1.4025,  ..., -0.8807, -0.9504, -0.6890],\n",
            "          [ 1.4374,  1.4025,  1.4200,  ..., -0.8284, -0.8807, -1.1944],\n",
            "          [ 1.5420,  1.5420,  1.5594,  ..., -1.1944, -1.1073, -0.7936]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4098,  1.4269,  1.4269,  ...,  0.7591,  0.7591,  0.7419],\n",
            "          [ 1.4269,  1.4269,  1.4440,  ...,  0.7591,  0.7591,  0.7419],\n",
            "          [ 1.4612,  1.4783,  1.4954,  ...,  0.7591,  0.7591,  0.7419],\n",
            "          ...,\n",
            "          [-1.2959, -1.8268, -1.6384,  ..., -1.2617, -1.4500, -1.4672],\n",
            "          [-1.3130, -1.6042, -1.3644,  ..., -1.7240, -1.5357, -1.6555],\n",
            "          [-1.3130, -1.7412, -1.3815,  ..., -1.4672, -1.5699, -1.6213]],\n",
            "\n",
            "         [[ 1.7808,  1.7983,  1.7983,  ...,  0.9230,  0.9230,  0.9055],\n",
            "          [ 1.7983,  1.7983,  1.8333,  ...,  0.9230,  0.9230,  0.9055],\n",
            "          [ 1.7983,  1.8158,  1.8333,  ...,  0.9230,  0.9230,  0.9055],\n",
            "          ...,\n",
            "          [-1.0903, -1.6331, -1.4930,  ..., -1.0728, -1.2654, -1.2829],\n",
            "          [-1.1078, -1.4055, -1.2129,  ..., -1.5455, -1.3529, -1.4755],\n",
            "          [-1.1078, -1.5455, -1.2304,  ..., -1.2829, -1.3704, -1.4230]],\n",
            "\n",
            "         [[ 2.2043,  2.2217,  2.2217,  ...,  1.0539,  1.0539,  1.0365],\n",
            "          [ 2.2217,  2.2217,  2.2043,  ...,  1.0539,  1.0539,  1.0365],\n",
            "          [ 2.1868,  2.2043,  2.2217,  ...,  1.0539,  1.0539,  1.0365],\n",
            "          ...,\n",
            "          [-1.1073, -1.6476, -1.4559,  ..., -1.2293, -1.4210, -1.4384],\n",
            "          [-1.0898, -1.3861, -1.1770,  ..., -1.7173, -1.5256, -1.6476],\n",
            "          [-1.0898, -1.5256, -1.1944,  ..., -1.4559, -1.5953, -1.6476]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2557,  1.2557,  1.2557,  ..., -1.5699, -1.2445, -0.9877],\n",
            "          [ 1.2557,  1.2557,  1.2557,  ..., -1.4158, -1.2617, -1.1932],\n",
            "          [ 1.2557,  1.2557,  1.2557,  ..., -1.3473, -1.5014, -1.5528],\n",
            "          ...,\n",
            "          [-0.1828, -0.2171, -0.1999,  ..., -1.3987, -1.6555, -1.6042],\n",
            "          [ 0.3138,  0.2111,  0.2111,  ..., -1.7240, -1.5699, -1.5870],\n",
            "          [ 0.3652,  0.2282,  0.1597,  ..., -1.5699, -1.6384, -1.5357]],\n",
            "\n",
            "         [[ 1.4832,  1.4832,  1.4832,  ..., -1.3704, -1.0378, -0.7752],\n",
            "          [ 1.4832,  1.4832,  1.4832,  ..., -1.2129, -1.0553, -0.9853],\n",
            "          [ 1.4832,  1.4832,  1.4832,  ..., -1.1429, -1.3004, -1.3529],\n",
            "          ...,\n",
            "          [-0.3375, -0.3725, -0.3550,  ..., -1.3529, -1.6155, -1.5630],\n",
            "          [ 0.1352,  0.0301,  0.0301,  ..., -1.6856, -1.5280, -1.5455],\n",
            "          [ 0.1877,  0.0476, -0.0224,  ..., -1.5280, -1.5980, -1.4930]],\n",
            "\n",
            "         [[ 1.6814,  1.6814,  1.6814,  ..., -1.3164, -0.9853, -0.7238],\n",
            "          [ 1.6814,  1.6814,  1.6814,  ..., -1.1596, -1.0027, -0.9330],\n",
            "          [ 1.6814,  1.6814,  1.6814,  ..., -1.0898, -1.2467, -1.2990],\n",
            "          ...,\n",
            "          [-0.3404, -0.3753, -0.3578,  ..., -1.2119, -1.4733, -1.4210],\n",
            "          [ 0.1128,  0.0082,  0.0082,  ..., -1.5779, -1.4210, -1.4384],\n",
            "          [ 0.1651,  0.0256, -0.0441,  ..., -1.4210, -1.4907, -1.3861]]]],\n",
            "       device='cuda:0')\n",
            "2:  tensor([[[[0.8638, 0.8638, 0.8638,  ..., 0.6157, 0.6099, 0.6089],\n",
            "          [0.8638, 0.8638, 0.8638,  ..., 0.5801, 0.5815, 0.5840],\n",
            "          [0.8638, 0.8638, 0.8638,  ..., 0.4844, 0.5088, 0.5220],\n",
            "          ...,\n",
            "          [0.5620, 0.5713, 0.6011,  ..., 0.3550, 0.3457, 0.3416],\n",
            "          [0.5752, 0.5879, 0.6235,  ..., 0.2925, 0.2847, 0.2812],\n",
            "          [0.5796, 0.5942, 0.6304,  ..., 0.2649, 0.2578, 0.2549]],\n",
            "\n",
            "         [[0.8979, 0.8979, 0.8979,  ..., 0.7266, 0.7139, 0.7119],\n",
            "          [0.8979, 0.8979, 0.8979,  ..., 0.6958, 0.6870, 0.6865],\n",
            "          [0.8979, 0.8979, 0.8979,  ..., 0.6104, 0.6245, 0.6348],\n",
            "          ...,\n",
            "          [0.5054, 0.5151, 0.5459,  ..., 0.4644, 0.4546, 0.4507],\n",
            "          [0.5151, 0.5283, 0.5645,  ..., 0.3926, 0.3845, 0.3813],\n",
            "          [0.5186, 0.5332, 0.5703,  ..., 0.3604, 0.3530, 0.3501]],\n",
            "\n",
            "         [[0.9009, 0.9009, 0.9009,  ..., 0.8091, 0.8008, 0.7988],\n",
            "          [0.9009, 0.9009, 0.9009,  ..., 0.7964, 0.7891, 0.7866],\n",
            "          [0.9009, 0.9009, 0.9009,  ..., 0.7593, 0.7637, 0.7666],\n",
            "          ...,\n",
            "          [0.5142, 0.5239, 0.5542,  ..., 0.5625, 0.5527, 0.5488],\n",
            "          [0.5425, 0.5557, 0.5918,  ..., 0.4836, 0.4756, 0.4724],\n",
            "          [0.5522, 0.5669, 0.6040,  ..., 0.4485, 0.4409, 0.4382]]],\n",
            "\n",
            "\n",
            "        [[[0.8398, 0.8398, 0.8398,  ..., 0.8398, 0.8398, 0.8398],\n",
            "          [0.8369, 0.8374, 0.8389,  ..., 0.8398, 0.8398, 0.8398],\n",
            "          [0.8320, 0.8340, 0.8369,  ..., 0.8398, 0.8398, 0.8398],\n",
            "          ...,\n",
            "          [0.6221, 0.6660, 0.7544,  ..., 0.4104, 0.4050, 0.4026],\n",
            "          [0.6211, 0.6650, 0.7534,  ..., 0.4104, 0.4050, 0.4026],\n",
            "          [0.6187, 0.6631, 0.7524,  ..., 0.4104, 0.4050, 0.4026]],\n",
            "\n",
            "         [[0.8398, 0.8398, 0.8398,  ..., 0.8398, 0.8398, 0.8398],\n",
            "          [0.8398, 0.8398, 0.8398,  ..., 0.8398, 0.8398, 0.8398],\n",
            "          [0.8394, 0.8398, 0.8398,  ..., 0.8398, 0.8398, 0.8398],\n",
            "          ...,\n",
            "          [0.6396, 0.6812, 0.7627,  ..., 0.5122, 0.5068, 0.5044],\n",
            "          [0.6431, 0.6836, 0.7637,  ..., 0.5122, 0.5068, 0.5044],\n",
            "          [0.6421, 0.6831, 0.7632,  ..., 0.5122, 0.5068, 0.5044]],\n",
            "\n",
            "         [[0.8398, 0.8398, 0.8398,  ..., 0.8398, 0.8398, 0.8398],\n",
            "          [0.8398, 0.8398, 0.8398,  ..., 0.8398, 0.8398, 0.8398],\n",
            "          [0.8403, 0.8403, 0.8398,  ..., 0.8398, 0.8398, 0.8398],\n",
            "          ...,\n",
            "          [0.6294, 0.6719, 0.7563,  ..., 0.5835, 0.5781, 0.5757],\n",
            "          [0.6416, 0.6826, 0.7632,  ..., 0.5835, 0.5781, 0.5757],\n",
            "          [0.6450, 0.6851, 0.7646,  ..., 0.5835, 0.5781, 0.5757]]],\n",
            "\n",
            "\n",
            "        [[[0.7295, 0.7275, 0.7222,  ..., 0.4756, 0.4578, 0.4487],\n",
            "          [0.7349, 0.7324, 0.7261,  ..., 0.4768, 0.4595, 0.4509],\n",
            "          [0.7407, 0.7383, 0.7310,  ..., 0.4832, 0.4680, 0.4604],\n",
            "          ...,\n",
            "          [0.0627, 0.0714, 0.0898,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0695, 0.0813,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0691, 0.0767,  ..., 0.0627, 0.0627, 0.0627]],\n",
            "\n",
            "         [[0.8066, 0.8062, 0.8062,  ..., 0.7612, 0.7422, 0.7334],\n",
            "          [0.8066, 0.8066, 0.8062,  ..., 0.7632, 0.7451, 0.7368],\n",
            "          [0.8071, 0.8066, 0.8066,  ..., 0.7690, 0.7539, 0.7466],\n",
            "          ...,\n",
            "          [0.0627, 0.0718, 0.0917,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0698, 0.0827,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0694, 0.0779,  ..., 0.0627, 0.0627, 0.0627]],\n",
            "\n",
            "         [[0.8130, 0.8130, 0.8135,  ..., 0.8262, 0.8281, 0.8291],\n",
            "          [0.8130, 0.8130, 0.8135,  ..., 0.8257, 0.8276, 0.8286],\n",
            "          [0.8125, 0.8130, 0.8130,  ..., 0.8252, 0.8271, 0.8276],\n",
            "          ...,\n",
            "          [0.0627, 0.0771, 0.1113,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0740, 0.0969,  ..., 0.0627, 0.0627, 0.0627],\n",
            "          [0.0627, 0.0734, 0.0896,  ..., 0.0627, 0.0627, 0.0627]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.0983, 0.0973, 0.0953,  ..., 0.8413, 0.8413, 0.8413],\n",
            "          [0.0980, 0.0970, 0.0966,  ..., 0.8413, 0.8413, 0.8413],\n",
            "          [0.0977, 0.0964, 0.0987,  ..., 0.8413, 0.8413, 0.8413],\n",
            "          ...,\n",
            "          [0.6143, 0.6147, 0.6157,  ..., 0.1715, 0.1594, 0.1558],\n",
            "          [0.6426, 0.6426, 0.6411,  ..., 0.1865, 0.1764, 0.1752],\n",
            "          [0.6519, 0.6519, 0.6499,  ..., 0.1888, 0.1826, 0.1837]],\n",
            "\n",
            "         [[0.1333, 0.1259, 0.1115,  ..., 0.8413, 0.8413, 0.8413],\n",
            "          [0.1453, 0.1379, 0.1252,  ..., 0.8413, 0.8413, 0.8413],\n",
            "          [0.1708, 0.1621, 0.1508,  ..., 0.8413, 0.8413, 0.8413],\n",
            "          ...,\n",
            "          [0.7202, 0.7217, 0.7251,  ..., 0.2224, 0.2054, 0.1997],\n",
            "          [0.7495, 0.7505, 0.7520,  ..., 0.2450, 0.2306, 0.2274],\n",
            "          [0.7593, 0.7607, 0.7617,  ..., 0.2489, 0.2388, 0.2382]],\n",
            "\n",
            "         [[0.2053, 0.1906, 0.1604,  ..., 0.8413, 0.8413, 0.8413],\n",
            "          [0.2391, 0.2253, 0.1986,  ..., 0.8413, 0.8413, 0.8413],\n",
            "          [0.3137, 0.3008, 0.2805,  ..., 0.8413, 0.8413, 0.8413],\n",
            "          ...,\n",
            "          [0.8555, 0.8550, 0.8540,  ..., 0.2310, 0.2137, 0.2080],\n",
            "          [0.8555, 0.8550, 0.8550,  ..., 0.2566, 0.2418, 0.2385],\n",
            "          [0.8545, 0.8545, 0.8545,  ..., 0.2617, 0.2512, 0.2505]]],\n",
            "\n",
            "\n",
            "        [[[0.8271, 0.8271, 0.8271,  ..., 0.3418, 0.3342, 0.3301],\n",
            "          [0.8271, 0.8271, 0.8271,  ..., 0.3396, 0.3330, 0.3291],\n",
            "          [0.8271, 0.8271, 0.8271,  ..., 0.3340, 0.3289, 0.3262],\n",
            "          ...,\n",
            "          [0.0801, 0.0801, 0.0801,  ..., 0.0748, 0.0740, 0.0740],\n",
            "          [0.0801, 0.0801, 0.0801,  ..., 0.0707, 0.0697, 0.0695],\n",
            "          [0.0801, 0.0801, 0.0801,  ..., 0.0695, 0.0681, 0.0677]],\n",
            "\n",
            "         [[0.8271, 0.8271, 0.8271,  ..., 0.4363, 0.4287, 0.4243],\n",
            "          [0.8271, 0.8271, 0.8271,  ..., 0.4341, 0.4272, 0.4233],\n",
            "          [0.8271, 0.8271, 0.8271,  ..., 0.4287, 0.4236, 0.4209],\n",
            "          ...,\n",
            "          [0.0801, 0.0801, 0.0801,  ..., 0.1647, 0.1647, 0.1646],\n",
            "          [0.0801, 0.0801, 0.0801,  ..., 0.2106, 0.2247, 0.2285],\n",
            "          [0.0801, 0.0801, 0.0801,  ..., 0.2286, 0.2468, 0.2520]],\n",
            "\n",
            "         [[0.8271, 0.8271, 0.8271,  ..., 0.4619, 0.4543, 0.4502],\n",
            "          [0.8271, 0.8271, 0.8271,  ..., 0.4597, 0.4531, 0.4492],\n",
            "          [0.8271, 0.8271, 0.8271,  ..., 0.4531, 0.4475, 0.4446],\n",
            "          ...,\n",
            "          [0.0801, 0.0801, 0.0801,  ..., 0.0807, 0.0811, 0.0811],\n",
            "          [0.0801, 0.0801, 0.0801,  ..., 0.0815, 0.0818, 0.0818],\n",
            "          [0.0801, 0.0801, 0.0801,  ..., 0.0817, 0.0820, 0.0821]]],\n",
            "\n",
            "\n",
            "        [[[0.6914, 0.6899, 0.6870,  ..., 0.0483, 0.0483, 0.0483],\n",
            "          [0.6914, 0.6899, 0.6870,  ..., 0.0483, 0.0483, 0.0483],\n",
            "          [0.6914, 0.6899, 0.6870,  ..., 0.0483, 0.0483, 0.0483],\n",
            "          ...,\n",
            "          [0.0483, 0.0483, 0.0491,  ..., 0.3298, 0.3247, 0.3210],\n",
            "          [0.0483, 0.0483, 0.0490,  ..., 0.3296, 0.3550, 0.3630],\n",
            "          [0.0483, 0.0484, 0.0490,  ..., 0.3083, 0.3467, 0.3601]],\n",
            "\n",
            "         [[0.7910, 0.7905, 0.7891,  ..., 0.0483, 0.0483, 0.0483],\n",
            "          [0.7910, 0.7905, 0.7891,  ..., 0.0483, 0.0483, 0.0483],\n",
            "          [0.7910, 0.7905, 0.7891,  ..., 0.0483, 0.0483, 0.0483],\n",
            "          ...,\n",
            "          [0.0483, 0.0483, 0.0483,  ..., 0.3447, 0.3330, 0.3269],\n",
            "          [0.0483, 0.0483, 0.0483,  ..., 0.3552, 0.3745, 0.3801],\n",
            "          [0.0483, 0.0483, 0.0483,  ..., 0.3386, 0.3716, 0.3828]],\n",
            "\n",
            "         [[0.7998, 0.7998, 0.8003,  ..., 0.0483, 0.0483, 0.0483],\n",
            "          [0.7998, 0.7998, 0.8003,  ..., 0.0483, 0.0483, 0.0483],\n",
            "          [0.7998, 0.7998, 0.8003,  ..., 0.0483, 0.0483, 0.0483],\n",
            "          ...,\n",
            "          [0.0483, 0.0484, 0.0519,  ..., 0.3877, 0.3701, 0.3618],\n",
            "          [0.0483, 0.0485, 0.0513,  ..., 0.3997, 0.4146, 0.4187],\n",
            "          [0.0483, 0.0486, 0.0513,  ..., 0.3816, 0.4111, 0.4211]]]],\n",
            "       device='cuda:0')\n",
            "train tensor([0.5144, 0.0747, 0.0270, 0.3045, 0.0711, 0.0082], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [0, 3, 2, 2, 2, 4, 2, 2, 3, 0, 0, 3, 0, 3, 1, 2] [3, 0, 3, 2, 1, 3, 0, 2, 3, 0, 0, 3, 0, 3, 3, 3]\n",
            "tensor(-0.0484, device='cuda:0')\n",
            "############## 3\n",
            "1:  tensor([[[[-1.0048, -0.7137, -1.4158,  ...,  0.9646,  0.8789,  0.9646],\n",
            "          [-0.2684, -0.4397, -0.5938,  ...,  0.8789,  0.9303,  1.0502],\n",
            "          [-1.0904, -0.8507,  0.4166,  ...,  0.8618,  1.0159,  1.0502],\n",
            "          ...,\n",
            "          [-1.4672, -1.5528, -0.7308,  ..., -1.6727, -1.9467, -1.9295],\n",
            "          [-1.0219, -1.2274, -1.3302,  ..., -1.9638, -1.7754, -1.8782],\n",
            "          [-1.1247, -1.2617, -2.1008,  ..., -1.9809, -2.0323, -1.9638]],\n",
            "\n",
            "         [[-0.5301, -0.2850, -1.0378,  ...,  0.8354,  0.7479,  0.8354],\n",
            "          [ 0.2227, -0.0224, -0.1975,  ...,  0.7479,  0.8004,  0.8880],\n",
            "          [-0.6352, -0.4426,  0.8354,  ...,  0.7654,  0.8704,  0.8704],\n",
            "          ...,\n",
            "          [-1.0728, -1.1604, -0.3200,  ..., -1.5980, -1.8782, -1.8606],\n",
            "          [-0.5826, -0.7927, -0.8627,  ..., -1.8957, -1.7031, -1.8081],\n",
            "          [-0.6527, -0.7927, -1.6506,  ..., -1.9132, -1.9657, -1.8957]],\n",
            "\n",
            "         [[-1.0550, -0.7238, -1.3164,  ...,  0.7925,  0.7402,  0.8274],\n",
            "          [-0.2707, -0.4275, -0.4798,  ...,  0.7402,  0.7925,  0.9319],\n",
            "          [-1.0550, -0.8110,  0.5834,  ...,  0.7925,  0.9494,  0.9668],\n",
            "          ...,\n",
            "          [-1.4036, -1.4907, -0.6541,  ..., -1.4384, -1.7173, -1.6999],\n",
            "          [-0.8807, -1.0898, -1.2119,  ..., -1.7347, -1.5430, -1.6476],\n",
            "          [-0.9678, -1.1073, -1.8044,  ..., -1.7522, -1.8044, -1.7347]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4612,  1.4612,  1.4612,  ...,  1.8722,  1.8722,  1.8722],\n",
            "          [ 1.4612,  1.4612,  1.4612,  ...,  1.8550,  1.8722,  1.8722],\n",
            "          [ 1.4612,  1.4612,  1.4612,  ...,  1.8550,  1.8550,  1.8722],\n",
            "          ...,\n",
            "          [ 0.9303,  1.0673,  1.0159,  ..., -1.6042, -1.7925, -1.8610],\n",
            "          [ 0.9646,  0.9988,  1.0502,  ..., -1.8439, -1.6384, -2.0152],\n",
            "          [ 1.0502,  0.9474,  1.0331,  ..., -1.9124, -1.7069, -1.7754]],\n",
            "\n",
            "         [[ 1.6933,  1.6933,  1.6933,  ...,  2.1134,  2.1134,  2.1134],\n",
            "          [ 1.6933,  1.6933,  1.6933,  ...,  2.0959,  2.1134,  2.1134],\n",
            "          [ 1.6933,  1.6933,  1.6933,  ...,  2.0959,  2.0959,  2.1134],\n",
            "          ...,\n",
            "          [ 1.1506,  1.2906,  1.2381,  ..., -1.5455, -1.7381, -1.8081],\n",
            "          [ 1.1856,  1.2206,  1.2731,  ..., -1.7906, -1.5805, -1.9657],\n",
            "          [ 1.2731,  1.1681,  1.2556,  ..., -1.8606, -1.6506, -1.7206]],\n",
            "\n",
            "         [[ 1.8905,  1.8905,  1.8905,  ...,  2.3437,  2.3437,  2.3437],\n",
            "          [ 1.8905,  1.8905,  1.8905,  ...,  2.3263,  2.3437,  2.3437],\n",
            "          [ 1.8905,  1.8905,  1.8905,  ...,  2.3263,  2.3263,  2.3437],\n",
            "          ...,\n",
            "          [ 1.1237,  1.2631,  1.2108,  ..., -1.2990, -1.4559, -1.5256],\n",
            "          [ 1.1411,  1.1759,  1.2282,  ..., -1.5430, -1.2990, -1.6824],\n",
            "          [ 1.2282,  1.1237,  1.2108,  ..., -1.6127, -1.3687, -1.4384]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7865,  1.8208,  1.8379,  ...,  1.7865,  1.7694,  1.7523],\n",
            "          [ 1.7865,  1.8037,  1.8379,  ...,  1.8037,  1.7865,  1.7523],\n",
            "          [ 1.7694,  1.8037,  1.8379,  ...,  1.8208,  1.7865,  1.7694],\n",
            "          ...,\n",
            "          [-0.5767, -0.5767, -0.6109,  ..., -1.3815, -1.5528, -1.4158],\n",
            "          [-0.6452, -0.5082, -0.4911,  ..., -1.8439, -1.6213, -1.5699],\n",
            "          [-0.8849, -0.6452, -0.5767,  ..., -1.5870, -1.6555, -1.5357]],\n",
            "\n",
            "         [[ 2.0959,  2.1310,  2.1485,  ...,  2.0084,  1.9909,  1.9734],\n",
            "          [ 2.0959,  2.1134,  2.1485,  ...,  2.0259,  2.0084,  1.9734],\n",
            "          [ 2.0784,  2.1134,  2.1485,  ...,  2.0434,  2.0084,  1.9909],\n",
            "          ...,\n",
            "          [-0.2150, -0.1800, -0.2150,  ..., -1.2304, -1.4055, -1.2654],\n",
            "          [-0.2675, -0.1099, -0.0924,  ..., -1.7031, -1.4755, -1.4230],\n",
            "          [-0.5126, -0.2675, -0.1800,  ..., -1.4405, -1.5105, -1.3880]],\n",
            "\n",
            "         [[ 2.3611,  2.3960,  2.4134,  ...,  2.3786,  2.3611,  2.3437],\n",
            "          [ 2.3611,  2.3786,  2.4134,  ...,  2.3960,  2.3786,  2.3437],\n",
            "          [ 2.3437,  2.3786,  2.4134,  ...,  2.4134,  2.3786,  2.3611],\n",
            "          ...,\n",
            "          [-1.0550, -1.0376, -1.0724,  ..., -1.3339, -1.5081, -1.3687],\n",
            "          [-1.0724, -0.9678, -0.9504,  ..., -1.8044, -1.5779, -1.5256],\n",
            "          [-1.3164, -1.0724, -1.0376,  ..., -1.5779, -1.6476, -1.5256]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3242,  1.3070,  1.2557,  ..., -0.4739, -0.4911, -0.5596],\n",
            "          [ 1.3070,  1.3070,  1.2557,  ..., -0.5938, -0.2684, -1.0562],\n",
            "          [ 1.3070,  1.2728,  1.2557,  ..., -0.9192, -0.5424, -0.8678],\n",
            "          ...,\n",
            "          [ 0.6563,  0.7933,  0.8104,  ..., -1.1247, -1.3130, -1.2617],\n",
            "          [ 0.6221,  0.7591,  0.8789,  ..., -1.4672, -1.3644, -1.5528],\n",
            "          [ 0.8104,  0.7762,  0.7762,  ..., -1.5014, -1.4843, -1.3302]],\n",
            "\n",
            "         [[ 1.6583,  1.6758,  1.6758,  ..., -0.3025, -0.3025, -0.3725],\n",
            "          [ 1.6758,  1.6758,  1.6758,  ..., -0.3901, -0.0749, -0.8803],\n",
            "          [ 1.6758,  1.6933,  1.6758,  ..., -0.7227, -0.2850, -0.6352],\n",
            "          ...,\n",
            "          [ 0.7129,  0.8529,  0.8704,  ..., -1.0378, -1.2304, -1.1779],\n",
            "          [ 0.6779,  0.8179,  0.9405,  ..., -1.3704, -1.2654, -1.4580],\n",
            "          [ 0.8704,  0.8354,  0.8354,  ..., -1.4055, -1.3880, -1.2304]],\n",
            "\n",
            "         [[ 2.3088,  2.3088,  2.2914,  ..., -1.0027, -0.9678, -1.0201],\n",
            "          [ 2.3088,  2.3088,  2.2914,  ..., -1.1421, -0.7413, -1.5256],\n",
            "          [ 2.3437,  2.3088,  2.2914,  ..., -1.5081, -1.0550, -1.3513],\n",
            "          ...,\n",
            "          [ 0.5834,  0.7228,  0.7402,  ..., -0.8981, -1.0898, -1.0376],\n",
            "          [ 0.5485,  0.6879,  0.7751,  ..., -1.2816, -1.1770, -1.3687],\n",
            "          [ 0.7402,  0.6705,  0.6705,  ..., -1.3164, -1.2990, -1.1421]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9646,  0.9646,  0.9646,  ..., -2.1179, -2.1179, -1.1247],\n",
            "          [ 0.9646,  0.9646,  0.9646,  ..., -1.9124, -1.9124, -1.3987],\n",
            "          [ 0.9646,  0.9646,  0.9646,  ..., -1.6727, -1.5870, -1.6384],\n",
            "          ...,\n",
            "          [ 0.1939,  0.1083,  0.0569,  ..., -1.6042, -1.7925, -1.6727],\n",
            "          [-0.0458, -0.0116,  0.1083,  ..., -1.9638, -1.7754, -1.7583],\n",
            "          [ 0.1254,  0.1083,  0.1254,  ..., -1.7240, -1.8097, -1.7412]],\n",
            "\n",
            "         [[ 1.1856,  1.1856,  1.1856,  ..., -1.9482, -1.8606, -0.8102],\n",
            "          [ 1.1856,  1.1856,  1.1856,  ..., -1.6331, -1.5980, -1.0728],\n",
            "          [ 1.1856,  1.1856,  1.1856,  ..., -1.3529, -1.2654, -1.2829],\n",
            "          ...,\n",
            "          [ 0.3452,  0.2577,  0.2052,  ..., -1.4405, -1.6331, -1.5105],\n",
            "          [ 0.1001,  0.1352,  0.2577,  ..., -1.8081, -1.6155, -1.5980],\n",
            "          [ 0.2752,  0.2577,  0.2752,  ..., -1.5630, -1.6506, -1.5805]],\n",
            "\n",
            "         [[ 1.4200,  1.4200,  1.4200,  ..., -1.6999, -1.6302, -0.6193],\n",
            "          [ 1.4200,  1.4200,  1.4200,  ..., -1.5430, -1.5256, -1.0027],\n",
            "          [ 1.4200,  1.4200,  1.4200,  ..., -1.4384, -1.3861, -1.4210],\n",
            "          ...,\n",
            "          [ 0.4265,  0.3393,  0.2871,  ..., -1.4733, -1.6650, -1.5430],\n",
            "          [ 0.1825,  0.2173,  0.3393,  ..., -1.8044, -1.6476, -1.6302],\n",
            "          [ 0.3568,  0.3393,  0.3568,  ..., -1.6302, -1.7173, -1.6476]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6734,  0.6734,  0.6734,  ...,  0.2624,  0.4337,  0.4851],\n",
            "          [ 0.6734,  0.6734,  0.6734,  ...,  0.3309,  0.2967,  0.2282],\n",
            "          [ 0.6563,  0.6563,  0.6563,  ..., -0.1999, -0.4054, -0.4739],\n",
            "          ...,\n",
            "          [ 0.9988,  1.1187,  1.1358,  ..., -1.5870, -1.8268, -1.8268],\n",
            "          [ 0.7248,  0.7248,  0.9474,  ..., -2.0323, -1.8610, -1.9295],\n",
            "          [ 1.0159,  0.8618,  1.0159,  ..., -1.8782, -1.9467, -1.8953]],\n",
            "\n",
            "         [[ 1.1681,  1.1681,  1.1681,  ...,  0.6954,  0.7479,  0.7479],\n",
            "          [ 1.1681,  1.1681,  1.1681,  ...,  0.7654,  0.6078,  0.5203],\n",
            "          [ 1.1506,  1.1506,  1.1506,  ...,  0.2227, -0.0574, -0.1800],\n",
            "          ...,\n",
            "          [ 0.4153,  0.4678,  0.4153,  ..., -1.4930, -1.7381, -1.7381],\n",
            "          [ 0.2052,  0.1352,  0.2752,  ..., -1.9482, -1.7731, -1.8431],\n",
            "          [ 0.5378,  0.2927,  0.3627,  ..., -1.7906, -1.8606, -1.8081]],\n",
            "\n",
            "         [[ 1.9603,  1.9603,  1.9603,  ...,  1.0539,  1.1237,  1.1062],\n",
            "          [ 1.9603,  1.9603,  1.9603,  ...,  1.1237,  0.9842,  0.8971],\n",
            "          [ 1.9428,  1.9428,  1.9428,  ...,  0.6182,  0.3219,  0.2173],\n",
            "          ...,\n",
            "          [ 0.2173,  0.2696,  0.1999,  ..., -1.2641, -1.5081, -1.5081],\n",
            "          [ 0.0605, -0.0615,  0.0431,  ..., -1.7173, -1.5430, -1.6127],\n",
            "          [ 0.3742,  0.1302,  0.1651,  ..., -1.5604, -1.6302, -1.5779]]]],\n",
            "       device='cuda:0')\n",
            "2:  tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.9434e-01,\n",
            "           6.9287e-01, 6.9287e-01],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.1973e-01,\n",
            "           7.1777e-01, 7.1729e-01],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.7686e-01,\n",
            "           7.7441e-01, 7.7344e-01],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.8037e-01,\n",
            "           8.7939e-01, 8.7939e-01],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.9014e-01,\n",
            "           8.8916e-01, 8.8867e-01],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1113e-01,\n",
            "           9.0967e-01, 9.0869e-01],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[9.7852e-01, 9.7705e-01, 9.7314e-01,  ..., 9.8242e-01,\n",
            "           9.9219e-01, 9.9609e-01],\n",
            "          [9.7754e-01, 9.7656e-01, 9.7363e-01,  ..., 9.8193e-01,\n",
            "           9.9072e-01, 9.9414e-01],\n",
            "          [9.7412e-01, 9.7412e-01, 9.7412e-01,  ..., 9.8096e-01,\n",
            "           9.8779e-01, 9.9023e-01],\n",
            "          ...,\n",
            "          [1.9623e-02, 1.4191e-02, 1.0887e-02,  ..., 8.9697e-01,\n",
            "           9.0234e-01, 9.0430e-01],\n",
            "          [9.4757e-03, 6.7711e-03, 8.6136e-03,  ..., 9.0088e-01,\n",
            "           9.0576e-01, 9.0771e-01],\n",
            "          [3.9253e-03, 2.7313e-03, 7.3090e-03,  ..., 9.0186e-01,\n",
            "           9.0674e-01, 9.0869e-01]],\n",
            "\n",
            "         [[9.9170e-01, 9.9121e-01, 9.8975e-01,  ..., 9.9316e-01,\n",
            "           9.9707e-01, 9.9854e-01],\n",
            "          [9.9121e-01, 9.9121e-01, 9.8975e-01,  ..., 9.9316e-01,\n",
            "           9.9658e-01, 9.9805e-01],\n",
            "          [9.9023e-01, 9.9023e-01, 9.9023e-01,  ..., 9.9268e-01,\n",
            "           9.9561e-01, 9.9658e-01],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.5996e-01,\n",
            "           9.6191e-01, 9.6240e-01],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.6094e-01,\n",
            "           9.6289e-01, 9.6387e-01],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.6143e-01,\n",
            "           9.6338e-01, 9.6436e-01]],\n",
            "\n",
            "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          ...,\n",
            "          [8.9478e-02, 6.3599e-02, 3.6987e-02,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [3.7445e-02, 2.6505e-02, 2.5055e-02,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [9.9945e-03, 6.9580e-03, 1.8616e-02,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 3.6776e-05,  ..., 1.3380e-03,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.5177e-03,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.9507e-03,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 1.4424e-05,  ..., 5.2547e-04,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.8896e-04,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1587e-03,\n",
            "           0.0000e+00, 0.0000e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[6.3623e-01, 6.3037e-01, 6.1719e-01,  ..., 3.5205e-01,\n",
            "           3.7695e-01, 3.8647e-01],\n",
            "          [6.4355e-01, 6.3770e-01, 6.2500e-01,  ..., 3.5767e-01,\n",
            "           3.8013e-01, 3.8892e-01],\n",
            "          [6.6064e-01, 6.5527e-01, 6.4355e-01,  ..., 3.7329e-01,\n",
            "           3.9111e-01, 3.9795e-01],\n",
            "          ...,\n",
            "          [6.2158e-01, 6.1963e-01, 6.0840e-01,  ..., 6.6467e-02,\n",
            "           3.7567e-02, 2.3483e-02],\n",
            "          [5.7129e-01, 5.7715e-01, 5.7080e-01,  ..., 1.9745e-02,\n",
            "           1.3695e-02, 9.9792e-03],\n",
            "          [5.4834e-01, 5.5615e-01, 5.4883e-01,  ..., 6.3229e-04,\n",
            "           1.8768e-03, 2.6970e-03]],\n",
            "\n",
            "         [[8.5156e-01, 8.4473e-01, 8.2959e-01,  ..., 5.2148e-01,\n",
            "           5.3809e-01, 5.4443e-01],\n",
            "          [8.5596e-01, 8.5010e-01, 8.3691e-01,  ..., 5.2832e-01,\n",
            "           5.4248e-01, 5.4785e-01],\n",
            "          [8.6523e-01, 8.6133e-01, 8.5205e-01,  ..., 5.4590e-01,\n",
            "           5.5566e-01, 5.5957e-01],\n",
            "          ...,\n",
            "          [6.1865e-01, 6.1670e-01, 6.0547e-01,  ..., 2.8906e-01,\n",
            "           2.4768e-01, 2.2705e-01],\n",
            "          [5.6592e-01, 5.7178e-01, 5.6543e-01,  ..., 1.2561e-01,\n",
            "           1.2695e-01, 1.2634e-01],\n",
            "          [5.4248e-01, 5.5029e-01, 5.4297e-01,  ..., 4.8889e-02,\n",
            "           6.3782e-02, 7.1350e-02]],\n",
            "\n",
            "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          ...,\n",
            "          [6.4844e-01, 6.4648e-01, 6.3525e-01,  ..., 8.5327e-02,\n",
            "           5.7007e-02, 4.2603e-02],\n",
            "          [5.9521e-01, 6.0107e-01, 5.9473e-01,  ..., 3.5889e-02,\n",
            "           2.5772e-02, 1.9623e-02],\n",
            "          [5.7129e-01, 5.7910e-01, 5.7178e-01,  ..., 1.2527e-02,\n",
            "           9.7809e-03, 8.1482e-03]]],\n",
            "\n",
            "\n",
            "        [[[7.5488e-01, 7.5195e-01, 7.4463e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [7.5000e-01, 7.4756e-01, 7.4170e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [7.3926e-01, 7.3828e-01, 7.3486e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [1.2311e-01, 1.3013e-01, 1.4148e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.3013e-01, 1.3989e-01, 1.5588e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.3464e-01, 1.4478e-01, 1.6174e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[8.4863e-01, 8.4473e-01, 8.3398e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [8.4229e-01, 8.3887e-01, 8.3008e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [8.2715e-01, 8.2568e-01, 8.2031e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [1.5674e-01, 1.6394e-01, 1.7554e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.6394e-01, 1.7383e-01, 1.9006e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.6858e-01, 1.7896e-01, 1.9617e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [3.6621e-01, 3.7329e-01, 3.8501e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [3.7329e-01, 3.8330e-01, 3.9966e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [3.7793e-01, 3.8843e-01, 4.0576e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[5.5518e-01, 5.5566e-01, 5.5615e-01,  ..., 8.0261e-03,\n",
            "           2.7027e-03, 0.0000e+00],\n",
            "          [5.5371e-01, 5.5420e-01, 5.5469e-01,  ..., 5.5809e-03,\n",
            "           1.8806e-03, 0.0000e+00],\n",
            "          [5.4980e-01, 5.5078e-01, 5.5176e-01,  ..., 1.8806e-03,\n",
            "           6.3324e-04, 0.0000e+00],\n",
            "          ...,\n",
            "          [3.3228e-01, 4.5947e-01, 7.0801e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [3.5864e-01, 4.8608e-01, 7.3291e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [3.7842e-01, 5.0635e-01, 7.5244e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[8.0566e-01, 8.0615e-01, 8.0713e-01,  ..., 5.0545e-03,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [8.0371e-01, 8.0420e-01, 8.0518e-01,  ..., 3.5172e-03,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [7.9834e-01, 7.9932e-01, 8.0078e-01,  ..., 1.1854e-03,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [1.7468e-01, 2.6611e-01, 4.4385e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.9849e-01, 2.9443e-01, 4.8022e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [2.1631e-01, 3.1616e-01, 5.0977e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.9814e-02,\n",
            "           1.2009e-02, 0.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 4.1595e-02,\n",
            "           8.3618e-03, 0.0000e+00],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.4015e-02,\n",
            "           2.8152e-03, 0.0000e+00],\n",
            "          ...,\n",
            "          [2.9907e-02, 5.6061e-02, 1.0016e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [4.0771e-02, 7.5134e-02, 1.3416e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [4.9774e-02, 9.1187e-02, 1.6309e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]]], device='cuda:0')\n",
            "train tensor([3.2937e-03, 3.9209e-03, 9.9229e-01, 1.0660e-04, 1.2294e-04, 2.6904e-04],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "7 [2, 0, 4, 0, 3, 0, 2, 0, 4, 4, 3, 2, 3, 2, 1, 0] [2, 2, 4, 1, 2, 3, 2, 3, 4, 4, 4, 2, 3, 1, 4, 2]\n",
            "tensor(-0.0515, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "yjix6KhUqxY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71db8d44-d8df-433e-a4b7-80c530adb2e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# @title data (old)\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "dir='/content/gsv70kg'\n",
        "\n",
        "data = datasets.ImageFolder(dir, transform=transform)\n",
        "# data = datasets.ImageFolder(dir, transform=None)\n",
        "torch.manual_seed(0)\n",
        "train_data, test_data = torch.utils.data.random_split(data, [.9,.1])\n",
        "\n",
        "batch_size = 16 # 64\n",
        "num_batches=int(np.ceil(len(train_data)/batch_size))\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "del data, train_data, test_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Pqw5n--6WYEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea99e39-81a3-483a-d71c-6692a2e0c04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# dataset has PILImage images of range [0, 1], transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "# transform = transforms.Compose(transforms.ToTensor())\n",
        "\n",
        "# dir='/content/gsv'\n",
        "dir='/content/gsv70kg'\n",
        "\n",
        "# data = datasets.ImageFolder(dir, transform=transform)\n",
        "data = datasets.ImageFolder(dir, transform=None)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# split data manually so that can work with weighted random sampler\n",
        "# train_data, test_data = torch.utils.data.random_split(data, [.85,.15])\n",
        "# https://www.scaler.com/topics/pytorch/how-to-split-a-torch-dataset/\n",
        "data_size = len(data)\n",
        "indices = np.arange(data_size)\n",
        "np.random.shuffle(indices)\n",
        "split_index = int(np.floor(0.9 * data_size))\n",
        "# split_index = int(np.floor(0.002 * data_size))\n",
        "train_idx, test_idx = indices[:split_index], indices[split_index:]\n",
        "# train_idx, test_idx = indices[:split_index], indices[split_index:split_index*2]\n",
        "# train_idx, test_idx = indices[:145], indices[10000:10017]\n",
        "train_data = torch.utils.data.Subset(data, train_idx)\n",
        "test_data = torch.utils.data.Subset(data, test_idx)\n",
        "targets = np.array(data.targets)\n",
        "train_targets = targets[train_idx]\n",
        "test_targets = targets[test_idx]\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "class DatasetWrap(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super(DatasetWrap, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "# dataset wrapper in order to apply transforms to train data only\n",
        "# train_data = DatasetWrap(train_data, TrainTransform()) # apply data augmentation to train dataset only\n",
        "train_data = DatasetWrap(train_data, transform) # apply transform during training to use gpu\n",
        "test_data = DatasetWrap(test_data, transform)\n",
        "\n",
        "# use batch size 16 for resnet 152/ vit with grad accumulation\n",
        "# can use batch size 64 for inception v3 without grad accumulation?\n",
        "batch_size = 16 # 64/16\n",
        "num_batches=int(np.ceil(len(train_data)/batch_size))\n",
        "\n",
        "# oversampling\n",
        "# https://stackoverflow.com/questions/62319228/number-of-instances-per-class-in-pytorch-dataset\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data.targets).values()))\n",
        "weights=1./class_count\n",
        "# weights=sum(class_count)/class_count\n",
        "# print(weights)\n",
        "# https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler\n",
        "\n",
        "train_weight = weights[train_targets]\n",
        "test_weight = weights[test_targets]\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(train_weight, len(train_weight))\n",
        "test_sampler = torch.utils.data.WeightedRandomSampler(test_weight, len(test_weight))\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True, drop_last=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=4, pin_memory=True, drop_last=True)\n",
        "del data, train_data, test_data\n",
        "\n",
        "\n",
        "# test oversampling: occurence of each class should be roughly equal\n",
        "# c=0\n",
        "# print(len(test_loader))\n",
        "# # for batch, (x, y) in enumerate(train_loader):\n",
        "# for batch, (x, y) in enumerate(test_loader):\n",
        "#     print(torch.bincount(y)) # torch count number of elements with value in tensor\n",
        "#     c+=1\n",
        "#     if c>5: break\n",
        "\n",
        "# display img from torch tensor\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = next(dataiter)\n",
        "# images=trs(images)\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=4))\n",
        "# del dataiter\n",
        "\n",
        "# print(labels)\n",
        "\n",
        "# dataiter = iter(test_loader)\n",
        "# images, labels = next(dataiter)\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=4))\n",
        "# del dataiter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7oYDr8kuA5Bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13d4692-d997-4994-8d2f-bf62d0ddac0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-f82ba261.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-f82ba261.pth\n",
            "100%|| 230M/230M [00:03<00:00, 67.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "# # https://pytorch.org/vision/0.12/models.html#id10\n",
        "model = models.resnet152(weights='DEFAULT') # 18 34 50 101 152\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential( # og (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "    nn.Linear(num_ftrs, 6),\n",
        "    nn.Softmax(dim=1),\n",
        "    )\n",
        "\n",
        "def track_false(m):\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        m.track_running_stats = False\n",
        "model.apply(track_false)\n",
        "\n",
        "# print(model)\n",
        "\n",
        "# # model.mods = [module for k, module in model._modules.items()]\n",
        "# # modules = [module for k, module in model._modules.items()]\n",
        "\n",
        "# torch._dynamo.config.suppress_errors = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "# model = torch.compile(model.to(device))\n",
        "# model = torch.compile(model.to(device),mode='reduce-overhead')\n",
        "model = torch.compile(model.to(device),mode='max-autotune')\n",
        "\n",
        "# resnet152 batch16 compile gradacc nogradckpt lr3e-6,3e-5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rJw9_Ort2Sek"
      },
      "outputs": [],
      "source": [
        "# @title vit\n",
        "# https://arxiv.org/pdf/2010.11929.pdf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "# https://pytorch.org/vision/main/models/vision_transformer.html\n",
        "# https://pytorch.org/vision/main/models/generated/torchvision.models.vit_b_16.html#torchvision.models.vit_b_16\n",
        "# model = models.vit_l_16(weights='DEFAULT') # small vit_b_16 vit_b_32 vit_l_16 vit_l_32 vit_h_14 big\n",
        "# # VisionTransformer(image_size, patch_size, num_layers, num_heads, hidden_dim, mlp_dim)\n",
        "# num_ftrs = model.heads.head.in_features\n",
        "# # num_ftrs = model.heads[-1].in_features\n",
        "# model.heads = nn.Sequential(\n",
        "#     # nn.Dropout(0.2),\n",
        "#     nn.Linear(num_ftrs, 6, bias=False),\n",
        "#     nn.Softmax(dim=1),\n",
        "#     )\n",
        "\n",
        "\n",
        "!pip install timm\n",
        "# https://github.com/huggingface/pytorch-image-models/issues/908\n",
        "import timm\n",
        "# model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "model = timm.create_model('vit_base_patch16_224', img_size=(400, 640), pretrained=True)\n",
        "# [print(x) for x in timm.list_models('vit*',pretrained=True)]\n",
        "# https://huggingface.co/google/vit-base-patch16-224\n",
        "# https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/vision_transformer.py\n",
        "# vit_base_patch16_224 compile,no ckpt # patch_size=16, embed_dim=768, depth=12, num_heads=12\n",
        "# vit_base_patch16_384\n",
        "# vit_large_patch16_224 explodesgpu # patch_size=16, embed_dim=1024, depth=24, num_heads=16\n",
        "# vit_large_patch16_384 # patch_size=16, embed_dim=1024, depth=24, num_heads=16\n",
        "\n",
        "# or fine tune huge\n",
        "# vit_large_patch14_224 # patch_size=16, embed_dim=1024, depth=24, num_heads=16\n",
        "# vit_large_patch16_384\n",
        "\n",
        "\n",
        "num_ftrs = model.head.in_features\n",
        "model.head = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 6),\n",
        "    nn.Softmax(dim=1),\n",
        "    )\n",
        "# model.set_grad_checkpointing()\n",
        "\n",
        "# print(model.patch_embed.grid_size) # (25, 40)\n",
        "# print(model.pos_embed.shape) # [1, 1001, 768]\n",
        "# https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
        "\n",
        "# print(model)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "model = torch.compile(model.to(device))\n",
        "# model = torch.compile(model.to(device),mode='reduce-overhead')\n",
        "# model = torch.compile(model.to(device),mode='max-autotune')\n",
        "\n",
        "# vit_base_patch16_224 batch16 maxcompile nockpt gradacc lr1e-5,1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-oKYpG8n2fBI"
      },
      "outputs": [],
      "source": [
        "# @title inception\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "# # https://pytorch.org/vision/0.12/models.html#id10\n",
        "model = models.inception_v3(pretrained=True)\n",
        "# https://discuss.pytorch.org/t/inception-v3-is-not-working-very-well/38296/16\n",
        "# https://colab.research.google.com/github/CaoCharles/Deep-Learning-with-PyTorch/blob/master/2_Inception.ipynb\n",
        "model.aux_logits = False\n",
        "num_ftrs = model.fc.in_features # 2048\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 6), # og: (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "    # nn.Linear(num_ftrs, 128), nn.ReLU(), nn.Linear(128, 6),\n",
        "    nn.Softmax(dim=1),\n",
        "    )\n",
        "# pytorch \"inception\" v3 \"gradient checkpointing\" https://github.com/jianweif/OptimalGradCheckpointing\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "model = torch.compile(model.to(device))\n",
        "# model = torch.compile(model.to(device),mode='max-autotune')\n",
        "\n",
        "# inception batch64 compile nogradacc nogradckpt lr3e-6,3e-5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEZCFg5YSS9J",
        "outputId": "6bd41d04-a4aa-4f33-8edd-6a61197b2330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 6])\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# @title try\n",
        "\n",
        "# # check model's input and output dimensions are correct\n",
        "# X = torch.rand(64, 3, 32, 32, device=device)\n",
        "X = torch.rand(16, 3, 400, 640, device=device)\n",
        "# X = torch.rand(16, 3, 224, 224, device=device)\n",
        "model.eval()\n",
        "\n",
        "# 224x224\n",
        "# 16x16 / 32x32 patch\n",
        "# -> 14x14=196 7x7=49 seq length\n",
        "# 400x640 -> 25x40=1000 seq length\n",
        "\n",
        "\n",
        "logits = model(X)\n",
        "\n",
        "# modules = [module for k, module in model._modules.items()]\n",
        "# for i,x in enumerate(modules):\n",
        "#     print(i,x)\n",
        "\n",
        "# logits = checkpoint_sequential(functions=modules, segments=1, input=X)\n",
        "\n",
        "print(logits.shape)\n",
        "# print(logits[0])\n",
        "# print(logits[0].argmax(1))\n",
        "\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(y_pred)\n",
        "del X, logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fsealXK3OPQa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "# https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/resnet_new.py\n",
        "from torch.utils.checkpoint import checkpoint, checkpoint_sequential\n",
        "\n",
        "trs=TrainTransform() # for image augmentation during train time\n",
        "# train function with automatic mixed precision\n",
        "def strain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "            x = trs(x) # image augmentation during train time to use gpu\n",
        "            # pred = model(x) # default\n",
        "            modules = [module for k, module in model._modules.items()]\n",
        "            pred = checkpoint_sequential(functions=modules, segments=1, input=x) # gradient checkpointing for resnet and inception only\n",
        "            # # pred = checkpoint_sequential(functions=model.mods, segments=1, input=x)\n",
        "            print(\"train\",pred[0])\n",
        "            print((pred.argmax(1)==y).sum().item(), pred.argmax(1).tolist(), y.tolist())\n",
        "            loss = loss_fn(pred, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        if ((batch + 1) % 4 == 0) or (batch + 1 == len(dataloader)): # gradient accumulation\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "                print(\"### lr: \", optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "        print(model.state_dict()['_orig_mod.bn1.running_mean'][0])\n",
        "        loss_list.append(loss.item())\n",
        "        # if (batch) % (size//(10* len(x))) == 0:\n",
        "        # loss, current = loss.item(), batch * len(x)\n",
        "        loss, current = loss.item()/len(y), batch * len(x)\n",
        "        if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def test(dataloader, model, loss_fn, verbose=True):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            print(pred[0])\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            print((pred.argmax(1)==y).sum().item(), pred.argmax(1).tolist(), y.tolist())\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    # should not use weighted rand sampler for test?\n",
        "    if verbose: print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
        "    return correct, test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "a5CHCIMo7ZC5"
      },
      "outputs": [],
      "source": [
        "# @title Lamb\n",
        "# https://github.com/cybertronai/pytorch-lamb/blob/master/pytorch_lamb/lamb.py\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "class Lamb(Optimizer):\n",
        "    \"\"\"Large Batch Optimization for Deep Learning: Training BERT in 76 minutes: https://arxiv.org/abs/1904.00962\n",
        "        adam (bool, optional): always use trust ratio = 1, which turns this into Adam\"\"\"\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-6, weight_decay=0, adam=False): # eps=1e-8, weight_decay=0\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.adam = adam\n",
        "        super(Lamb, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None: loss = closure() # closure (callable, optional): A closure that reevaluates the model and returns the loss.\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None: continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse: raise RuntimeError('Lamb does not support sparse gradients, consider SparseAdam instad.')\n",
        "                state = self.state[p] # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data) # Exponential moving average of gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data) # Exponential moving average of squared gradient values\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "                state['step'] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1) # m_t\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2) # v_t\n",
        "\n",
        "                # Paper v3 does not use debiasing.\n",
        "                # bias_correction1 = 1 - beta1 ** state['step']\n",
        "                # bias_correction2 = 1 - beta2 ** state['step']\n",
        "                # Apply bias to lr to avoid broadcast.\n",
        "                step_size = group['lr'] # * math.sqrt(bias_correction2) / bias_correction1\n",
        "                weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)\n",
        "                adam_step = exp_avg / exp_avg_sq.sqrt().add(group['eps'])\n",
        "                if group['weight_decay'] != 0: adam_step.add_(p.data, alpha=group['weight_decay'])\n",
        "                adam_norm = adam_step.pow(2).sum().sqrt()\n",
        "                if weight_norm == 0 or adam_norm == 0: trust_ratio = 1\n",
        "                else: trust_ratio = weight_norm / adam_norm\n",
        "                state['weight_norm'] = weight_norm\n",
        "                state['adam_norm'] = adam_norm\n",
        "                state['trust_ratio'] = trust_ratio\n",
        "                if self.adam: trust_ratio = 1\n",
        "                p.data.add_(adam_step, alpha=-step_size * trust_ratio)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iuumbm2SB_lX"
      },
      "outputs": [],
      "source": [
        "# @title LR range test\n",
        "# gives insight into good LR range to use.\n",
        "# for accurate results, be sure to use a new model for range test;\n",
        "# also reset the model before training bec range test destroys the model\n",
        "# 1cycle super convergencehttps://arxiv.org/pdf/1708.07120.pdf\n",
        "# # cyclic lr https://arxiv.org/pdf/1506.01186.pdf\n",
        "# Note the learning rate value when the accuracy starts to\n",
        "# increase and when the accuracy slows, becomes ragged, or starts to fall\n",
        "\n",
        "# one training run of the network for a few epochs\n",
        "# pth='/content/lr.pth'\n",
        "# torch.save(model.state_dict(), pth) # save temporary model for lr finding\n",
        "# model.load_state_dict(torch.load(\"lr.pth\"))\n",
        "# torch.autograd.set_detect_anomaly(True)\n",
        "epochs=1\n",
        "min_lr= 1e-6\n",
        "max_lr= 1e-1 # 1e-2\n",
        "# 152: 1e-7 - 1e-4      result 3e-7 - 3e-6\n",
        "# inception: 1e-7 - 1e1      result 3e-7 - 3e-6\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=start_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=start_lr, momentum=0.9)\n",
        "# import bitsandbytes as bnb\n",
        "# optimizer = bnb.optim.AdamW(model.parameters(), lr=min_lr, betas=(0.9, 0.999), optim_bits=8)\n",
        "optimizer = Lamb(model.parameters(), lr=min_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "\n",
        "num_batches=len(test_loader)\n",
        "# num_batches=len(train_loader)\n",
        "\n",
        "# total_steps=int(num_batches*epochs)\n",
        "total_steps=int(np.ceil(num_batches/4)*epochs) # for grad accumulation\n",
        "\n",
        "# min_lr* gamma^total_steps = max_lr\n",
        "gamma = np.exp(np.log(max_lr/min_lr)/total_steps)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # 0.75(20)-0.9(100)\n",
        "\n",
        "total_steps=total_steps*4 # for grad accumulation\n",
        "gamma = np.exp(np.log(max_lr/min_lr)/total_steps)\n",
        "lr_list=np.ones(total_steps)*min_lr*gamma**np.arange(total_steps)\n",
        "train_lst, test_lst=[],[]\n",
        "\n",
        "\n",
        "print(\"lr: \", optimizer.param_groups[0][\"lr\"])\n",
        "for i in range(epochs):\n",
        "    train_ls = strain(test_loader, model, loss_fn, optimizer, scheduler)\n",
        "    # train_ls = strain(train_loader, model, loss_fn, optimizer, scheduler)\n",
        "    train_lst.extend(train_ls)\n",
        "print(optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "# https://stackoverflow.com/a/53472966/13359815\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "train_lstsm = gaussian_filter1d(train_lst, sigma=30)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lr_list, train_lst)\n",
        "plt.plot(lr_list, train_lstsm)\n",
        "plt.xscale('log')\n",
        "# plt.plot(train_lst)\n",
        "# plt.plot(np.linspace(0,len(train_lst),len(test_lst)), test_lst)\n",
        "plt.show()\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wkBp7WjC8LLA"
      },
      "outputs": [],
      "source": [
        "# @title wwwwwwwww\n",
        "acc_lst, train_lst, test_lst=[],[],[]\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "base_lr, max_lr = 3e-7, 3e-6 # resnet\n",
        "# base_lr, max_lr = 1e-3, 1e-2 # resnet lamb\n",
        "# base_lr, max_lr = 1e-6, 1e-5 # vit\n",
        "# base_lr, max_lr = 3e-6, 3e-5 # inception\n",
        "# end_lr, start_lr = 1e-5, 1e-3 # 0.0001,0.1\n",
        "tp=0\n",
        "epochs = 5 #5 20\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr = start_lr, momentum=0.9)\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "import bitsandbytes as bnb # 8bit optimizer\n",
        "optimizer = bnb.optim.AdamW(model.parameters(), lr=base_lr, betas=(0.9, 0.999), optim_bits=8)\n",
        "# optimizer = bnb.optim.AdamW(model.parameters(), lr=3e-6, betas=(0.9, 0.999), optim_bits=8)\n",
        "# optimizer = Lamb(model.parameters(), lr=base_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "# optimizer = Lamb(model.parameters(), lr=1e-2, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "# 152 1e-5\n",
        "# cnn 3e-4\n",
        "\n",
        "div_factor = max_lr/base_lr\n",
        "num_batches=len(train_loader)\n",
        "# total_steps=int(num_batches*epochs)+1 # +1 to excluse uptick at the end of onecycle\n",
        "total_steps=int(np.ceil(num_batches/4)*epochs +1) # /4 for when using grad accumulation\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, total_steps=total_steps, pct_start=0.45, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=div_factor, final_div_factor=100.0, three_phase=True,)\n",
        "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, epochs=epochs, steps_per_epoch=num_batches, pct_start=0.45, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=div_factor, final_div_factor=10000.0, three_phase=True,)\n",
        "# gamma = np.exp(np.log(end_lr/start_lr)/(num_batches*epochs)) # for scheduler step every optimizer step\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # 0.75(20)-0.9(100)\n",
        "\n",
        "# pth='/content/res15270kg.pth'\n",
        "# pth='/content/res15270kg05aug.pth' # sps\n",
        "# pth='/content/drive/MyDrive/frame/res15236.pth' # B\n",
        "# pth='/content/drive/MyDrive/frame/res152373605aug.pth' # B\n",
        "# pth='/content/drive/MyDrive/frame/res152lamb12.pth' # sps\n",
        "# pth='/content/res152lamb12.pth' # sps\n",
        "# pth='/content/drive/MyDrive/frame/res15270kold.pth' # M\n",
        "pth='/content/drive/MyDrive/frame/res152trackf.pth' # B\n",
        "\n",
        "\n",
        "# pth='/content/vit.pth'\n",
        "# pth='/content/drive/MyDrive/frame/vit.pth'\n",
        "# pth='/content/drive/MyDrive/frame/vit3736.pth'\n",
        "# pth='/content/drive/MyDrive/frame/vit161505aug.pth' # A\n",
        "\n",
        "# pth='/content/drive/MyDrive/frame/inception1.pth'\n",
        "# pth='/content/drive/MyDrive/frame/inception363505aug.pth' # ty\n",
        "\n",
        "\n",
        "# # to continue training\n",
        "# tp, modelsd, optimsd, schedsd = torch.load(pth).values()\n",
        "# # tp, modelsd, optimsd = torch.load(pth).values()\n",
        "# model.load_state_dict(modelsd)\n",
        "# optimizer.load_state_dict(optimsd)\n",
        "# scheduler.load_state_dict(schedsd)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "REiP7-nvhc4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "65571b31-1dbf-42e1-fc30-c2cdb03d7f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title save\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# # pth='/content/drive/MyDrive/frame/vit.pth'\n",
        "# pth='/content/drive/MyDrive/frame/res55.pth'\n",
        "# pth='/content/drive/MyDrive/frame/resnet152.pth'\n",
        "# pth='/content/drive/MyDrive/frame/res152373605aug.pth'\n",
        "# pth='/content/res152373605aug.pth' # B\n",
        "# pth='/content/drive/MyDrive/frame/res152lamb12.pth' # ty\n",
        "# pth='/content/drive/MyDrive/frame/res1522.pth' # A\n",
        "# pth='/content/drive/MyDrive/frame/res1522do.pth' # A\n",
        "\n",
        "# pth='/content/drive/MyDrive/frame/inception.pth'\n",
        "# pth='/content/inception2.pth'\n",
        "\n",
        "# pth='/content/res15270kg.pth'\n",
        "\n",
        "# pth='/content/drive/MyDrive/frame/vit3736.pth'\n",
        "\n",
        "\n",
        "# tp, modelsd, optimsd, schedsd = torch.load(pth).values()\n",
        "# model.load_state_dict(modelsd)\n",
        "# # optimizer.load_state_dict(optimsd)\n",
        "# # scheduler.load_state_dict(schedsd)\n",
        "\n",
        "\n",
        "# checkpoint = { # https://discuss.pytorch.org/t/saving-model-and-optimiser-and-scheduler/52030\n",
        "# 'epoch': t+1,\n",
        "# 'model': model.state_dict(),\n",
        "# 'optimizer': optimizer.state_dict(),\n",
        "# # # 'lr_sched': scheduler.state_dict()\n",
        "# }\n",
        "# torch.save(checkpoint, pth)\n",
        "\n",
        "\n",
        "\n",
        "# pth='/content/model.pth'\n",
        "# torch.save(model.state_dict(), pth)\n",
        "# model.load_state_dict(torch.load(pth))\n",
        "# # model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# !gdown 1---4fdFbOUBTrS-VP5Va6pKowfgoU2UN -O inception2.pth\n",
        "# !gdown 1visTNvWmnuV7jAm2TBiAIIrNjbOAi1Fv -O resnet152.pth\n",
        "# !gdown 1vszqD7O9hju9-iWm4WkDPZ_adHY1j2rw -O res152373605aug.pth # A\n",
        "# !gdown 1IDQLTn6yisr47-ronpJGfEmi2-lhAcve -O res152373605aug.pth # S\n",
        "# !gdown 1-3oA1cKxgw4cfrqx079h_MKtMqRT1UFq -O res152lamb12.pth # S\n",
        "\n",
        "\n",
        "\n",
        "# # t, modelsd, optimsd, scheduler = torch.load('/content/drive/MyDrive/frame/resnet152.pth').values()\n",
        "# t, modelsd, optimsd, scheduler = torch.load('/content/resnet152.pth').values()\n",
        "# model.load_state_dict(modelsd)\n",
        "# # optimizer.load_state_dict(optimsd)\n",
        "\n",
        "# # matt152 # https://drive.google.com/file/d/1MQ0xLfHbio458uEVbn2VyMpD3bij2A4J/view?usp=sharing\n",
        "# !gdown 1MQ0xLfHbio458uEVbn2VyMpD3bij2A4J -O res152.pth\n",
        "# model.load_state_dict(torch.load(\"res152.pth\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title reset batchnorm\n",
        "# print(model.state_dict()['_orig_mod.bn1.running_mean'][0])\n",
        "\n",
        "def deactivate_batchnorm(m):\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        m.reset_parameters()\n",
        "        m.eval()\n",
        "        with torch.no_grad():\n",
        "            m.weight.fill_(1.0)\n",
        "            m.bias.zero_()\n",
        "\n",
        "# model.apply(deactivate_batchnorm)\n"
      ],
      "metadata": {
        "id": "2u8mM5kWTb5N",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDBEk-l-Oxjn",
        "outputId": "66f813fd-96a8-417a-d423-ae74a219934c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "3.000000000000001e-07\n",
            "train tensor([0.1752, 0.1661, 0.1747, 0.1680, 0.1646, 0.1515], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 1, 0, 2, 2, 2, 2, 1, 0, 4, 4, 2, 2, 2, 2] [2, 2, 3, 4, 1, 2, 4, 4, 0, 1, 3, 0, 3, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111788  [    0/61145]\n",
            "train tensor([0.1689, 0.1687, 0.1829, 0.1650, 0.1629, 0.1517], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 1, 2, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 2] [0, 2, 0, 4, 3, 1, 5, 4, 4, 2, 2, 0, 3, 4, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111931  [   16/61145]\n",
            "train tensor([0.1930, 0.1793, 0.1614, 0.1638, 0.1518, 0.1506], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2] [3, 0, 3, 2, 1, 3, 0, 2, 3, 0, 0, 3, 0, 3, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111831  [   32/61145]\n",
            "train tensor([0.1812, 0.1753, 0.1755, 0.1625, 0.1619, 0.1436], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 0, 2, 2, 0, 3, 2] [2, 2, 4, 1, 2, 3, 2, 3, 4, 4, 4, 2, 3, 1, 4, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### lr:  3.000014406044184e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111800  [   48/61145]\n",
            "train tensor([0.1763, 0.1713, 0.1701, 0.1748, 0.1567, 0.1507], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [0, 2, 3, 1, 3, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2] [2, 0, 3, 3, 0, 3, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111608  [   64/61145]\n",
            "train tensor([0.1801, 0.1570, 0.1927, 0.1683, 0.1504, 0.1515], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 1, 1, 2, 0, 2, 2, 2, 1, 1, 2, 1, 2, 2, 0] [2, 2, 0, 1, 0, 1, 0, 4, 4, 4, 1, 0, 0, 0, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111599  [   80/61145]\n",
            "train tensor([0.1761, 0.1666, 0.1702, 0.1602, 0.1682, 0.1588], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [0, 1, 0, 2, 0, 0, 2, 1, 2, 0, 3, 2, 2, 0, 1, 1] [1, 2, 2, 0, 2, 3, 2, 0, 3, 2, 1, 3, 4, 1, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111751  [   96/61145]\n",
            "train tensor([0.1855, 0.1725, 0.1562, 0.1572, 0.1600, 0.1686], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 2, 0, 0, 2, 0, 2, 2, 1, 1, 2, 1, 2, 2, 1] [4, 1, 3, 2, 0, 3, 0, 3, 3, 2, 2, 2, 1, 0, 0, 1]\n",
            "### lr:  3.000057624145998e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111719  [  112/61145]\n",
            "train tensor([0.1521, 0.1730, 0.1904, 0.1639, 0.1718, 0.1489], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 0] [0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 2, 1, 0, 4, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111909  [  128/61145]\n",
            "train tensor([0.1661, 0.1605, 0.1727, 0.1793, 0.1583, 0.1630], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [3, 0, 2, 0, 0, 2, 3, 1, 1, 2, 2, 2, 2, 3, 2, 2] [4, 3, 0, 3, 2, 2, 4, 3, 3, 0, 4, 3, 3, 4, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112062  [  144/61145]\n",
            "train tensor([0.1823, 0.1695, 0.1792, 0.1692, 0.1476, 0.1523], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 0, 2, 4, 2, 0, 4, 2, 2, 3, 2, 2, 2, 0] [0, 4, 4, 2, 0, 3, 2, 3, 3, 1, 3, 3, 0, 0, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111792  [  160/61145]\n",
            "train tensor([0.1657, 0.1680, 0.1806, 0.1695, 0.1628, 0.1535], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2] [1, 0, 2, 2, 0, 0, 1, 3, 3, 2, 3, 1, 3, 3, 3, 3]\n",
            "### lr:  3.000129654213193e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112002  [  176/61145]\n",
            "train tensor([0.1704, 0.1797, 0.1581, 0.1738, 0.1698, 0.1482], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 2, 1, 2, 0, 0, 2, 2, 1, 1, 1, 2, 2, 0, 2] [3, 2, 3, 2, 1, 4, 3, 0, 2, 2, 2, 3, 0, 2, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111602  [  192/61145]\n",
            "train tensor([0.1805, 0.1711, 0.1721, 0.1582, 0.1601, 0.1580], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 1, 2, 4, 2, 3, 2, 0, 0, 2, 2, 2, 2, 2, 0] [0, 3, 4, 4, 2, 3, 2, 0, 4, 3, 3, 2, 2, 2, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111842  [  208/61145]\n",
            "train tensor([0.1752, 0.1859, 0.1771, 0.1486, 0.1644, 0.1488], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [1, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2] [2, 2, 2, 4, 3, 4, 3, 1, 1, 0, 2, 0, 3, 1, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111507  [  224/61145]\n",
            "train tensor([0.1610, 0.1742, 0.1826, 0.1766, 0.1443, 0.1613], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2] [2, 4, 2, 3, 2, 3, 1, 1, 3, 1, 0, 4, 4, 2, 3, 0]\n",
            "### lr:  3.000230496092049e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111877  [  240/61145]\n",
            "train tensor([0.1796, 0.1565, 0.1765, 0.1640, 0.1699, 0.1536], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 2, 2, 0, 2, 2, 1, 1, 2, 2, 2, 2, 4, 2, 4, 0] [1, 2, 1, 3, 2, 2, 1, 2, 4, 2, 0, 3, 1, 2, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111558  [  256/61145]\n",
            "train tensor([0.1776, 0.1671, 0.1756, 0.1598, 0.1659, 0.1540], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 1, 2, 2, 1, 2, 2, 1, 1, 0, 0, 2, 2, 2, 4, 1] [0, 1, 4, 3, 2, 0, 4, 3, 1, 3, 3, 2, 2, 0, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111811  [  272/61145]\n",
            "train tensor([0.1665, 0.1934, 0.1679, 0.1590, 0.1594, 0.1538], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [1, 2, 0, 2, 1, 0, 2, 1, 0, 2, 2, 2, 2, 1, 1, 2] [3, 0, 3, 1, 2, 4, 2, 4, 0, 3, 1, 0, 4, 2, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111769  [  288/61145]\n",
            "train tensor([0.1727, 0.1715, 0.1774, 0.1646, 0.1575, 0.1562], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 0, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2] [3, 0, 0, 3, 2, 3, 4, 2, 1, 2, 5, 0, 4, 0, 1, 2]\n",
            "### lr:  3.000360149567344e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111655  [  304/61145]\n",
            "train tensor([0.1726, 0.1785, 0.1659, 0.1671, 0.1581, 0.1578], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [1, 2, 3, 2, 0, 2, 2, 0, 0, 2, 0, 3, 2, 2, 2, 0] [2, 0, 0, 2, 1, 2, 3, 0, 2, 0, 0, 3, 0, 0, 4, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111514  [  320/61145]\n",
            "train tensor([0.1790, 0.1720, 0.1710, 0.1590, 0.1742, 0.1448], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 0, 2, 2, 3, 0, 2, 0, 1, 2, 2, 0, 1, 2, 2, 2] [2, 2, 2, 2, 0, 4, 2, 0, 4, 0, 4, 0, 0, 0, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111628  [  336/61145]\n",
            "train tensor([0.1683, 0.1721, 0.1755, 0.1672, 0.1671, 0.1498], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 0, 2, 3, 3, 5, 2, 1, 2, 2, 3, 1, 0, 2, 3, 2] [2, 4, 2, 0, 4, 0, 2, 1, 1, 5, 3, 2, 2, 4, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111778  [  352/61145]\n",
            "train tensor([0.1870, 0.1674, 0.1775, 0.1619, 0.1520, 0.1541], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 0, 1, 4, 4, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 1] [3, 1, 3, 0, 2, 2, 4, 0, 2, 1, 0, 0, 3, 3, 0, 2]\n",
            "### lr:  3.0005186143623644e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111759  [  368/61145]\n",
            "train tensor([0.1611, 0.1660, 0.1953, 0.1671, 0.1592, 0.1513], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 3, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 0, 2] [3, 4, 2, 0, 0, 2, 1, 2, 2, 2, 4, 3, 0, 3, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111794  [  384/61145]\n",
            "train tensor([0.1620, 0.1925, 0.1796, 0.1689, 0.1565, 0.1405], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 1, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0] [0, 4, 0, 2, 4, 3, 2, 4, 2, 4, 1, 3, 2, 2, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111845  [  400/61145]\n",
            "train tensor([0.1687, 0.1707, 0.1769, 0.1720, 0.1623, 0.1495], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2] [4, 3, 2, 3, 2, 0, 3, 2, 2, 2, 5, 3, 3, 0, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111835  [  416/61145]\n",
            "train tensor([0.1784, 0.1728, 0.1694, 0.1588, 0.1619, 0.1588], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 2, 0, 2, 1, 2, 1, 2, 2, 2, 4, 3, 2, 1, 1] [2, 2, 0, 4, 0, 5, 4, 1, 3, 2, 1, 4, 3, 4, 0, 3]\n",
            "### lr:  3.00070589013892e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111942  [  432/61145]\n",
            "train tensor([0.1758, 0.1656, 0.1791, 0.1613, 0.1606, 0.1576], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 0, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 3, 0] [2, 0, 0, 3, 2, 3, 3, 2, 2, 1, 2, 0, 2, 3, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111510  [  448/61145]\n",
            "train tensor([0.1723, 0.1614, 0.1775, 0.1608, 0.1804, 0.1477], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [4, 4, 0, 1, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2] [0, 0, 2, 4, 0, 4, 0, 0, 0, 2, 3, 0, 1, 0, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111857  [  464/61145]\n",
            "train tensor([0.1687, 0.1665, 0.1803, 0.1725, 0.1596, 0.1522], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 0, 3, 2, 3, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2] [2, 1, 1, 2, 3, 3, 2, 2, 4, 4, 2, 0, 0, 2, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111412  [  480/61145]\n",
            "train tensor([0.1692, 0.1627, 0.1944, 0.1733, 0.1440, 0.1565], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 1, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, 0, 2] [2, 2, 1, 0, 0, 1, 3, 2, 3, 3, 4, 3, 2, 3, 3, 0]\n",
            "### lr:  3.000921976497309e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111641  [  496/61145]\n",
            "train tensor([0.1737, 0.1707, 0.1791, 0.1631, 0.1657, 0.1478], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 0, 2, 2] [0, 3, 3, 3, 5, 0, 0, 0, 2, 3, 2, 0, 3, 0, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111751  [  512/61145]\n",
            "train tensor([0.1614, 0.1895, 0.1779, 0.1519, 0.1618, 0.1575], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [1, 2, 1, 2, 2, 0, 2, 2, 2, 4, 1, 2, 0, 2, 2, 2] [0, 0, 3, 2, 1, 4, 0, 3, 1, 0, 4, 3, 1, 1, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111925  [  528/61145]\n",
            "train tensor([0.1681, 0.1762, 0.1766, 0.1683, 0.1613, 0.1494], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 1, 2, 1, 2, 0, 2, 1, 0, 2, 2, 2, 0, 2, 2] [2, 3, 4, 3, 0, 3, 3, 0, 2, 1, 0, 2, 0, 4, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111926  [  544/61145]\n",
            "train tensor([0.1699, 0.1698, 0.1698, 0.1693, 0.1683, 0.1529], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 0, 0, 4, 2, 3, 0, 2, 2, 1, 1, 1, 0, 2] [2, 0, 4, 3, 2, 3, 3, 4, 3, 3, 2, 4, 1, 2, 3, 2]\n",
            "### lr:  3.0011668729763675e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111954  [  560/61145]\n",
            "train tensor([0.1704, 0.1679, 0.1718, 0.1665, 0.1608, 0.1626], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 1, 2, 2, 2, 2, 2, 4, 0, 2, 1, 2, 1, 2, 2, 2] [2, 0, 3, 3, 0, 3, 2, 0, 0, 3, 2, 0, 1, 2, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111846  [  576/61145]\n",
            "train tensor([0.1673, 0.1785, 0.1879, 0.1590, 0.1620, 0.1453], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 1, 2, 2, 0, 2, 2, 0, 1, 1, 3, 0, 3, 2, 2] [5, 2, 2, 3, 1, 4, 2, 1, 0, 3, 4, 0, 0, 3, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111729  [  592/61145]\n",
            "train tensor([0.1576, 0.1704, 0.1911, 0.1727, 0.1597, 0.1485], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 2, 2, 1, 2, 2, 0, 3, 0, 2, 2, 3, 2, 0] [3, 3, 2, 2, 4, 0, 2, 3, 0, 4, 0, 1, 4, 4, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111798  [  608/61145]\n",
            "train tensor([0.1851, 0.1685, 0.1825, 0.1644, 0.1516, 0.1478], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 2, 1, 4, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2] [4, 1, 1, 0, 2, 4, 0, 0, 3, 1, 0, 2, 1, 4, 3, 3]\n",
            "### lr:  3.0014405790534136e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112026  [  624/61145]\n",
            "train tensor([0.1769, 0.1609, 0.1872, 0.1667, 0.1450, 0.1634], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 1, 0, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 0, 0] [2, 0, 2, 0, 0, 0, 3, 1, 2, 2, 1, 0, 4, 4, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111462  [  640/61145]\n",
            "train tensor([0.1782, 0.1762, 0.1699, 0.1600, 0.1750, 0.1406], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 1, 1, 2, 4, 1, 1, 0, 2, 1, 2, 2, 2, 0, 0, 2] [2, 0, 2, 4, 2, 2, 2, 2, 2, 2, 3, 0, 0, 2, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111641  [  656/61145]\n",
            "train tensor([0.1648, 0.1719, 0.1882, 0.1822, 0.1504, 0.1424], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 1, 1, 2, 2, 0, 2, 2, 2, 2, 4, 0, 0, 2, 2] [1, 0, 4, 3, 3, 3, 2, 3, 4, 4, 4, 4, 1, 2, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112101  [  672/61145]\n",
            "train tensor([0.1625, 0.1682, 0.1781, 0.1612, 0.1637, 0.1664], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2] [2, 4, 0, 0, 3, 0, 2, 4, 2, 0, 4, 2, 0, 2, 4, 2]\n",
            "### lr:  3.0017430941443076e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111667  [  688/61145]\n",
            "train tensor([0.1805, 0.1687, 0.1787, 0.1608, 0.1663, 0.1450], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 2, 2, 2, 1, 2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2] [2, 3, 1, 4, 2, 3, 3, 2, 0, 3, 4, 2, 4, 0, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111937  [  704/61145]\n",
            "train tensor([0.1650, 0.1681, 0.1725, 0.1665, 0.1713, 0.1566], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 0, 2, 2, 1, 2, 4, 2, 2, 2, 3, 2, 0, 0, 2] [4, 0, 3, 2, 0, 2, 2, 1, 3, 1, 2, 2, 3, 0, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111804  [  720/61145]\n",
            "train tensor([0.1664, 0.1849, 0.1721, 0.1588, 0.1684, 0.1495], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [1, 0, 2, 2, 2, 2, 3, 3, 1, 1, 2, 0, 0, 1, 2, 2] [3, 0, 3, 2, 2, 4, 4, 4, 2, 1, 2, 1, 3, 0, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111712  [  736/61145]\n",
            "train tensor([0.1521, 0.1705, 0.2089, 0.1777, 0.1386, 0.1521], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 1, 0, 0, 2] [2, 4, 0, 4, 4, 3, 4, 2, 3, 3, 0, 4, 4, 2, 2, 2]\n",
            "### lr:  3.0020744176034155e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111786  [  752/61145]\n",
            "train tensor([0.1661, 0.1735, 0.2003, 0.1645, 0.1473, 0.1484], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 1, 2, 2, 0, 2, 0, 0, 2, 1, 2, 3, 2, 2, 2, 1] [1, 2, 3, 2, 0, 2, 0, 2, 3, 2, 2, 0, 3, 3, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111578  [  768/61145]\n",
            "train tensor([0.1649, 0.1756, 0.1858, 0.1579, 0.1661, 0.1496], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 1, 2, 2, 4, 2, 2, 2, 2, 3, 1, 2, 2, 2, 0, 2] [3, 4, 2, 2, 0, 2, 0, 0, 0, 4, 1, 3, 2, 0, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111697  [  784/61145]\n",
            "train tensor([0.1735, 0.1716, 0.1656, 0.1644, 0.1728, 0.1521], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 0, 1, 2, 2, 0, 1, 1, 2, 0, 0, 2, 2, 0, 0, 2] [2, 0, 2, 2, 4, 2, 2, 2, 3, 5, 0, 3, 2, 3, 1, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111579  [  800/61145]\n",
            "train tensor([0.1694, 0.1744, 0.1796, 0.1643, 0.1751, 0.1372], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 2, 2, 1, 2, 0, 0, 2, 1, 2, 2, 2, 1] [0, 0, 2, 3, 3, 3, 0, 2, 2, 3, 2, 3, 0, 3, 2, 0]\n",
            "### lr:  3.002434548723605e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111794  [  816/61145]\n",
            "train tensor([0.1619, 0.1634, 0.1925, 0.1522, 0.1721, 0.1579], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 0, 0, 3, 2, 2, 2, 2, 2, 2, 3, 2, 0, 1, 1, 2] [4, 4, 2, 1, 3, 1, 4, 4, 2, 4, 1, 3, 1, 0, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111824  [  832/61145]\n",
            "train tensor([0.1695, 0.1690, 0.1810, 0.1565, 0.1718, 0.1522], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 0, 2, 5, 2, 2, 2, 0, 2, 2, 1, 1, 2, 2, 1, 1] [1, 3, 1, 4, 3, 4, 0, 4, 0, 3, 2, 2, 4, 2, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112055  [  848/61145]\n",
            "train tensor([0.1588, 0.1748, 0.1858, 0.1632, 0.1572, 0.1601], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0, 2, 1] [1, 1, 2, 3, 4, 3, 1, 1, 3, 1, 2, 3, 2, 1, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111786  [  864/61145]\n",
            "train tensor([0.1637, 0.1588, 0.1813, 0.1681, 0.1678, 0.1603], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 1, 2, 4, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1] [2, 3, 4, 4, 1, 2, 4, 2, 0, 0, 2, 2, 3, 2, 2, 3]\n",
            "### lr:  3.002823486736286e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111893  [  880/61145]\n",
            "train tensor([0.1757, 0.1711, 0.1797, 0.1618, 0.1694, 0.1423], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2] [0, 1, 0, 0, 3, 0, 3, 4, 3, 2, 3, 4, 2, 2, 4, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111779  [  896/61145]\n",
            "train tensor([0.1612, 0.1629, 0.1765, 0.1737, 0.1657, 0.1600], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 1, 2, 1, 2, 2, 2, 0, 2, 0, 2, 1, 2, 1, 2, 1] [3, 0, 2, 3, 5, 3, 4, 0, 2, 3, 1, 0, 4, 2, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111797  [  912/61145]\n",
            "train tensor([0.1716, 0.1746, 0.1724, 0.1739, 0.1567, 0.1509], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 0] [0, 0, 0, 0, 3, 4, 2, 0, 3, 4, 0, 2, 0, 2, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111822  [  928/61145]\n",
            "train tensor([0.1608, 0.1775, 0.1791, 0.1633, 0.1643, 0.1550], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 1, 2, 2, 1, 3, 2, 1, 2, 1, 0, 0, 2, 0, 2] [2, 4, 2, 3, 0, 0, 3, 2, 4, 3, 1, 2, 0, 1, 1, 2]\n",
            "### lr:  3.0032412308113713e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111645  [  944/61145]\n",
            "train tensor([0.1708, 0.1798, 0.1734, 0.1660, 0.1578, 0.1523], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [1, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2, 2] [2, 4, 4, 5, 2, 0, 3, 3, 4, 2, 4, 2, 4, 2, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111967  [  960/61145]\n",
            "train tensor([0.1704, 0.1692, 0.1859, 0.1685, 0.1587, 0.1474], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 1, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2] [3, 4, 2, 0, 2, 0, 1, 5, 2, 4, 4, 4, 4, 1, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112062  [  976/61145]\n",
            "train tensor([0.1568, 0.1897, 0.1642, 0.1667, 0.1726, 0.1500], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [1, 2, 2, 1, 2, 0, 1, 2, 1, 2, 4, 2, 0, 0, 2, 2] [2, 3, 4, 4, 0, 1, 0, 0, 0, 0, 4, 0, 4, 4, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111935  [  992/61145]\n",
            "train tensor([0.1726, 0.1670, 0.1886, 0.1659, 0.1486, 0.1574], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 0, 0, 0, 2, 1, 2, 2, 2, 1, 1, 2] [2, 2, 5, 4, 0, 2, 3, 0, 2, 0, 1, 2, 1, 4, 3, 4]\n",
            "### lr:  3.003687780057295e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111849  [ 1008/61145]\n",
            "train tensor([0.1791, 0.1670, 0.1846, 0.1607, 0.1606, 0.1480], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 3, 1, 2, 0, 2, 2, 2, 0, 2, 2, 2] [0, 2, 0, 0, 4, 4, 2, 2, 4, 2, 3, 2, 2, 0, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111358  [ 1024/61145]\n",
            "train tensor([0.1728, 0.1741, 0.1784, 0.1637, 0.1699, 0.1411], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 2, 2, 0, 4, 0, 0, 2, 0, 1, 2] [0, 1, 2, 2, 1, 3, 4, 3, 1, 4, 1, 4, 2, 3, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111774  [ 1040/61145]\n",
            "train tensor([0.1795, 0.1559, 0.1798, 0.1672, 0.1675, 0.1501], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2] [0, 0, 1, 4, 2, 4, 2, 3, 3, 3, 2, 4, 4, 3, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111760  [ 1056/61145]\n",
            "train tensor([0.1806, 0.1683, 0.1751, 0.1738, 0.1487, 0.1536], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 4, 0, 0, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2] [0, 1, 1, 2, 0, 1, 0, 2, 3, 0, 1, 2, 2, 2, 0, 1]\n",
            "### lr:  3.004163133521026e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111611  [ 1072/61145]\n",
            "train tensor([0.1643, 0.1681, 0.1840, 0.1790, 0.1601, 0.1445], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 0, 0, 2, 2, 2, 2, 0, 1, 2, 1, 2, 2, 0, 2] [4, 0, 0, 2, 0, 4, 3, 1, 0, 3, 3, 4, 4, 2, 4, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111925  [ 1088/61145]\n",
            "train tensor([0.1602, 0.1913, 0.1743, 0.1635, 0.1628, 0.1479], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 2, 0, 2, 1, 1, 2, 2, 1, 2, 0, 4, 2, 0, 1, 0] [3, 4, 3, 2, 2, 0, 0, 4, 1, 2, 1, 0, 0, 2, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111723  [ 1104/61145]\n",
            "train tensor([0.1761, 0.1705, 0.1850, 0.1602, 0.1704, 0.1378], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 0, 1, 2] [1, 0, 4, 0, 0, 3, 0, 3, 0, 3, 0, 0, 2, 0, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111932  [ 1120/61145]\n",
            "train tensor([0.1653, 0.1688, 0.1837, 0.1689, 0.1571, 0.1561], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 4, 2, 4, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2] [2, 1, 4, 1, 0, 4, 4, 2, 0, 0, 3, 1, 0, 2, 0, 1]\n",
            "### lr:  3.004667290188044e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111882  [ 1136/61145]\n",
            "train tensor([0.1781, 0.1778, 0.1815, 0.1488, 0.1571, 0.1566], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 0, 3, 0, 2, 2, 2, 2, 2, 1, 2, 0, 4] [2, 4, 2, 3, 0, 2, 0, 2, 2, 0, 2, 3, 0, 0, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111553  [ 1152/61145]\n",
            "train tensor([0.1683, 0.1697, 0.1798, 0.1729, 0.1522, 0.1570], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 1, 2, 2, 3, 2, 2, 2, 0, 1, 1, 2, 3, 0] [4, 2, 2, 2, 2, 0, 1, 3, 2, 0, 2, 0, 2, 2, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111661  [ 1168/61145]\n",
            "train tensor([0.1847, 0.1664, 0.1716, 0.1587, 0.1691, 0.1495], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2] [0, 1, 0, 4, 1, 3, 4, 2, 0, 3, 0, 3, 3, 4, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111912  [ 1184/61145]\n",
            "train tensor([0.1640, 0.1883, 0.1624, 0.1652, 0.1585, 0.1617], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 1, 4, 1, 3, 1, 2, 2, 4, 1, 2, 0, 2, 4, 0] [1, 0, 2, 2, 4, 2, 0, 2, 2, 3, 4, 3, 1, 0, 2, 2]\n",
            "### lr:  3.0052002489823707e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111752  [ 1200/61145]\n",
            "train tensor([0.1865, 0.1859, 0.1704, 0.1581, 0.1516, 0.1475], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 4, 2] [3, 3, 0, 0, 2, 3, 3, 2, 1, 0, 0, 3, 2, 1, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111795  [ 1216/61145]\n",
            "train tensor([0.1731, 0.1703, 0.1988, 0.1542, 0.1559, 0.1478], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0] [0, 2, 2, 4, 2, 4, 3, 3, 4, 1, 3, 0, 0, 3, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111878  [ 1232/61145]\n",
            "train tensor([0.1695, 0.1900, 0.1633, 0.1581, 0.1691, 0.1499], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 2, 2, 2, 2, 1, 1, 2, 2, 0, 2, 4, 1, 0, 2, 2] [4, 2, 0, 0, 1, 1, 2, 4, 2, 2, 3, 0, 2, 0, 1, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111762  [ 1248/61145]\n",
            "train tensor([0.1728, 0.1767, 0.1730, 0.1637, 0.1602, 0.1535], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [1, 1, 2, 2, 2, 1, 2, 3, 0, 0, 0, 1, 2, 1, 1, 2] [2, 1, 3, 2, 0, 0, 0, 3, 2, 0, 4, 2, 2, 2, 3, 2]\n",
            "### lr:  3.005762008766543e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111413  [ 1264/61145]\n",
            "train tensor([0.1642, 0.1649, 0.2057, 0.1637, 0.1529, 0.1486], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 0, 2, 2, 2, 0, 1, 0, 2, 0, 1, 0, 2, 1, 2] [3, 1, 0, 2, 3, 2, 3, 4, 0, 2, 0, 4, 1, 1, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111707  [ 1280/61145]\n",
            "train tensor([0.1704, 0.1805, 0.1792, 0.1596, 0.1675, 0.1428], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 3, 2, 1, 0, 2, 0, 1, 4, 1, 1, 1, 2, 1, 0] [2, 2, 1, 3, 3, 1, 0, 1, 3, 0, 0, 3, 2, 2, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111728  [ 1296/61145]\n",
            "train tensor([0.1606, 0.1647, 0.1624, 0.1768, 0.1666, 0.1690], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [3, 1, 0, 3, 2, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 1] [0, 0, 1, 0, 2, 1, 3, 3, 0, 2, 4, 2, 4, 3, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111886  [ 1312/61145]\n",
            "train tensor([0.1709, 0.1820, 0.1771, 0.1693, 0.1421, 0.1585], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 1, 2] [1, 3, 2, 0, 4, 0, 0, 3, 3, 3, 2, 1, 1, 0, 2, 1]\n",
            "### lr:  3.006352568341645e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111739  [ 1328/61145]\n",
            "train tensor([0.1871, 0.1739, 0.1867, 0.1531, 0.1530, 0.1461], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 2, 2, 0, 0, 0] [3, 4, 2, 0, 0, 0, 0, 3, 4, 2, 4, 4, 2, 0, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111822  [ 1344/61145]\n",
            "train tensor([0.1863, 0.1711, 0.1724, 0.1493, 0.1745, 0.1465], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 0, 3, 2, 2, 2, 1, 3, 1, 2, 2, 2, 1, 1, 2, 0] [3, 2, 1, 3, 1, 1, 3, 4, 0, 2, 0, 1, 4, 2, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111905  [ 1360/61145]\n",
            "train tensor([0.1740, 0.1662, 0.1751, 0.1615, 0.1789, 0.1442], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [4, 4, 2, 2, 1, 1, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2] [2, 4, 2, 1, 0, 0, 3, 4, 0, 4, 0, 3, 2, 0, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111780  [ 1376/61145]\n",
            "train tensor([0.1758, 0.1716, 0.1810, 0.1666, 0.1658, 0.1391], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 4, 0, 2, 1, 2, 3, 2, 2, 3, 2, 2, 1, 0] [2, 0, 1, 2, 0, 0, 3, 3, 3, 4, 0, 3, 2, 2, 1, 2]\n",
            "### lr:  3.0069719264472836e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111558  [ 1392/61145]\n",
            "train tensor([0.1539, 0.1626, 0.2075, 0.1723, 0.1481, 0.1556], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 0, 0, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2] [3, 0, 3, 2, 0, 2, 3, 1, 3, 0, 3, 0, 4, 1, 4, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111960  [ 1408/61145]\n",
            "train tensor([0.1766, 0.1742, 0.1680, 0.1727, 0.1668, 0.1417], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [0, 0, 2, 1, 3, 4, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1] [4, 1, 2, 4, 4, 4, 2, 1, 0, 2, 2, 1, 1, 2, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111521  [ 1424/61145]\n",
            "train tensor([0.1637, 0.1628, 0.2020, 0.1609, 0.1700, 0.1406], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 0, 2, 2] [4, 0, 2, 4, 0, 4, 0, 2, 1, 1, 3, 0, 2, 3, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111758  [ 1440/61145]\n",
            "train tensor([0.1701, 0.1605, 0.1866, 0.1725, 0.1583, 0.1520], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 0] [1, 4, 2, 4, 2, 1, 1, 3, 2, 2, 4, 3, 0, 2, 0, 0]\n",
            "### lr:  3.007620081761604e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111702  [ 1456/61145]\n",
            "train tensor([0.1667, 0.1768, 0.1806, 0.1581, 0.1663, 0.1514], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 1, 0, 0, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2] [2, 0, 4, 2, 2, 2, 4, 3, 4, 0, 0, 3, 2, 4, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111650  [ 1472/61145]\n",
            "train tensor([0.1757, 0.1710, 0.1704, 0.1628, 0.1731, 0.1470], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 2, 2, 2, 4, 2, 2, 2, 3, 2, 1, 1, 2, 1, 0, 2] [2, 2, 2, 3, 2, 4, 0, 1, 3, 2, 3, 1, 4, 2, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111623  [ 1488/61145]\n",
            "train tensor([0.1719, 0.1564, 0.1868, 0.1586, 0.1702, 0.1561], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 0, 0, 0, 2, 2, 1, 0, 2, 2, 0, 2, 2, 0, 0, 2] [2, 2, 1, 0, 0, 3, 0, 1, 2, 0, 2, 1, 3, 2, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111654  [ 1504/61145]\n",
            "train tensor([0.1841, 0.1544, 0.1998, 0.1679, 0.1497, 0.1441], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0] [2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 0, 2, 4, 4, 2, 1]\n",
            "### lr:  3.0082970329012997e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111528  [ 1520/61145]\n",
            "train tensor([0.1663, 0.1678, 0.1862, 0.1666, 0.1640, 0.1492], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 4, 2, 3, 1] [3, 3, 2, 2, 0, 0, 1, 2, 2, 3, 3, 0, 4, 0, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111543  [ 1536/61145]\n",
            "train tensor([0.1847, 0.1655, 0.1938, 0.1566, 0.1576, 0.1417], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 1, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 4, 2] [3, 4, 2, 0, 1, 3, 1, 1, 3, 2, 2, 2, 4, 0, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111704  [ 1552/61145]\n",
            "train tensor([0.1725, 0.1612, 0.1812, 0.1694, 0.1624, 0.1534], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 0, 2, 0, 3, 2, 2, 2, 0, 2, 0, 2, 0, 1, 2] [2, 0, 1, 1, 3, 0, 0, 1, 1, 2, 1, 3, 2, 4, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111857  [ 1568/61145]\n",
            "train tensor([0.1618, 0.1735, 0.1927, 0.1608, 0.1555, 0.1558], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 1, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 1, 2, 0] [4, 1, 2, 2, 4, 4, 2, 1, 1, 3, 0, 2, 3, 0, 3, 2]\n",
            "### lr:  3.0090027784215954e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111654  [ 1584/61145]\n",
            "train tensor([0.1836, 0.1818, 0.1799, 0.1553, 0.1629, 0.1365], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 1, 2, 0, 0, 2, 2, 0, 0, 3, 2, 1, 2, 4, 2, 2] [1, 2, 0, 0, 3, 3, 4, 3, 2, 3, 2, 2, 1, 2, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111419  [ 1600/61145]\n",
            "train tensor([0.1751, 0.1643, 0.1745, 0.1715, 0.1637, 0.1510], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 2, 0, 0, 1, 2, 1, 3, 0, 4, 2, 2, 2, 2, 2, 2] [1, 2, 0, 4, 4, 3, 1, 3, 3, 2, 0, 3, 0, 2, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111669  [ 1616/61145]\n",
            "train tensor([0.1695, 0.1549, 0.1785, 0.1843, 0.1578, 0.1550], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [3, 0, 3, 2, 2, 1, 2, 2, 4, 2, 2, 2, 2, 1, 2, 2] [4, 1, 3, 0, 2, 4, 2, 4, 0, 3, 2, 3, 2, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111507  [ 1632/61145]\n",
            "train tensor([0.1856, 0.1705, 0.1961, 0.1575, 0.1508, 0.1396], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 0, 0, 0, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0] [4, 2, 0, 4, 0, 3, 1, 3, 1, 4, 3, 4, 2, 0, 2, 2]\n",
            "### lr:  3.00973731681628e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111649  [ 1648/61145]\n",
            "train tensor([0.1881, 0.1634, 0.1825, 0.1629, 0.1596, 0.1436], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 2, 2, 0, 3, 2, 1, 2, 2, 2, 2, 2, 2, 2] [3, 0, 3, 2, 3, 1, 4, 0, 4, 0, 2, 1, 2, 0, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112084  [ 1664/61145]\n",
            "train tensor([0.1596, 0.1810, 0.1919, 0.1638, 0.1479, 0.1560], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 1, 2, 3, 2, 2, 2] [2, 3, 2, 2, 0, 2, 1, 0, 0, 0, 4, 0, 3, 4, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111765  [ 1680/61145]\n",
            "train tensor([0.1610, 0.1787, 0.1808, 0.1603, 0.1681, 0.1512], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 1, 4, 3, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1] [2, 2, 3, 2, 4, 4, 3, 4, 0, 2, 1, 2, 2, 2, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111650  [ 1696/61145]\n",
            "train tensor([0.1680, 0.1832, 0.1872, 0.1499, 0.1533, 0.1584], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 1, 2, 2, 0, 4, 2, 2, 2, 4, 2, 1, 1, 2, 0, 0] [2, 1, 3, 4, 2, 3, 0, 3, 2, 4, 2, 3, 0, 2, 3, 2]\n",
            "### lr:  3.0105006465176653e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111632  [ 1712/61145]\n",
            "train tensor([0.1637, 0.1890, 0.1866, 0.1681, 0.1456, 0.1471], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2] [0, 2, 2, 2, 1, 0, 2, 3, 2, 2, 1, 3, 0, 3, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111698  [ 1728/61145]\n",
            "train tensor([0.1683, 0.1837, 0.1785, 0.1702, 0.1539, 0.1454], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [1, 0, 2, 0, 2, 1, 1, 1, 2, 0, 2, 2, 0, 2, 1, 0] [4, 0, 2, 0, 4, 0, 0, 1, 2, 0, 3, 4, 1, 3, 4, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111921  [ 1744/61145]\n",
            "train tensor([0.1702, 0.1683, 0.1777, 0.1677, 0.1614, 0.1547], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 4, 0, 2, 2, 4, 2, 2, 2, 2, 2, 1, 2, 2, 0] [4, 1, 0, 2, 3, 4, 0, 4, 1, 3, 2, 4, 4, 1, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112060  [ 1760/61145]\n",
            "train tensor([0.1700, 0.1645, 0.1726, 0.1712, 0.1683, 0.1534], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2] [0, 2, 2, 1, 2, 3, 3, 0, 3, 0, 3, 0, 0, 4, 3, 4]\n",
            "### lr:  3.011292765896648e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111891  [ 1776/61145]\n",
            "train tensor([0.1747, 0.1711, 0.1832, 0.1778, 0.1399, 0.1535], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 0, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 2, 0, 2, 2] [4, 2, 0, 3, 0, 3, 4, 2, 2, 1, 0, 3, 2, 2, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111956  [ 1792/61145]\n",
            "train tensor([0.1674, 0.1802, 0.1766, 0.1602, 0.1695, 0.1461], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [1, 2, 0, 3, 1, 1, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2] [2, 2, 4, 1, 4, 2, 0, 1, 2, 3, 2, 4, 2, 3, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111743  [ 1808/61145]\n",
            "train tensor([0.1776, 0.1735, 0.1764, 0.1620, 0.1605, 0.1500], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 1, 2, 2, 2, 1, 4, 2, 2, 1, 3, 1, 1, 2, 0, 2] [2, 3, 4, 4, 0, 3, 1, 1, 4, 1, 4, 3, 2, 1, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111799  [ 1824/61145]\n",
            "train tensor([0.1734, 0.1801, 0.1768, 0.1551, 0.1627, 0.1518], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [1, 1, 2, 0, 0, 2, 2, 3, 1, 2, 2, 0, 2, 0, 2, 0] [3, 5, 1, 0, 2, 1, 3, 3, 2, 4, 2, 2, 2, 0, 4, 0]\n",
            "### lr:  3.0121136732626483e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111698  [ 1840/61145]\n",
            "train tensor([0.1730, 0.1618, 0.1788, 0.1686, 0.1673, 0.1505], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 2, 1, 1] [0, 0, 3, 0, 1, 4, 0, 3, 2, 3, 0, 3, 1, 0, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111662  [ 1856/61145]\n",
            "train tensor([0.1712, 0.1775, 0.1700, 0.1603, 0.1747, 0.1463], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 2, 2, 3, 0, 4, 1, 3, 1, 2, 3, 2, 2, 2, 0] [1, 3, 0, 1, 0, 0, 2, 3, 2, 2, 0, 3, 4, 0, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111624  [ 1872/61145]\n",
            "train tensor([0.1575, 0.1609, 0.1954, 0.1780, 0.1496, 0.1586], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 0, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 1] [2, 0, 1, 0, 1, 0, 1, 2, 3, 2, 0, 4, 1, 0, 4, 5]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111702  [ 1888/61145]\n",
            "train tensor([0.1583, 0.1661, 0.1969, 0.1679, 0.1573, 0.1535], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 0, 2, 1, 0, 2, 3, 1, 0, 2, 2, 1, 2, 2] [0, 3, 2, 3, 4, 0, 2, 2, 3, 2, 2, 2, 0, 0, 2, 0]\n",
            "### lr:  3.012963366863667e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111461  [ 1904/61145]\n",
            "train tensor([0.1699, 0.1688, 0.1826, 0.1652, 0.1598, 0.1538], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 0, 2, 1, 3, 2, 2, 2, 2, 2, 0, 1, 1, 2, 1, 2] [2, 2, 0, 4, 0, 0, 0, 2, 3, 0, 4, 3, 2, 2, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111885  [ 1920/61145]\n",
            "train tensor([0.1578, 0.1776, 0.1692, 0.1893, 0.1574, 0.1486], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [3, 2, 2, 2, 1, 1, 1, 2, 3, 0, 2, 0, 2, 0, 0, 2] [4, 1, 2, 2, 3, 1, 2, 4, 3, 2, 2, 4, 3, 0, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111756  [ 1936/61145]\n",
            "train tensor([0.1735, 0.1681, 0.1900, 0.1564, 0.1739, 0.1381], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 4, 2, 0, 2, 1, 2, 2, 1, 1, 3, 2, 0, 0] [3, 3, 2, 4, 2, 2, 2, 4, 0, 2, 3, 3, 1, 4, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111381  [ 1952/61145]\n",
            "train tensor([0.1730, 0.1782, 0.1672, 0.1734, 0.1571, 0.1512], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2] [0, 4, 0, 3, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 1, 4]\n",
            "### lr:  3.0138418448862705e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111653  [ 1968/61145]\n",
            "train tensor([0.1746, 0.1684, 0.1839, 0.1560, 0.1710, 0.1461], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 3, 3, 1, 4, 0, 2, 1, 2, 1, 2, 3, 2, 1, 2, 2] [2, 0, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 1, 2, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111590  [ 1984/61145]\n",
            "train tensor([0.1523, 0.1641, 0.1943, 0.1716, 0.1617, 0.1560], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 0, 0, 2, 1] [0, 0, 2, 4, 2, 0, 4, 4, 3, 2, 2, 3, 0, 1, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111820  [ 2000/61145]\n",
            "train tensor([0.1775, 0.1692, 0.1908, 0.1566, 0.1646, 0.1413], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 1] [0, 0, 0, 2, 3, 3, 3, 3, 2, 2, 3, 2, 1, 2, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111400  [ 2016/61145]\n",
            "train tensor([0.1715, 0.1697, 0.1715, 0.1791, 0.1626, 0.1456], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [3, 2, 2, 1, 2, 2, 0, 1, 2, 2, 4, 2, 1, 3, 0, 2] [0, 2, 2, 2, 3, 4, 3, 4, 3, 1, 4, 3, 2, 0, 3, 0]\n",
            "### lr:  3.014749105455581e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111913  [ 2032/61145]\n",
            "train tensor([0.1490, 0.1666, 0.1920, 0.1765, 0.1563, 0.1596], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 3, 0, 2, 0, 2, 3, 3, 2, 2, 2, 2] [0, 0, 0, 4, 2, 0, 3, 1, 0, 0, 1, 2, 0, 1, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111734  [ 2048/61145]\n",
            "train tensor([0.1660, 0.1763, 0.1804, 0.1714, 0.1722, 0.1337], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 2, 2, 2, 2, 0, 2, 2, 3, 2, 2, 2, 2, 2, 2] [3, 2, 3, 3, 3, 3, 2, 0, 3, 3, 2, 2, 0, 3, 4, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111640  [ 2064/61145]\n",
            "train tensor([0.1630, 0.1637, 0.1917, 0.1888, 0.1473, 0.1455], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 2] [3, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 3, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111482  [ 2080/61145]\n",
            "train tensor([0.1700, 0.1601, 0.1876, 0.1679, 0.1677, 0.1467], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 4, 2, 4, 3, 2, 1, 0, 3, 3, 1, 4, 0, 2, 2, 4]\n",
            "### lr:  3.0156851466352975e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111998  [ 2096/61145]\n",
            "train tensor([0.1677, 0.1675, 0.1860, 0.1663, 0.1571, 0.1555], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 0, 2, 1, 2, 2, 4, 1, 2, 2, 2, 2, 4, 2, 0, 0] [3, 3, 0, 3, 4, 3, 0, 3, 2, 3, 0, 4, 2, 3, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112170  [ 2112/61145]\n",
            "train tensor([0.1602, 0.1760, 0.1787, 0.1703, 0.1587, 0.1561], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 0, 1, 2, 2, 2, 4, 3, 2, 2, 2, 2, 2, 2] [4, 2, 5, 3, 2, 1, 2, 3, 0, 2, 1, 3, 2, 4, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111913  [ 2128/61145]\n",
            "train tensor([0.1820, 0.1704, 0.1812, 0.1575, 0.1597, 0.1492], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 2, 0, 2, 2, 2, 3, 4, 2, 1, 1, 0, 1, 2, 1] [3, 0, 2, 0, 3, 1, 3, 0, 0, 0, 4, 3, 0, 1, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111623  [ 2144/61145]\n",
            "train tensor([0.1767, 0.1701, 0.1653, 0.1696, 0.1652, 0.1532], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 0, 2, 2, 1, 2, 0, 1, 1, 0, 0, 2, 1, 2, 1, 2] [0, 2, 2, 3, 2, 2, 4, 4, 3, 2, 4, 4, 0, 3, 0, 0]\n",
            "### lr:  3.016649966427689e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111879  [ 2160/61145]\n",
            "train tensor([0.1761, 0.1592, 0.1967, 0.1605, 0.1508, 0.1567], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2] [1, 0, 2, 4, 0, 2, 0, 1, 0, 0, 1, 2, 3, 1, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111587  [ 2176/61145]\n",
            "train tensor([0.1928, 0.1680, 0.1814, 0.1431, 0.1630, 0.1518], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 0, 2, 2, 1, 0, 3, 2, 4, 0, 0, 0, 2, 2, 0, 2] [2, 2, 2, 3, 0, 2, 1, 2, 3, 3, 3, 3, 4, 4, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111865  [ 2192/61145]\n",
            "train tensor([0.1625, 0.1715, 0.1748, 0.1697, 0.1664, 0.1551], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 1, 0, 1, 1, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2] [2, 5, 3, 2, 1, 3, 4, 1, 2, 4, 0, 2, 3, 3, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111794  [ 2208/61145]\n",
            "train tensor([0.1714, 0.1673, 0.1912, 0.1640, 0.1588, 0.1473], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 3, 0, 2, 1, 1, 2, 3, 2, 2, 2, 2, 2, 1, 2, 0] [2, 3, 2, 2, 1, 2, 3, 3, 2, 2, 2, 3, 3, 3, 3, 4]\n",
            "### lr:  3.0176435627736146e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111446  [ 2224/61145]\n",
            "train tensor([0.1758, 0.1609, 0.1964, 0.1598, 0.1501, 0.1571], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 0, 3, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 0] [3, 4, 0, 3, 3, 0, 4, 4, 1, 4, 1, 4, 2, 0, 1, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112181  [ 2240/61145]\n",
            "train tensor([0.1722, 0.1760, 0.1968, 0.1634, 0.1547, 0.1369], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 3, 1, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 4, 2, 2] [2, 0, 2, 4, 0, 3, 0, 0, 3, 2, 4, 4, 0, 4, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111797  [ 2256/61145]\n",
            "train tensor([0.1842, 0.1675, 0.1776, 0.1703, 0.1582, 0.1422], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 1, 2, 1, 3, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 0] [2, 3, 3, 2, 2, 2, 4, 3, 2, 4, 0, 2, 3, 3, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111710  [ 2272/61145]\n",
            "train tensor([0.1785, 0.1721, 0.1951, 0.1596, 0.1559, 0.1388], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 1, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 0, 2] [1, 3, 0, 2, 0, 2, 0, 4, 4, 2, 4, 2, 0, 2, 3, 0]\n",
            "### lr:  3.018665933552514e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111548  [ 2288/61145]\n",
            "train tensor([0.1699, 0.1700, 0.1872, 0.1563, 0.1630, 0.1537], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 4, 0, 2] [0, 4, 2, 3, 2, 1, 2, 0, 4, 4, 4, 0, 1, 4, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111877  [ 2304/61145]\n",
            "train tensor([0.1662, 0.1669, 0.1969, 0.1725, 0.1580, 0.1395], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 1, 2, 2, 1, 1, 2, 0, 2, 2, 2, 0, 2, 2, 2] [0, 1, 3, 4, 1, 2, 3, 4, 2, 3, 3, 2, 1, 3, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111824  [ 2320/61145]\n",
            "train tensor([0.1800, 0.1780, 0.1711, 0.1621, 0.1610, 0.1477], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 3, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 3, 2, 2] [1, 3, 2, 4, 3, 4, 0, 0, 0, 3, 0, 3, 3, 3, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111958  [ 2336/61145]\n",
            "train tensor([0.1908, 0.1764, 0.1668, 0.1569, 0.1628, 0.1463], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 1, 2, 2, 2, 2, 3, 2, 2, 1, 2, 4, 2, 2, 1] [4, 2, 3, 4, 2, 4, 2, 3, 0, 2, 3, 3, 1, 4, 0, 0]\n",
            "### lr:  3.0197170765824137e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111715  [ 2352/61145]\n",
            "train tensor([0.1692, 0.1677, 0.2044, 0.1665, 0.1504, 0.1417], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 2, 2, 0, 2, 2, 1] [1, 0, 0, 2, 2, 3, 3, 1, 3, 0, 3, 3, 1, 4, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111747  [ 2368/61145]\n",
            "train tensor([0.1631, 0.1851, 0.1919, 0.1594, 0.1569, 0.1436], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 0, 1, 2, 2, 3, 1, 2, 2, 3, 1, 0, 0, 0, 2, 2] [0, 2, 0, 4, 2, 0, 4, 0, 3, 0, 4, 3, 2, 2, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111850  [ 2384/61145]\n",
            "train tensor([0.1754, 0.1556, 0.1724, 0.1655, 0.1742, 0.1570], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 1, 0, 3] [0, 3, 0, 0, 0, 2, 3, 3, 4, 0, 0, 1, 4, 2, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111802  [ 2400/61145]\n",
            "train tensor([0.1818, 0.1818, 0.1874, 0.1527, 0.1535, 0.1427], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 1, 2] [4, 3, 0, 2, 2, 4, 1, 2, 1, 3, 0, 3, 4, 3, 3, 2]\n",
            "### lr:  3.0207969896199256e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111745  [ 2416/61145]\n",
            "train tensor([0.1818, 0.1714, 0.1763, 0.1572, 0.1714, 0.1419], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2] [2, 0, 4, 1, 2, 3, 3, 0, 1, 4, 4, 2, 0, 3, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111635  [ 2432/61145]\n",
            "train tensor([0.1678, 0.1668, 0.1922, 0.1608, 0.1511, 0.1613], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 3, 2, 2, 0, 0, 2, 1, 0, 2, 0, 2, 2, 2, 1] [3, 4, 4, 3, 2, 3, 3, 0, 2, 1, 2, 5, 2, 2, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111873  [ 2448/61145]\n",
            "train tensor([0.1752, 0.1809, 0.1618, 0.1616, 0.1683, 0.1522], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 1, 1, 0, 2, 2, 2, 2, 0, 0, 1, 0, 2, 2, 2, 2] [0, 0, 0, 1, 2, 4, 0, 2, 2, 3, 4, 2, 4, 2, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111775  [ 2464/61145]\n",
            "train tensor([0.1578, 0.1660, 0.1816, 0.1759, 0.1669, 0.1518], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 1, 0, 2, 2, 1, 3, 0, 2, 2, 2, 0, 0, 2, 1, 2] [2, 0, 3, 1, 3, 1, 3, 2, 0, 0, 3, 0, 0, 2, 4, 1]\n",
            "### lr:  3.021905670360277e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111586  [ 2480/61145]\n",
            "train tensor([0.1732, 0.1681, 0.1721, 0.1664, 0.1640, 0.1562], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2] [4, 1, 4, 4, 0, 1, 2, 0, 3, 0, 4, 1, 3, 0, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112248  [ 2496/61145]\n",
            "train tensor([0.1844, 0.1736, 0.1729, 0.1556, 0.1654, 0.1481], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 1] [4, 3, 2, 3, 3, 3, 3, 1, 1, 4, 0, 0, 2, 0, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111684  [ 2512/61145]\n",
            "train tensor([0.1638, 0.1594, 0.1908, 0.1572, 0.1732, 0.1556], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2] [2, 0, 0, 3, 2, 2, 1, 2, 2, 4, 4, 2, 3, 3, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111501  [ 2528/61145]\n",
            "train tensor([0.1684, 0.1581, 0.1945, 0.1743, 0.1568, 0.1480], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 1, 2, 0, 2] [3, 3, 2, 4, 3, 0, 2, 2, 2, 2, 1, 4, 3, 2, 0, 2]\n",
            "### lr:  3.0230431164372865e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111594  [ 2544/61145]\n",
            "train tensor([0.1642, 0.1656, 0.2006, 0.1676, 0.1642, 0.1378], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0] [4, 0, 2, 3, 1, 0, 1, 3, 3, 1, 3, 2, 1, 3, 4, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111822  [ 2560/61145]\n",
            "train tensor([0.1751, 0.1752, 0.1903, 0.1549, 0.1635, 0.1409], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 4, 2, 2, 2, 2, 2, 0, 2, 4, 2, 2, 2, 2, 1, 2] [3, 2, 2, 4, 0, 2, 4, 0, 1, 4, 2, 4, 4, 4, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111888  [ 2576/61145]\n",
            "train tensor([0.1575, 0.1745, 0.1987, 0.1626, 0.1570, 0.1498], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 0, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0] [3, 2, 3, 0, 2, 3, 2, 3, 2, 2, 0, 0, 2, 3, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111710  [ 2592/61145]\n",
            "train tensor([0.1741, 0.1829, 0.1805, 0.1714, 0.1466, 0.1444], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 2, 0, 0, 2, 2, 2, 0, 2, 1, 0, 2, 2, 2, 2, 0] [1, 4, 2, 2, 4, 2, 4, 3, 1, 0, 0, 0, 4, 2, 0, 1]\n",
            "### lr:  3.024209325423382e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111915  [ 2608/61145]\n",
            "train tensor([0.1664, 0.1778, 0.1750, 0.1668, 0.1758, 0.1382], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 1, 1, 2, 0, 1, 2] [0, 4, 3, 2, 3, 1, 0, 0, 1, 1, 2, 4, 3, 3, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111998  [ 2624/61145]\n",
            "train tensor([0.1673, 0.1738, 0.1760, 0.1699, 0.1615, 0.1514], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 1] [2, 0, 1, 1, 2, 2, 4, 1, 2, 2, 3, 0, 4, 2, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111584  [ 2640/61145]\n",
            "train tensor([0.1692, 0.1634, 0.1970, 0.1623, 0.1569, 0.1512], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 1, 1, 2, 2, 2, 2, 3, 2, 2, 2, 4, 2, 2, 2] [2, 4, 3, 3, 2, 0, 4, 4, 4, 0, 4, 3, 2, 2, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112079  [ 2656/61145]\n",
            "train tensor([0.1699, 0.1694, 0.1828, 0.1533, 0.1815, 0.1430], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 1] [3, 2, 2, 2, 3, 4, 2, 0, 1, 2, 3, 1, 2, 3, 3, 4]\n",
            "### lr:  3.0254042948296133e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111802  [ 2672/61145]\n",
            "train tensor([0.1664, 0.1743, 0.1858, 0.1580, 0.1637, 0.1518], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 1, 1, 0, 2, 2, 2] [0, 0, 1, 0, 4, 3, 1, 2, 3, 1, 3, 0, 0, 0, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111803  [ 2688/61145]\n",
            "train tensor([0.1591, 0.1575, 0.1985, 0.1696, 0.1609, 0.1544], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 3, 2, 4, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1] [2, 0, 2, 5, 2, 0, 3, 0, 1, 4, 0, 4, 0, 0, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111721  [ 2704/61145]\n",
            "train tensor([0.1655, 0.1852, 0.1713, 0.1560, 0.1723, 0.1496], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 0, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2] [2, 2, 2, 1, 3, 0, 0, 3, 0, 3, 2, 3, 3, 2, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111753  [ 2720/61145]\n",
            "train tensor([0.1567, 0.1728, 0.1660, 0.1892, 0.1651, 0.1503], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [3, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2] [3, 4, 3, 1, 2, 2, 2, 2, 0, 3, 1, 4, 1, 2, 3, 2]\n",
            "### lr:  3.0266280221056396e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111499  [ 2736/61145]\n",
            "train tensor([0.1683, 0.1685, 0.1821, 0.1687, 0.1692, 0.1432], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 1, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0] [3, 2, 0, 2, 0, 3, 2, 4, 2, 3, 3, 0, 3, 0, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111595  [ 2752/61145]\n",
            "train tensor([0.1529, 0.1712, 0.1914, 0.1625, 0.1681, 0.1538], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 4, 2, 0, 1, 2, 0, 2, 3, 4, 2, 2, 2, 2] [3, 0, 2, 3, 2, 0, 2, 1, 1, 0, 3, 2, 1, 2, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111576  [ 2768/61145]\n",
            "train tensor([0.1761, 0.1558, 0.1921, 0.1587, 0.1521, 0.1652], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0] [0, 2, 4, 3, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111392  [ 2784/61145]\n",
            "train tensor([0.1795, 0.1624, 0.1759, 0.1760, 0.1615, 0.1447], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 3, 2, 2, 1, 2] [0, 3, 0, 3, 3, 2, 3, 1, 2, 4, 1, 4, 4, 2, 2, 1]\n",
            "### lr:  3.027880504639741e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111836  [ 2800/61145]\n",
            "train tensor([0.1640, 0.1669, 0.1792, 0.1638, 0.1723, 0.1537], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0] [2, 2, 4, 3, 4, 2, 1, 2, 2, 3, 0, 0, 2, 0, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111702  [ 2816/61145]\n",
            "train tensor([0.1723, 0.1700, 0.1853, 0.1766, 0.1450, 0.1508], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 4, 2, 2, 0] [1, 1, 2, 2, 2, 2, 3, 0, 3, 1, 1, 2, 4, 2, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111623  [ 2832/61145]\n",
            "train tensor([0.1592, 0.1700, 0.1914, 0.1682, 0.1604, 0.1507], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 4, 0, 0] [0, 0, 4, 2, 1, 4, 3, 0, 4, 2, 3, 4, 0, 1, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112008  [ 2848/61145]\n",
            "train tensor([0.1853, 0.1708, 0.1859, 0.1739, 0.1442, 0.1399], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 1, 2, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0] [2, 0, 2, 3, 2, 0, 3, 2, 3, 4, 1, 3, 2, 3, 2, 3]\n",
            "### lr:  3.029161739758838e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111351  [ 2864/61145]\n",
            "train tensor([0.1764, 0.1733, 0.1795, 0.1659, 0.1579, 0.1471], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 0, 2, 2, 4, 0, 1, 1, 0, 1, 0, 1, 1] [0, 2, 4, 2, 2, 2, 0, 3, 3, 1, 0, 1, 1, 2, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111590  [ 2880/61145]\n",
            "train tensor([0.1865, 0.1732, 0.1796, 0.1642, 0.1707, 0.1258], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 3, 2, 0, 1, 2, 1, 2, 2, 2, 0, 0, 2, 2] [0, 2, 0, 0, 1, 3, 2, 0, 2, 3, 4, 2, 4, 2, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111467  [ 2896/61145]\n",
            "train tensor([0.1732, 0.1691, 0.2101, 0.1592, 0.1383, 0.1499], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 3, 2, 2, 2, 2, 3, 0, 2, 0, 0, 2, 2, 2, 2, 2] [4, 4, 2, 1, 2, 1, 2, 1, 3, 1, 4, 1, 1, 1, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111746  [ 2912/61145]\n",
            "train tensor([0.1601, 0.1801, 0.1897, 0.1581, 0.1498, 0.1622], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 3, 1, 2, 1, 0, 2, 2, 2, 1, 2, 0] [0, 2, 2, 1, 0, 1, 4, 1, 3, 3, 3, 1, 4, 2, 3, 4]\n",
            "### lr:  3.0304717247284843e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111714  [ 2928/61145]\n",
            "train tensor([0.1785, 0.1710, 0.1709, 0.1706, 0.1639, 0.1452], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 3, 2, 2] [0, 3, 3, 3, 0, 0, 1, 2, 1, 5, 0, 3, 2, 3, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111728  [ 2944/61145]\n",
            "train tensor([0.1722, 0.1695, 0.1787, 0.1662, 0.1614, 0.1520], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 3, 0, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2] [3, 2, 0, 3, 4, 2, 1, 2, 2, 2, 1, 1, 3, 2, 1, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111850  [ 2960/61145]\n",
            "train tensor([0.1793, 0.1740, 0.1857, 0.1593, 0.1536, 0.1480], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 1, 0, 0, 2, 2, 2, 2, 3, 1, 2, 2, 0] [2, 2, 2, 2, 3, 0, 3, 3, 1, 3, 0, 3, 1, 0, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111562  [ 2976/61145]\n",
            "train tensor([0.1813, 0.1714, 0.1729, 0.1656, 0.1661, 0.1428], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 3, 1, 4, 1, 2, 0, 2, 0, 1, 2, 2, 2, 0, 2, 2] [2, 2, 2, 0, 3, 1, 1, 1, 3, 2, 3, 2, 1, 4, 2, 1]\n",
            "### lr:  3.031810456752865e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111637  [ 2992/61145]\n",
            "train tensor([0.1522, 0.1768, 0.1949, 0.1732, 0.1594, 0.1435], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 1, 3, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2] [0, 3, 0, 0, 1, 2, 2, 3, 2, 3, 3, 0, 4, 2, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111723  [ 3008/61145]\n",
            "train tensor([0.1557, 0.1748, 0.1908, 0.1567, 0.1555, 0.1665], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 0, 2, 2, 3, 0, 2] [2, 3, 0, 4, 0, 2, 4, 2, 0, 4, 4, 1, 0, 0, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111658  [ 3024/61145]\n",
            "train tensor([0.1691, 0.1838, 0.1890, 0.1560, 0.1555, 0.1466], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 0, 2, 2, 0, 2, 0] [2, 2, 2, 3, 2, 2, 0, 2, 0, 2, 2, 2, 0, 4, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111383  [ 3040/61145]\n",
            "train tensor([0.1694, 0.1807, 0.1933, 0.1664, 0.1506, 0.1397], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 4, 0, 2, 0, 2, 2, 1, 2, 2, 0, 1, 2] [1, 2, 4, 1, 2, 2, 0, 2, 0, 0, 3, 3, 2, 3, 1, 4]\n",
            "### lr:  3.0331779329748325e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111757  [ 3056/61145]\n",
            "train tensor([0.1819, 0.1686, 0.1834, 0.1638, 0.1564, 0.1459], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 1, 2, 2, 2, 0, 0, 2, 2, 0, 2, 3, 0, 2, 0, 1] [0, 2, 0, 2, 3, 1, 2, 0, 4, 2, 2, 0, 0, 4, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111548  [ 3072/61145]\n",
            "train tensor([0.1693, 0.1753, 0.1816, 0.1611, 0.1715, 0.1412], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 3, 1, 2, 2, 1, 2] [0, 1, 1, 0, 0, 2, 1, 0, 3, 1, 1, 4, 2, 3, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111540  [ 3088/61145]\n",
            "train tensor([0.1604, 0.1650, 0.1888, 0.1640, 0.1663, 0.1556], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 2, 2, 2, 2, 1, 0, 2, 2, 1, 2, 3, 2, 2] [2, 0, 3, 4, 3, 2, 4, 2, 1, 2, 2, 1, 4, 0, 1, 5]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111647  [ 3104/61145]\n",
            "train tensor([0.1725, 0.1629, 0.1813, 0.1752, 0.1510, 0.1571], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0] [0, 2, 2, 3, 1, 3, 3, 0, 0, 0, 1, 2, 1, 2, 0, 2]\n",
            "### lr:  3.0345741504758667e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111464  [ 3120/61145]\n",
            "train tensor([0.1792, 0.1744, 0.1736, 0.1561, 0.1680, 0.1487], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 2, 0] [2, 2, 2, 0, 0, 2, 2, 0, 3, 3, 4, 2, 2, 0, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111475  [ 3136/61145]\n",
            "train tensor([0.1628, 0.1684, 0.1974, 0.1601, 0.1583, 0.1530], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 1, 3, 1, 2, 2, 0, 2, 0, 2, 0] [1, 4, 3, 2, 2, 2, 3, 4, 2, 2, 3, 0, 1, 3, 1, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111675  [ 3152/61145]\n",
            "train tensor([0.1778, 0.1735, 0.1684, 0.1647, 0.1710, 0.1447], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2] [0, 0, 0, 0, 3, 0, 2, 3, 2, 1, 1, 1, 0, 0, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111674  [ 3168/61145]\n",
            "train tensor([0.1798, 0.1746, 0.1780, 0.1546, 0.1682, 0.1448], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 0, 2] [3, 3, 0, 2, 4, 2, 3, 4, 0, 0, 2, 0, 4, 1, 3, 0]\n",
            "### lr:  3.035999106276123e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111968  [ 3184/61145]\n",
            "train tensor([0.1703, 0.1696, 0.1902, 0.1605, 0.1576, 0.1519], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2] [2, 1, 3, 1, 3, 3, 0, 0, 3, 3, 2, 2, 1, 2, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111536  [ 3200/61145]\n",
            "train tensor([0.1587, 0.1672, 0.1845, 0.1779, 0.1546, 0.1572], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 1, 2, 4, 3, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0] [3, 2, 0, 4, 1, 2, 4, 4, 2, 3, 0, 0, 3, 1, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111770  [ 3216/61145]\n",
            "train tensor([0.1509, 0.1655, 0.1856, 0.1888, 0.1557, 0.1534], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [3, 1, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 0, 3] [1, 2, 1, 1, 1, 3, 3, 0, 2, 1, 1, 3, 0, 4, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111812  [ 3232/61145]\n",
            "train tensor([0.1710, 0.1668, 0.1803, 0.1584, 0.1755, 0.1480], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 1, 1, 4, 1, 2, 0, 2, 1, 0, 2, 2] [0, 2, 0, 3, 3, 2, 0, 0, 1, 2, 2, 3, 0, 3, 2, 2]\n",
            "### lr:  3.037452797334422e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111723  [ 3248/61145]\n",
            "train tensor([0.1716, 0.1637, 0.1844, 0.1662, 0.1667, 0.1473], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 3, 2, 2, 3] [0, 2, 2, 1, 2, 0, 2, 0, 2, 3, 2, 2, 2, 3, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111450  [ 3264/61145]\n",
            "train tensor([0.1787, 0.1678, 0.1850, 0.1782, 0.1462, 0.1441], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 0, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2] [2, 1, 4, 2, 3, 2, 2, 3, 0, 0, 2, 4, 0, 1, 4, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111703  [ 3280/61145]\n",
            "train tensor([0.1597, 0.1659, 0.1771, 0.1722, 0.1770, 0.1480], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2] [3, 2, 4, 3, 2, 2, 0, 3, 1, 0, 4, 4, 4, 0, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112057  [ 3296/61145]\n",
            "train tensor([0.1657, 0.1751, 0.1774, 0.1642, 0.1682, 0.1495], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 3, 2, 2, 0, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 1] [1, 0, 0, 1, 2, 2, 3, 3, 4, 1, 3, 2, 0, 0, 2, 1]\n",
            "### lr:  3.0389352205482523e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111661  [ 3312/61145]\n",
            "train tensor([0.1707, 0.1716, 0.1887, 0.1674, 0.1423, 0.1593], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [3, 0, 3, 2, 4, 2, 0, 3, 0, 2, 3, 2, 0, 0, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111685  [ 3328/61145]\n",
            "train tensor([0.1751, 0.1698, 0.1885, 0.1688, 0.1491, 0.1488], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 2, 0, 1, 2, 2, 1, 2, 1, 0, 2, 2, 2] [2, 0, 0, 4, 4, 0, 2, 1, 0, 0, 2, 3, 4, 0, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111584  [ 3344/61145]\n",
            "train tensor([0.1710, 0.1702, 0.1824, 0.1714, 0.1527, 0.1524], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 1, 2, 1, 2, 0, 1, 2, 2, 0, 2, 2, 2, 2] [0, 1, 2, 4, 2, 2, 0, 3, 2, 0, 0, 0, 2, 0, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111511  [ 3360/61145]\n",
            "train tensor([0.1640, 0.1697, 0.1701, 0.1620, 0.1786, 0.1556], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [4, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 0, 4, 0, 0, 2] [2, 3, 1, 1, 4, 2, 2, 2, 2, 3, 4, 2, 3, 3, 3, 2]\n",
            "### lr:  3.040446372753789e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111714  [ 3376/61145]\n",
            "train tensor([0.1816, 0.1760, 0.1633, 0.1826, 0.1546, 0.1419], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [3, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 1] [4, 3, 0, 0, 2, 3, 0, 2, 2, 0, 0, 0, 4, 2, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111734  [ 3392/61145]\n",
            "train tensor([0.1782, 0.1703, 0.1626, 0.1725, 0.1641, 0.1524], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 1, 2, 2, 2] [4, 2, 0, 2, 2, 3, 1, 1, 4, 0, 2, 0, 0, 4, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111701  [ 3408/61145]\n",
            "train tensor([0.1578, 0.1771, 0.1935, 0.1694, 0.1556, 0.1466], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 1, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0] [4, 2, 0, 3, 0, 3, 0, 4, 0, 2, 0, 3, 4, 0, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111727  [ 3424/61145]\n",
            "train tensor([0.1637, 0.1642, 0.1815, 0.1651, 0.1724, 0.1530], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2] [2, 4, 4, 4, 3, 1, 0, 1, 1, 0, 4, 2, 2, 2, 4, 2]\n",
            "### lr:  3.0419862507258816e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111631  [ 3440/61145]\n",
            "train tensor([0.1655, 0.1740, 0.1666, 0.1737, 0.1754, 0.1448], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [4, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2] [4, 0, 4, 2, 0, 2, 2, 2, 3, 1, 2, 3, 2, 2, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111395  [ 3456/61145]\n",
            "train tensor([0.1704, 0.1697, 0.1848, 0.1598, 0.1751, 0.1402], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 1, 2, 1, 0, 2, 0, 0, 2, 4, 2] [0, 0, 2, 2, 3, 3, 1, 3, 0, 4, 4, 3, 2, 2, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111597  [ 3472/61145]\n",
            "train tensor([0.1747, 0.1667, 0.1979, 0.1497, 0.1604, 0.1506], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 0, 0, 2, 2, 2] [3, 3, 0, 3, 0, 3, 3, 0, 0, 3, 2, 3, 1, 4, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111930  [ 3488/61145]\n",
            "train tensor([0.1668, 0.1728, 0.1815, 0.1677, 0.1602, 0.1509], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 3, 2] [4, 3, 2, 1, 0, 2, 4, 2, 2, 4, 0, 2, 3, 2, 1, 0]\n",
            "### lr:  3.043554851178081e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111731  [ 3504/61145]\n",
            "train tensor([0.1641, 0.1764, 0.1815, 0.1554, 0.1693, 0.1533], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 0, 2] [0, 0, 4, 3, 1, 2, 4, 4, 2, 4, 4, 0, 2, 0, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111981  [ 3520/61145]\n",
            "train tensor([0.1817, 0.1701, 0.1860, 0.1615, 0.1622, 0.1386], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 1, 3, 0, 3, 1] [0, 3, 4, 1, 4, 2, 0, 1, 0, 2, 2, 2, 2, 2, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111478  [ 3536/61145]\n",
            "train tensor([0.1723, 0.1616, 0.1846, 0.1652, 0.1696, 0.1467], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 3, 1, 1, 2, 0, 2, 2, 0, 3, 2, 2, 2] [0, 0, 3, 4, 4, 0, 4, 2, 2, 0, 3, 0, 2, 4, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111806  [ 3552/61145]\n",
            "train tensor([0.1913, 0.1687, 0.1851, 0.1663, 0.1552, 0.1334], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 3, 0, 2, 2, 0, 1] [2, 2, 3, 4, 2, 2, 2, 4, 3, 2, 3, 0, 4, 2, 0, 3]\n",
            "### lr:  3.045152170762633e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111324  [ 3568/61145]\n",
            "train tensor([0.1591, 0.1753, 0.1865, 0.1607, 0.1552, 0.1633], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 1, 1] [1, 4, 2, 1, 3, 3, 4, 2, 3, 3, 4, 2, 2, 2, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111615  [ 3584/61145]\n",
            "train tensor([0.1723, 0.1797, 0.1780, 0.1680, 0.1549, 0.1472], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 3, 2, 1, 2] [2, 4, 2, 1, 3, 0, 2, 4, 3, 2, 1, 3, 4, 4, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111888  [ 3600/61145]\n",
            "train tensor([0.1758, 0.1716, 0.1717, 0.1602, 0.1692, 0.1515], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 3, 1, 2, 0] [3, 2, 0, 3, 4, 4, 1, 2, 1, 0, 0, 0, 4, 3, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111704  [ 3616/61145]\n",
            "train tensor([0.1815, 0.1655, 0.1777, 0.1547, 0.1747, 0.1458], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 2, 1, 1, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2] [2, 4, 2, 2, 2, 2, 4, 1, 2, 4, 0, 0, 0, 1, 2, 3]\n",
            "### lr:  3.046778206070497e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111638  [ 3632/61145]\n",
            "train tensor([0.1662, 0.1699, 0.1849, 0.1671, 0.1639, 0.1480], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 1, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 1, 0, 2, 2] [3, 3, 3, 0, 2, 0, 0, 2, 1, 2, 3, 3, 3, 0, 2, 5]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111846  [ 3648/61145]\n",
            "train tensor([0.1760, 0.1683, 0.1844, 0.1602, 0.1731, 0.1380], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2] [2, 0, 1, 0, 3, 2, 1, 2, 3, 0, 2, 2, 2, 2, 3, 5]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111580  [ 3664/61145]\n",
            "train tensor([0.1630, 0.1749, 0.1767, 0.1655, 0.1650, 0.1549], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 4, 2, 2, 0] [3, 0, 2, 2, 0, 2, 0, 0, 3, 3, 1, 3, 0, 0, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111721  [ 3680/61145]\n",
            "train tensor([0.1755, 0.1895, 0.1603, 0.1617, 0.1613, 0.1517], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [1, 2, 3, 2, 2, 3, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2] [0, 4, 2, 3, 0, 0, 0, 2, 3, 0, 2, 1, 1, 4, 2, 2]\n",
            "### lr:  3.048432953631337e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111565  [ 3696/61145]\n",
            "train tensor([0.1638, 0.1709, 0.1785, 0.1710, 0.1598, 0.1561], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 1, 2, 2, 2, 4, 3, 1, 2, 1, 2, 2, 2, 2] [4, 2, 4, 0, 3, 2, 3, 2, 2, 3, 0, 4, 2, 1, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111647  [ 3712/61145]\n",
            "train tensor([0.1753, 0.1800, 0.1693, 0.1585, 0.1716, 0.1452], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [1, 2, 2, 0, 2, 2, 0, 2, 2, 3, 0, 0, 0, 2, 0, 2] [1, 2, 0, 1, 3, 3, 4, 2, 2, 3, 0, 3, 2, 0, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111500  [ 3728/61145]\n",
            "train tensor([0.1650, 0.1773, 0.1960, 0.1710, 0.1504, 0.1403], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 0, 0, 1, 2, 2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 1] [0, 0, 1, 2, 4, 2, 2, 2, 0, 2, 1, 4, 2, 2, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111631  [ 3744/61145]\n",
            "train tensor([0.1858, 0.1672, 0.1872, 0.1710, 0.1483, 0.1405], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 2, 0, 2, 2, 4, 0, 2, 2, 0, 0, 0, 0] [1, 3, 2, 0, 1, 0, 3, 3, 3, 3, 2, 1, 3, 0, 2, 2]\n",
            "### lr:  3.0501164099135457e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111474  [ 3760/61145]\n",
            "train tensor([0.1731, 0.1869, 0.1550, 0.1825, 0.1575, 0.1450], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0] [4, 3, 3, 2, 2, 4, 0, 2, 3, 3, 2, 3, 4, 1, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111794  [ 3776/61145]\n",
            "train tensor([0.1637, 0.1726, 0.1801, 0.1709, 0.1655, 0.1473], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 4, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1, 2, 3] [4, 0, 3, 0, 2, 0, 4, 0, 1, 3, 4, 0, 2, 2, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111807  [ 3792/61145]\n",
            "train tensor([0.1698, 0.1698, 0.2062, 0.1613, 0.1437, 0.1492], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 0, 2, 2, 2, 1, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2] [0, 3, 2, 1, 0, 2, 2, 2, 1, 2, 2, 0, 2, 2, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111486  [ 3808/61145]\n",
            "train tensor([0.1811, 0.1641, 0.1807, 0.1668, 0.1644, 0.1429], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 3] [2, 1, 2, 3, 4, 0, 3, 1, 3, 3, 0, 4, 3, 0, 3, 0]\n",
            "### lr:  3.051828571324239e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111868  [ 3824/61145]\n",
            "train tensor([0.1774, 0.1680, 0.1882, 0.1580, 0.1566, 0.1518], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2] [2, 0, 1, 0, 3, 2, 3, 0, 0, 3, 2, 1, 3, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111597  [ 3840/61145]\n",
            "train tensor([0.1915, 0.1597, 0.1917, 0.1607, 0.1523, 0.1441], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1] [1, 1, 0, 3, 4, 3, 0, 2, 0, 4, 3, 4, 4, 1, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111830  [ 3856/61145]\n",
            "train tensor([0.2036, 0.1632, 0.1872, 0.1504, 0.1687, 0.1268], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 0, 2, 2, 0, 3, 2] [0, 0, 1, 0, 4, 4, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111806  [ 3872/61145]\n",
            "train tensor([0.1681, 0.1706, 0.1836, 0.1599, 0.1550, 0.1628], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 0, 0, 2, 4, 2, 2, 2, 2, 2, 2] [3, 1, 3, 2, 0, 4, 3, 4, 3, 4, 2, 3, 2, 0, 4, 0]\n",
            "### lr:  3.0535694342092736e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111871  [ 3888/61145]\n",
            "train tensor([0.1866, 0.1671, 0.1730, 0.1747, 0.1625, 0.1361], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 3, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 2, 2] [0, 4, 2, 2, 2, 2, 3, 2, 1, 0, 4, 2, 4, 5, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111687  [ 3904/61145]\n",
            "train tensor([0.1662, 0.1750, 0.2006, 0.1676, 0.1536, 0.1370], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 2, 3, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2] [0, 1, 4, 2, 4, 4, 3, 2, 2, 4, 0, 0, 0, 0, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111896  [ 3920/61145]\n",
            "train tensor([0.1769, 0.1758, 0.1730, 0.1723, 0.1526, 0.1493], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 2, 2, 2, 2, 0, 0, 1, 2, 1, 2, 2, 2, 0, 0] [2, 3, 3, 3, 4, 2, 2, 0, 4, 4, 3, 4, 2, 2, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111710  [ 3936/61145]\n",
            "train tensor([0.1817, 0.1736, 0.1875, 0.1585, 0.1539, 0.1448], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2] [0, 1, 2, 1, 4, 3, 0, 2, 4, 0, 2, 3, 2, 0, 3, 3]\n",
            "### lr:  3.0553389948532544e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111931  [ 3952/61145]\n",
            "train tensor([0.1655, 0.1701, 0.1810, 0.1702, 0.1628, 0.1504], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 0, 2, 2, 1, 2, 2, 3, 2, 2, 0, 2, 2, 0] [0, 0, 4, 4, 3, 0, 3, 4, 0, 0, 1, 2, 2, 2, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111908  [ 3968/61145]\n",
            "train tensor([0.1542, 0.1776, 0.1849, 0.1673, 0.1679, 0.1481], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "0 [2, 3, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2] [0, 2, 3, 4, 1, 3, 0, 3, 3, 2, 3, 3, 1, 1, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112008  [ 3984/61145]\n",
            "train tensor([0.1756, 0.1774, 0.1748, 0.1668, 0.1656, 0.1397], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 2, 2, 2, 2, 2, 3, 2, 0, 4, 1, 1, 2, 4, 2] [4, 0, 2, 3, 0, 2, 0, 2, 1, 3, 2, 3, 3, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111624  [ 4000/61145]\n",
            "train tensor([0.1684, 0.1711, 0.2067, 0.1639, 0.1393, 0.1505], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 2, 0, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 0] [4, 0, 2, 2, 0, 3, 0, 0, 1, 1, 5, 3, 3, 1, 3, 1]\n",
            "### lr:  3.0571372494795323e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112179  [ 4016/61145]\n",
            "train tensor([0.1735, 0.1644, 0.1866, 0.1731, 0.1579, 0.1445], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2] [0, 4, 2, 0, 4, 0, 3, 2, 2, 3, 3, 2, 0, 5, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111784  [ 4032/61145]\n",
            "train tensor([0.1755, 0.1698, 0.1754, 0.1607, 0.1709, 0.1477], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 0, 0, 1, 0, 1, 0, 2, 2, 1, 2, 0, 2, 1, 2] [3, 1, 4, 3, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111522  [ 4048/61145]\n",
            "train tensor([0.1679, 0.1668, 0.1791, 0.1735, 0.1645, 0.1482], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 0, 2, 1, 0, 0, 2] [1, 0, 2, 1, 0, 1, 4, 0, 3, 2, 0, 0, 4, 3, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112063  [ 4064/61145]\n",
            "train tensor([0.1658, 0.1699, 0.1869, 0.1633, 0.1602, 0.1539], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2] [2, 2, 1, 2, 4, 3, 2, 2, 0, 2, 4, 2, 2, 0, 0, 3]\n",
            "### lr:  3.0589641942502137e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111569  [ 4080/61145]\n",
            "train tensor([0.1768, 0.1608, 0.1875, 0.1706, 0.1544, 0.1499], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 0, 0, 1] [2, 0, 0, 0, 0, 2, 4, 0, 0, 3, 2, 0, 0, 3, 4, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111776  [ 4096/61145]\n",
            "train tensor([0.1622, 0.1690, 0.1936, 0.1629, 0.1672, 0.1451], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 0, 2, 1, 2, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2] [1, 2, 4, 2, 0, 3, 0, 1, 0, 0, 2, 4, 4, 1, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111919  [ 4112/61145]\n",
            "train tensor([0.1593, 0.1641, 0.1816, 0.1821, 0.1616, 0.1513], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [3, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2] [1, 0, 0, 2, 0, 0, 3, 0, 2, 0, 2, 0, 3, 1, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111620  [ 4128/61145]\n",
            "train tensor([0.1671, 0.1644, 0.1749, 0.1721, 0.1596, 0.1619], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 3, 1, 0, 0, 2, 2, 0, 2, 0, 1, 2, 4, 2, 2, 0] [3, 4, 4, 3, 1, 3, 0, 2, 0, 3, 1, 3, 2, 2, 1, 2]\n",
            "### lr:  3.06081982526619e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111751  [ 4144/61145]\n",
            "train tensor([0.1657, 0.1723, 0.1949, 0.1616, 0.1521, 0.1535], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 3] [4, 1, 0, 0, 4, 2, 4, 2, 2, 3, 1, 3, 0, 2, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111862  [ 4160/61145]\n",
            "train tensor([0.1574, 0.1747, 0.1854, 0.1669, 0.1627, 0.1529], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "0 [2, 2, 0, 2, 2, 2, 0, 3, 2, 2, 2, 2, 2, 3, 0, 0] [0, 3, 2, 3, 1, 4, 1, 2, 1, 3, 3, 3, 0, 4, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111891  [ 4176/61145]\n",
            "train tensor([0.1751, 0.1770, 0.1774, 0.1692, 0.1568, 0.1446], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [3, 2, 0, 1, 4, 3, 4, 4, 2, 0, 2, 2, 1, 1, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111661  [ 4192/61145]\n",
            "train tensor([0.1723, 0.1753, 0.1770, 0.1434, 0.1807, 0.1514], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [4, 2, 0, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0] [3, 1, 3, 0, 0, 1, 2, 1, 3, 0, 4, 3, 2, 2, 3, 0]\n",
            "### lr:  3.062704138567108e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111874  [ 4208/61145]\n",
            "train tensor([0.1671, 0.1618, 0.1854, 0.1634, 0.1561, 0.1661], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0] [4, 0, 2, 4, 1, 3, 0, 0, 4, 4, 0, 3, 2, 1, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111718  [ 4224/61145]\n",
            "train tensor([0.1774, 0.1725, 0.1822, 0.1784, 0.1485, 0.1409], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 4, 2, 3, 2] [3, 2, 2, 3, 3, 4, 2, 4, 4, 1, 2, 0, 3, 3, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111737  [ 4240/61145]\n",
            "train tensor([0.1632, 0.1690, 0.2006, 0.1664, 0.1634, 0.1373], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 0, 2, 3, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2] [4, 0, 0, 3, 0, 4, 3, 2, 2, 3, 2, 2, 3, 1, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111834  [ 4256/61145]\n",
            "train tensor([0.1703, 0.1762, 0.1781, 0.1639, 0.1625, 0.1489], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [2, 1, 3, 4, 4, 2, 2, 4, 3, 0, 0, 1, 3, 2, 3, 3]\n",
            "### lr:  3.0646171301314285e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111810  [ 4272/61145]\n",
            "train tensor([0.1793, 0.1668, 0.1848, 0.1690, 0.1519, 0.1483], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 4, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 1] [2, 1, 0, 3, 0, 4, 4, 2, 0, 4, 4, 3, 2, 4, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112048  [ 4288/61145]\n",
            "train tensor([0.1601, 0.1700, 0.1933, 0.1670, 0.1559, 0.1537], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 2, 2, 3, 2, 0, 2, 3, 2, 2, 2, 2, 2] [1, 2, 2, 3, 2, 1, 0, 3, 4, 2, 2, 2, 0, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111412  [ 4304/61145]\n",
            "train tensor([0.1757, 0.1721, 0.1794, 0.1666, 0.1582, 0.1480], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [4, 3, 0, 2, 4, 2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111448  [ 4320/61145]\n",
            "train tensor([0.1837, 0.1622, 0.1719, 0.1784, 0.1592, 0.1446], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 0, 0, 2, 3] [3, 4, 2, 2, 1, 4, 0, 0, 3, 3, 3, 4, 2, 0, 4, 1]\n",
            "### lr:  3.066558795876377e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111634  [ 4336/61145]\n",
            "train tensor([0.1864, 0.1750, 0.1728, 0.1775, 0.1544, 0.1338], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 3, 0, 2, 2, 2, 2] [3, 2, 0, 3, 2, 0, 2, 3, 1, 2, 1, 0, 3, 1, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111470  [ 4352/61145]\n",
            "train tensor([0.1788, 0.1608, 0.1751, 0.1780, 0.1618, 0.1456], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 2, 2, 2, 4, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2] [3, 1, 2, 2, 2, 1, 3, 1, 2, 0, 4, 3, 2, 0, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111358  [ 4368/61145]\n",
            "train tensor([0.1583, 0.1707, 0.1789, 0.1801, 0.1585, 0.1534], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [3, 2, 2, 2, 4, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2] [3, 2, 1, 3, 1, 2, 2, 3, 3, 2, 0, 2, 0, 3, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111612  [ 4384/61145]\n",
            "train tensor([0.1734, 0.1739, 0.1862, 0.1648, 0.1599, 0.1417], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 0, 0, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [3, 0, 0, 2, 3, 2, 3, 3, 4, 2, 4, 2, 0, 4, 4, 3]\n",
            "### lr:  3.068529131658005e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111632  [ 4400/61145]\n",
            "train tensor([0.1761, 0.1631, 0.1800, 0.1666, 0.1618, 0.1524], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 3, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2] [1, 0, 0, 1, 2, 2, 2, 1, 0, 2, 1, 4, 2, 3, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111695  [ 4416/61145]\n",
            "train tensor([0.1722, 0.1719, 0.1867, 0.1729, 0.1506, 0.1457], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 2, 1, 2, 4, 2, 0, 0, 2, 1, 2, 2, 0, 0] [2, 0, 0, 3, 4, 1, 3, 0, 4, 4, 0, 3, 0, 2, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111838  [ 4432/61145]\n",
            "train tensor([0.1642, 0.1672, 0.1798, 0.1638, 0.1599, 0.1652], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 1, 2, 2, 1, 0, 2, 2, 2, 0, 3, 2] [4, 0, 2, 4, 1, 0, 1, 2, 0, 3, 0, 0, 3, 4, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111962  [ 4448/61145]\n",
            "train tensor([0.1874, 0.1626, 0.1782, 0.1617, 0.1710, 0.1391], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2] [3, 4, 1, 2, 3, 0, 3, 2, 3, 2, 1, 0, 0, 4, 3, 2]\n",
            "### lr:  3.0705281332711547e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111481  [ 4464/61145]\n",
            "train tensor([0.1542, 0.1608, 0.1777, 0.1601, 0.1838, 0.1633], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [4, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 1, 3, 2, 2] [1, 1, 5, 2, 2, 3, 4, 0, 2, 1, 3, 1, 4, 3, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111658  [ 4480/61145]\n",
            "train tensor([0.1743, 0.1703, 0.1992, 0.1646, 0.1473, 0.1443], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 2, 2, 2, 2, 2, 0, 1, 2, 0, 2, 4, 2, 2] [4, 2, 3, 1, 1, 2, 0, 0, 4, 3, 2, 4, 2, 1, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111671  [ 4496/61145]\n",
            "train tensor([0.1821, 0.1660, 0.1870, 0.1644, 0.1475, 0.1531], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 3, 2, 2, 2, 3, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2] [2, 2, 2, 1, 2, 4, 2, 2, 1, 3, 2, 2, 0, 0, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111375  [ 4512/61145]\n",
            "train tensor([0.1617, 0.1675, 0.1894, 0.1610, 0.1689, 0.1515], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 1, 2, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2] [3, 3, 1, 1, 4, 0, 3, 4, 3, 3, 5, 2, 3, 3, 2, 0]\n",
            "### lr:  3.0725557964494985e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111844  [ 4528/61145]\n",
            "train tensor([0.1737, 0.1808, 0.1815, 0.1654, 0.1612, 0.1375], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2] [3, 2, 2, 4, 2, 1, 3, 3, 1, 4, 0, 3, 2, 3, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111713  [ 4544/61145]\n",
            "train tensor([0.1725, 0.1751, 0.1897, 0.1792, 0.1478, 0.1357], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [4, 2, 2, 3, 0, 0, 3, 3, 2, 2, 1, 2, 4, 2, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111509  [ 4560/61145]\n",
            "train tensor([0.1872, 0.1598, 0.1822, 0.1712, 0.1550, 0.1446], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2] [0, 2, 3, 3, 2, 2, 3, 2, 2, 4, 2, 3, 0, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111439  [ 4576/61145]\n",
            "train tensor([0.1700, 0.1800, 0.1911, 0.1696, 0.1522, 0.1371], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2] [3, 3, 0, 4, 1, 2, 2, 3, 3, 3, 3, 0, 2, 4, 1, 0]\n",
            "### lr:  3.0746121168655496e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111694  [ 4592/61145]\n",
            "train tensor([0.1820, 0.1631, 0.1744, 0.1531, 0.1814, 0.1459], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 0, 0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2] [2, 2, 0, 0, 3, 0, 2, 2, 0, 0, 0, 1, 3, 2, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111671  [ 4608/61145]\n",
            "train tensor([0.1705, 0.1556, 0.1884, 0.1713, 0.1655, 0.1486], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 3, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2] [0, 4, 1, 4, 4, 3, 0, 4, 4, 1, 0, 0, 1, 0, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111978  [ 4624/61145]\n",
            "train tensor([0.1819, 0.1790, 0.1909, 0.1575, 0.1522, 0.1384], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 3, 0, 2, 2] [1, 4, 1, 2, 2, 4, 3, 3, 3, 1, 3, 3, 1, 4, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111801  [ 4640/61145]\n",
            "train tensor([0.1708, 0.1659, 0.1996, 0.1566, 0.1574, 0.1497], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2] [2, 3, 2, 4, 3, 2, 2, 0, 2, 5, 0, 2, 4, 0, 1, 0]\n",
            "### lr:  3.076697090130648e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111494  [ 4656/61145]\n",
            "train tensor([0.1597, 0.1670, 0.1803, 0.1658, 0.1725, 0.1547], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 3, 2, 2, 2, 2] [4, 4, 0, 0, 2, 3, 3, 0, 0, 3, 0, 4, 0, 2, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111547  [ 4672/61145]\n",
            "train tensor([0.1738, 0.1616, 0.1925, 0.1645, 0.1678, 0.1398], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 0, 3, 2, 0, 3, 2, 2, 2, 0, 2, 2, 2] [2, 4, 1, 3, 0, 2, 2, 3, 1, 2, 2, 1, 3, 1, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111650  [ 4688/61145]\n",
            "train tensor([0.1774, 0.1608, 0.1870, 0.1613, 0.1649, 0.1485], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 0, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3] [2, 2, 2, 1, 2, 3, 1, 3, 5, 1, 3, 0, 1, 3, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111460  [ 4704/61145]\n",
            "train tensor([0.1629, 0.1665, 0.1790, 0.1702, 0.1700, 0.1514], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 4, 2, 1, 2, 2, 2, 1, 0, 0, 2, 2, 2, 3, 2, 2] [2, 3, 5, 3, 1, 3, 4, 2, 0, 0, 3, 0, 4, 0, 2, 2]\n",
            "### lr:  3.078810711794978e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111702  [ 4720/61145]\n",
            "train tensor([0.1561, 0.1649, 0.1930, 0.1615, 0.1668, 0.1576], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 0, 2, 0, 2, 0, 2] [2, 2, 3, 3, 2, 2, 4, 2, 2, 2, 2, 4, 4, 1, 4, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111373  [ 4736/61145]\n",
            "train tensor([0.1645, 0.1700, 0.2055, 0.1649, 0.1513, 0.1438], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 1, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2] [0, 0, 4, 3, 0, 2, 2, 0, 5, 3, 4, 3, 2, 0, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111670  [ 4752/61145]\n",
            "train tensor([0.1733, 0.1665, 0.1798, 0.1767, 0.1590, 0.1447], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 3, 2, 0, 0, 1, 0, 2, 0, 0, 2, 2] [3, 2, 4, 0, 2, 2, 1, 0, 2, 2, 3, 3, 3, 4, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111777  [ 4768/61145]\n",
            "train tensor([0.1596, 0.1774, 0.1989, 0.1554, 0.1436, 0.1652], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0] [1, 0, 0, 3, 0, 0, 0, 2, 1, 4, 2, 2, 3, 2, 0, 2]\n",
            "### lr:  3.08095297734759e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111248  [ 4784/61145]\n",
            "train tensor([0.1580, 0.1636, 0.1991, 0.1633, 0.1720, 0.1440], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 1, 3, 2, 2, 0, 2] [0, 2, 2, 0, 0, 3, 2, 3, 2, 2, 2, 3, 4, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111462  [ 4800/61145]\n",
            "train tensor([0.1667, 0.1799, 0.1834, 0.1607, 0.1529, 0.1563], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 3, 2, 2] [3, 3, 2, 0, 3, 0, 3, 0, 2, 0, 1, 3, 4, 0, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111653  [ 4816/61145]\n",
            "train tensor([0.1801, 0.1568, 0.1936, 0.1692, 0.1540, 0.1462], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2] [3, 4, 3, 2, 1, 0, 2, 3, 2, 1, 3, 3, 1, 2, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111497  [ 4832/61145]\n",
            "train tensor([0.1711, 0.1706, 0.1878, 0.1755, 0.1532, 0.1418], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 3, 0, 3, 2, 0, 2, 1, 0, 2, 3, 3, 2, 3, 2, 1]\n",
            "### lr:  3.0831238822163985e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111700  [ 4848/61145]\n",
            "train tensor([0.1666, 0.1755, 0.1835, 0.1576, 0.1597, 0.1571], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 1] [2, 2, 2, 3, 4, 0, 0, 3, 4, 0, 0, 4, 3, 2, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111570  [ 4864/61145]\n",
            "train tensor([0.1786, 0.1762, 0.1877, 0.1556, 0.1692, 0.1327], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2] [0, 1, 3, 2, 0, 1, 4, 3, 0, 4, 1, 0, 3, 4, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111793  [ 4880/61145]\n",
            "train tensor([0.1664, 0.1669, 0.1822, 0.1675, 0.1734, 0.1436], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 2, 3, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0] [0, 2, 0, 2, 4, 2, 0, 1, 3, 0, 2, 0, 0, 3, 1, 5]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111728  [ 4896/61145]\n",
            "train tensor([0.1952, 0.1738, 0.1652, 0.1663, 0.1664, 0.1330], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0] [3, 4, 4, 4, 2, 4, 3, 4, 3, 2, 0, 2, 3, 3, 4, 2]\n",
            "### lr:  3.085323421768197e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111814  [ 4912/61145]\n",
            "train tensor([0.1916, 0.1691, 0.1814, 0.1592, 0.1616, 0.1371], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 3, 2, 1] [2, 0, 1, 4, 4, 2, 2, 3, 2, 2, 0, 0, 2, 2, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111538  [ 4928/61145]\n",
            "train tensor([0.1602, 0.1713, 0.2033, 0.1679, 0.1530, 0.1443], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 1, 2, 2, 2, 1, 2, 0, 4, 2, 2, 4, 2, 2, 2, 2] [3, 1, 0, 3, 2, 1, 2, 0, 0, 1, 2, 1, 3, 0, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111550  [ 4944/61145]\n",
            "train tensor([0.1849, 0.1677, 0.1700, 0.1638, 0.1648, 0.1488], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 0, 0, 2, 2, 2, 0, 2, 1, 2, 2, 1, 3, 2, 2, 0] [0, 2, 0, 4, 1, 1, 0, 3, 4, 2, 0, 0, 0, 1, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111399  [ 4960/61145]\n",
            "train tensor([0.1698, 0.1514, 0.2129, 0.1723, 0.1486, 0.1449], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 3, 2, 2, 2, 0, 2] [0, 1, 4, 2, 0, 2, 0, 3, 0, 2, 2, 3, 1, 3, 3, 1]\n",
            "### lr:  3.0875515913086657e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111543  [ 4976/61145]\n",
            "train tensor([0.1595, 0.1785, 0.1840, 0.1653, 0.1688, 0.1439], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2] [2, 2, 2, 0, 1, 1, 1, 2, 2, 0, 4, 0, 3, 4, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111839  [ 4992/61145]\n",
            "train tensor([0.1664, 0.1622, 0.2019, 0.1655, 0.1512, 0.1528], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2] [1, 0, 2, 2, 0, 3, 1, 0, 4, 4, 4, 3, 1, 5, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111900  [ 5008/61145]\n",
            "train tensor([0.1573, 0.1570, 0.1919, 0.1695, 0.1599, 0.1643], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2] [3, 0, 0, 4, 3, 3, 3, 2, 2, 3, 2, 3, 2, 2, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111473  [ 5024/61145]\n",
            "train tensor([0.1564, 0.1756, 0.1889, 0.1751, 0.1551, 0.1488], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 0, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2] [0, 4, 2, 3, 2, 1, 5, 4, 4, 4, 3, 4, 4, 3, 0, 3]\n",
            "### lr:  3.089808386082379e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112249  [ 5040/61145]\n",
            "train tensor([0.1744, 0.1650, 0.1826, 0.1702, 0.1555, 0.1524], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 1, 2, 4, 2, 2, 2, 2, 0, 2, 2, 3, 0] [0, 3, 2, 2, 2, 4, 1, 4, 1, 3, 2, 2, 4, 5, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111592  [ 5056/61145]\n",
            "train tensor([0.1728, 0.1688, 0.1822, 0.1636, 0.1604, 0.1522], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2] [2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 1, 0, 3, 3, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111044  [ 5072/61145]\n",
            "train tensor([0.1628, 0.1686, 0.1834, 0.1676, 0.1734, 0.1441], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 0, 2, 1, 0, 2, 0, 2, 0, 4, 4, 0, 0, 3, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111631  [ 5088/61145]\n",
            "train tensor([0.1660, 0.1702, 0.1838, 0.1684, 0.1664, 0.1452], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 0, 2, 0, 2, 2, 1, 0, 2, 2, 0, 2, 2, 2] [1, 0, 3, 3, 4, 4, 0, 2, 2, 2, 0, 3, 3, 2, 3, 3]\n",
            "### lr:  3.0920938012728245e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111886  [ 5104/61145]\n",
            "train tensor([0.1684, 0.1639, 0.1848, 0.1712, 0.1602, 0.1516], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2] [0, 2, 2, 2, 0, 2, 3, 0, 2, 3, 0, 2, 1, 0, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111391  [ 5120/61145]\n",
            "train tensor([0.1799, 0.1625, 0.1817, 0.1534, 0.1793, 0.1431], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 2, 2, 2, 0, 2, 0, 2, 3, 0, 2, 0, 2, 2, 2, 2] [2, 1, 2, 2, 0, 3, 3, 2, 1, 1, 2, 2, 3, 3, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111269  [ 5136/61145]\n",
            "train tensor([0.1818, 0.1602, 0.1932, 0.1669, 0.1543, 0.1437], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "9 [2, 2, 2, 2, 2, 2, 2, 2, 3, 0, 2, 2, 0, 2, 2, 2] [2, 3, 4, 2, 4, 2, 0, 4, 3, 0, 2, 2, 0, 3, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111421  [ 5152/61145]\n",
            "train tensor([0.1757, 0.1778, 0.1772, 0.1627, 0.1716, 0.1350], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "0 [1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0] [0, 0, 3, 2, 4, 3, 2, 3, 4, 3, 4, 5, 2, 3, 3, 1]\n",
            "### lr:  3.094407832002396e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111905  [ 5168/61145]\n",
            "train tensor([0.1742, 0.1704, 0.2050, 0.1670, 0.1466, 0.1369], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 3, 2, 0, 0, 0] [0, 2, 0, 0, 0, 4, 3, 0, 2, 4, 1, 2, 0, 0, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111407  [ 5184/61145]\n",
            "train tensor([0.1761, 0.1649, 0.1940, 0.1604, 0.1632, 0.1414], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 0, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2] [2, 0, 3, 1, 3, 3, 2, 3, 1, 4, 4, 0, 2, 0, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111292  [ 5200/61145]\n",
            "train tensor([0.1688, 0.1786, 0.1848, 0.1635, 0.1619, 0.1425], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2] [4, 3, 5, 1, 3, 2, 0, 4, 3, 0, 0, 0, 3, 4, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111952  [ 5216/61145]\n",
            "train tensor([0.1728, 0.1692, 0.1789, 0.1572, 0.1725, 0.1494], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 0, 2, 2, 3, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0] [2, 0, 0, 4, 0, 3, 2, 0, 4, 2, 2, 3, 1, 3, 4, 2]\n",
            "### lr:  3.096750473332431e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111813  [ 5232/61145]\n",
            "train tensor([0.1725, 0.1706, 0.1770, 0.1870, 0.1454, 0.1476], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [3, 3, 1, 1, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0] [3, 3, 2, 2, 0, 2, 3, 1, 2, 2, 3, 4, 3, 4, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111676  [ 5248/61145]\n",
            "train tensor([0.1845, 0.1760, 0.1703, 0.1681, 0.1611, 0.1400], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 1, 0, 2, 3, 2, 2, 2, 2, 2, 2, 0, 2, 2] [2, 1, 3, 2, 2, 3, 2, 2, 0, 3, 0, 2, 3, 0, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111603  [ 5264/61145]\n",
            "train tensor([0.1723, 0.1693, 0.1824, 0.1726, 0.1509, 0.1524], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 2, 0, 2, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2] [4, 3, 0, 2, 0, 2, 4, 3, 0, 3, 0, 4, 3, 3, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111629  [ 5280/61145]\n",
            "train tensor([0.1817, 0.1692, 0.1809, 0.1596, 0.1607, 0.1480], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 4, 2, 3, 2, 2, 1, 2, 2, 0, 0, 0, 2, 2, 0] [1, 3, 4, 1, 0, 1, 0, 3, 1, 4, 0, 2, 1, 2, 0, 4]\n",
            "### lr:  3.099121720263189e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111704  [ 5296/61145]\n",
            "train tensor([0.1698, 0.1797, 0.1960, 0.1481, 0.1546, 0.1519], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 4, 2, 0, 2, 2, 2, 0, 2, 3, 0, 3, 2, 2] [4, 3, 3, 0, 2, 0, 0, 4, 0, 0, 2, 3, 1, 1, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111523  [ 5312/61145]\n",
            "train tensor([0.1607, 0.1716, 0.1989, 0.1531, 0.1632, 0.1526], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2] [0, 2, 1, 1, 1, 1, 2, 4, 2, 3, 0, 0, 2, 0, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111424  [ 5328/61145]\n",
            "train tensor([0.1801, 0.1531, 0.1839, 0.1671, 0.1592, 0.1566], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1] [3, 2, 3, 2, 1, 3, 0, 0, 3, 1, 3, 2, 2, 4, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111618  [ 5344/61145]\n",
            "train tensor([0.1512, 0.1657, 0.1950, 0.1877, 0.1479, 0.1525], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 4, 2, 2, 2] [0, 3, 3, 0, 3, 2, 1, 2, 1, 2, 1, 4, 3, 3, 1, 0]\n",
            "### lr:  3.1015215677338946e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111580  [ 5360/61145]\n",
            "train tensor([0.1803, 0.1666, 0.1934, 0.1652, 0.1568, 0.1376], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 0, 2, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2] [3, 4, 1, 2, 4, 3, 2, 2, 3, 2, 3, 2, 3, 1, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111643  [ 5376/61145]\n",
            "train tensor([0.1846, 0.1666, 0.2132, 0.1635, 0.1388, 0.1332], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 3, 2, 2] [2, 0, 0, 0, 3, 4, 2, 2, 1, 3, 3, 2, 0, 4, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111457  [ 5392/61145]\n",
            "train tensor([0.1831, 0.1688, 0.1753, 0.1637, 0.1652, 0.1439], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2] [2, 2, 2, 4, 0, 0, 2, 2, 3, 0, 2, 2, 4, 0, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111312  [ 5408/61145]\n",
            "train tensor([0.1812, 0.1798, 0.1989, 0.1606, 0.1508, 0.1286], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2] [2, 1, 0, 0, 1, 0, 2, 3, 0, 2, 4, 2, 3, 1, 2, 3]\n",
            "### lr:  3.103950010622713e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111142  [ 5424/61145]\n",
            "train tensor([0.1711, 0.1800, 0.1720, 0.1725, 0.1581, 0.1463], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 1] [0, 1, 2, 2, 2, 2, 3, 0, 3, 1, 3, 1, 3, 4, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111367  [ 5440/61145]\n",
            "train tensor([0.1711, 0.1597, 0.2063, 0.1616, 0.1557, 0.1456], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2] [0, 3, 2, 3, 2, 4, 2, 0, 1, 2, 0, 3, 2, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111504  [ 5456/61145]\n",
            "train tensor([0.1775, 0.1695, 0.1892, 0.1600, 0.1557, 0.1482], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 1, 2, 2, 3, 2, 4, 3, 2, 2, 2, 2, 2, 1, 2] [3, 4, 2, 3, 4, 0, 2, 2, 2, 4, 2, 3, 0, 3, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111773  [ 5472/61145]\n",
            "train tensor([0.1804, 0.1689, 0.1875, 0.1650, 0.1610, 0.1372], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0] [1, 0, 4, 3, 2, 3, 2, 1, 3, 4, 0, 2, 2, 2, 4, 2]\n",
            "### lr:  3.106407043746807e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111638  [ 5488/61145]\n",
            "train tensor([0.1697, 0.1862, 0.1686, 0.1764, 0.1589, 0.1401], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2] [0, 2, 2, 0, 3, 1, 0, 0, 1, 0, 1, 0, 0, 3, 5, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111776  [ 5504/61145]\n",
            "train tensor([0.1677, 0.1718, 0.1829, 0.1648, 0.1577, 0.1551], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 3, 0, 2, 2, 2, 3, 2, 2, 2, 0, 2, 2, 2] [1, 2, 3, 0, 0, 4, 3, 2, 1, 2, 0, 0, 2, 4, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111387  [ 5520/61145]\n",
            "train tensor([0.1776, 0.1691, 0.1822, 0.1683, 0.1548, 0.1481], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 1, 2, 0, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2] [2, 2, 0, 1, 4, 3, 3, 2, 3, 2, 1, 0, 2, 4, 4, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111645  [ 5536/61145]\n",
            "train tensor([0.1751, 0.1703, 0.1846, 0.1629, 0.1616, 0.1454], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 3, 2, 0, 2, 2, 2] [2, 4, 4, 0, 2, 4, 0, 2, 2, 3, 2, 0, 0, 0, 3, 3]\n",
            "### lr:  3.108892661862296e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111548  [ 5552/61145]\n",
            "train tensor([0.1759, 0.1774, 0.1659, 0.1778, 0.1651, 0.1379], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [3, 0, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2] [1, 1, 3, 3, 3, 1, 5, 2, 2, 0, 4, 0, 2, 0, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111544  [ 5568/61145]\n",
            "train tensor([0.1811, 0.1830, 0.1764, 0.1592, 0.1630, 0.1373], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [1, 2, 0, 0, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2] [4, 3, 0, 0, 3, 2, 3, 0, 3, 4, 2, 4, 1, 1, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111496  [ 5584/61145]\n",
            "train tensor([0.1701, 0.1696, 0.2055, 0.1593, 0.1565, 0.1390], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 0, 2, 2, 3, 2, 2, 2, 2, 3, 0, 2, 2, 2, 2, 2] [2, 0, 2, 0, 0, 2, 1, 0, 2, 1, 4, 2, 1, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111043  [ 5600/61145]\n",
            "train tensor([0.1812, 0.1709, 0.1770, 0.1657, 0.1530, 0.1522], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2] [1, 2, 4, 2, 2, 0, 1, 2, 0, 2, 2, 4, 3, 4, 4, 1]\n",
            "### lr:  3.1114068596642983e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111645  [ 5616/61145]\n",
            "train tensor([0.1571, 0.1743, 0.1896, 0.1847, 0.1433, 0.1510], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2] [2, 2, 2, 1, 0, 3, 3, 3, 3, 2, 2, 2, 0, 2, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111359  [ 5632/61145]\n",
            "train tensor([0.1811, 0.1732, 0.1845, 0.1707, 0.1542, 0.1363], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 0, 2, 0, 2, 2, 2, 2, 1, 3, 2, 2, 1, 3, 2, 0] [0, 0, 3, 2, 3, 4, 1, 4, 4, 1, 3, 4, 0, 0, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112039  [ 5648/61145]\n",
            "train tensor([0.1631, 0.1704, 0.1831, 0.1689, 0.1653, 0.1491], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 0] [2, 1, 2, 3, 2, 2, 3, 4, 1, 3, 4, 0, 0, 1, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111711  [ 5664/61145]\n",
            "train tensor([0.1760, 0.1612, 0.1865, 0.1780, 0.1625, 0.1358], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 3, 2, 2, 2, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2] [0, 2, 0, 2, 0, 1, 1, 1, 1, 2, 0, 2, 1, 3, 2, 1]\n",
            "### lr:  3.113949631786953e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111658  [ 5680/61145]\n",
            "train tensor([0.1652, 0.1654, 0.1819, 0.1708, 0.1598, 0.1569], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2] [0, 2, 4, 2, 1, 1, 3, 2, 2, 0, 2, 0, 2, 1, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111317  [ 5696/61145]\n",
            "train tensor([0.1681, 0.1626, 0.1942, 0.1641, 0.1607, 0.1503], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2] [1, 4, 1, 2, 2, 2, 3, 4, 4, 3, 3, 2, 2, 4, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111840  [ 5712/61145]\n",
            "train tensor([0.1798, 0.1668, 0.1762, 0.1696, 0.1572, 0.1505], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 2, 0, 2, 0, 3, 2, 2, 2, 2, 1, 2, 2, 2, 3] [1, 3, 0, 1, 0, 2, 0, 2, 3, 4, 0, 3, 2, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111733  [ 5728/61145]\n",
            "train tensor([0.1669, 0.1775, 0.1772, 0.1763, 0.1670, 0.1351], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 3, 2, 2, 4, 1, 2, 2, 2, 0, 2, 3, 1, 0, 3, 0]\n",
            "### lr:  3.116520972803388e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111536  [ 5744/61145]\n",
            "train tensor([0.1777, 0.1580, 0.1953, 0.1706, 0.1607, 0.1377], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2] [3, 3, 2, 3, 3, 4, 2, 1, 1, 0, 1, 4, 1, 1, 3, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112016  [ 5760/61145]\n",
            "train tensor([0.1528, 0.1653, 0.1812, 0.1728, 0.1649, 0.1630], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 3, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2] [4, 0, 3, 2, 2, 2, 2, 2, 3, 2, 2, 1, 4, 3, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111658  [ 5776/61145]\n",
            "train tensor([0.1649, 0.1871, 0.1836, 0.1689, 0.1483, 0.1472], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 4] [0, 2, 0, 0, 0, 3, 0, 2, 0, 2, 4, 1, 3, 0, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111552  [ 5792/61145]\n",
            "train tensor([0.1781, 0.1583, 0.1893, 0.1744, 0.1543, 0.1456], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 0, 3, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2] [3, 1, 3, 4, 0, 2, 0, 2, 2, 0, 1, 2, 3, 3, 3, 4]\n",
            "### lr:  3.1191208772257865e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111439  [ 5808/61145]\n",
            "train tensor([0.1776, 0.1753, 0.1757, 0.1655, 0.1701, 0.1357], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2] [2, 4, 4, 0, 2, 3, 2, 2, 0, 2, 3, 0, 1, 4, 4, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111762  [ 5824/61145]\n",
            "train tensor([0.1927, 0.1588, 0.1803, 0.1764, 0.1602, 0.1316], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 0, 2, 2, 2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 3, 2, 4, 2, 0, 1, 3, 0, 1, 3, 4, 0, 0, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111441  [ 5840/61145]\n",
            "train tensor([0.1745, 0.1701, 0.1824, 0.1717, 0.1574, 0.1439], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 2, 0, 0, 2, 3, 0, 2, 2, 2, 2, 0, 0, 0] [4, 2, 0, 1, 0, 0, 3, 3, 4, 1, 0, 2, 0, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111650  [ 5856/61145]\n",
            "train tensor([0.1913, 0.1717, 0.1603, 0.1650, 0.1597, 0.1520], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 2, 2, 0, 2, 3, 2, 1, 2, 0, 2, 2, 0, 2, 0, 0] [2, 2, 3, 0, 0, 0, 2, 4, 2, 2, 2, 1, 3, 1, 0, 4]\n",
            "### lr:  3.1217493395053547e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111253  [ 5872/61145]\n",
            "train tensor([0.1726, 0.1624, 0.1918, 0.1612, 0.1744, 0.1376], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 0, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2] [0, 2, 2, 4, 1, 5, 1, 0, 0, 3, 0, 4, 0, 4, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111949  [ 5888/61145]\n",
            "train tensor([0.1734, 0.1655, 0.1922, 0.1765, 0.1537, 0.1389], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2] [2, 1, 3, 3, 0, 0, 3, 1, 3, 3, 3, 3, 4, 2, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111676  [ 5904/61145]\n",
            "train tensor([0.1708, 0.1762, 0.1755, 0.1798, 0.1557, 0.1419], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [3, 2, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2] [3, 3, 2, 2, 2, 3, 2, 2, 1, 1, 4, 0, 2, 2, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111440  [ 5920/61145]\n",
            "train tensor([0.1664, 0.1646, 0.1852, 0.1648, 0.1590, 0.1601], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2] [0, 2, 4, 3, 0, 3, 4, 4, 2, 2, 4, 4, 1, 4, 0, 2]\n",
            "### lr:  3.1244063540323415e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111706  [ 5936/61145]\n",
            "train tensor([0.1832, 0.1549, 0.1927, 0.1664, 0.1576, 0.1452], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 3, 2, 2, 0, 1, 2, 2, 2, 2, 0, 2, 2, 2] [2, 3, 2, 2, 2, 0, 3, 2, 1, 2, 3, 4, 0, 4, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111433  [ 5952/61145]\n",
            "train tensor([0.1824, 0.1662, 0.1776, 0.1733, 0.1667, 0.1338], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2] [0, 2, 3, 0, 0, 3, 4, 2, 1, 1, 1, 0, 2, 3, 1, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111615  [ 5968/61145]\n",
            "train tensor([0.1751, 0.1846, 0.1764, 0.1689, 0.1589, 0.1361], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 2, 0, 3, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 0, 0] [3, 2, 4, 3, 4, 4, 4, 0, 2, 0, 1, 0, 0, 2, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111662  [ 5984/61145]\n",
            "train tensor([0.1779, 0.1683, 0.2001, 0.1753, 0.1438, 0.1347], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2] [2, 3, 0, 2, 4, 1, 0, 3, 0, 2, 0, 3, 1, 1, 2, 0]\n",
            "### lr:  3.12709191513609e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111478  [ 6000/61145]\n",
            "train tensor([0.1853, 0.1659, 0.1692, 0.1747, 0.1545, 0.1503], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2] [0, 3, 1, 0, 3, 5, 3, 2, 2, 0, 0, 0, 2, 3, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111482  [ 6016/61145]\n",
            "train tensor([0.1621, 0.1686, 0.1952, 0.1654, 0.1667, 0.1420], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2] [0, 0, 2, 0, 0, 3, 4, 1, 1, 4, 1, 0, 2, 0, 4, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111799  [ 6032/61145]\n",
            "train tensor([0.1709, 0.1659, 0.1833, 0.1671, 0.1628, 0.1500], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 0, 0, 3, 2, 2, 0] [4, 3, 0, 3, 3, 2, 4, 2, 4, 2, 2, 1, 2, 3, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111797  [ 6048/61145]\n",
            "train tensor([0.1857, 0.1629, 0.1876, 0.1548, 0.1661, 0.1429], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 0, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2] [2, 3, 1, 2, 2, 3, 2, 0, 4, 0, 4, 2, 0, 4, 1, 2]\n",
            "### lr:  3.129806017084982e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111536  [ 6064/61145]\n",
            "train tensor([0.1740, 0.1675, 0.1727, 0.1651, 0.1692, 0.1514], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 3, 2, 2, 4, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3] [3, 1, 4, 2, 2, 2, 4, 0, 4, 0, 4, 2, 1, 0, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111768  [ 6080/61145]\n",
            "train tensor([0.1605, 0.1815, 0.1955, 0.1562, 0.1612, 0.1450], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 0, 3, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2] [2, 2, 1, 3, 1, 3, 3, 1, 2, 2, 1, 2, 3, 2, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111500  [ 6096/61145]\n",
            "train tensor([0.1744, 0.1840, 0.1896, 0.1631, 0.1479, 0.1410], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2] [1, 2, 4, 2, 1, 2, 0, 3, 2, 0, 2, 4, 2, 0, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111262  [ 6112/61145]\n",
            "train tensor([0.1620, 0.1644, 0.1939, 0.1733, 0.1476, 0.1588], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 3, 0, 2, 0, 2] [2, 0, 0, 3, 3, 1, 1, 4, 1, 3, 2, 3, 3, 0, 2, 1]\n",
            "### lr:  3.132548654086507e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111585  [ 6128/61145]\n",
            "train tensor([0.1597, 0.1638, 0.1913, 0.1637, 0.1635, 0.1580], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0] [4, 0, 4, 0, 5, 3, 3, 2, 3, 3, 2, 0, 0, 0, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111650  [ 6144/61145]\n",
            "train tensor([0.1844, 0.1701, 0.1841, 0.1719, 0.1512, 0.1383], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2] [2, 2, 3, 4, 1, 1, 0, 0, 1, 4, 2, 1, 1, 2, 4, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111645  [ 6160/61145]\n",
            "train tensor([0.1626, 0.1591, 0.1835, 0.1854, 0.1599, 0.1494], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [3, 2, 2, 4, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2] [3, 4, 3, 3, 2, 3, 2, 1, 1, 4, 3, 1, 2, 4, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111619  [ 6176/61145]\n",
            "train tensor([0.1718, 0.1633, 0.1889, 0.1784, 0.1505, 0.1471], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 0, 2, 2, 2] [3, 2, 1, 1, 4, 3, 2, 3, 2, 4, 3, 3, 3, 2, 2, 1]\n",
            "### lr:  3.1353198202872524e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111469  [ 6192/61145]\n",
            "train tensor([0.1743, 0.1695, 0.1911, 0.1806, 0.1389, 0.1456], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2] [2, 1, 3, 3, 3, 2, 3, 0, 3, 2, 1, 0, 0, 0, 1, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111598  [ 6208/61145]\n",
            "train tensor([0.1576, 0.1665, 0.1974, 0.1754, 0.1596, 0.1435], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2] [4, 0, 3, 0, 2, 3, 3, 0, 2, 0, 4, 0, 0, 1, 4, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111430  [ 6224/61145]\n",
            "train tensor([0.1723, 0.1587, 0.1961, 0.1820, 0.1529, 0.1381], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 3, 0, 2, 2] [2, 2, 3, 3, 2, 3, 2, 4, 1, 4, 4, 2, 0, 2, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111306  [ 6240/61145]\n",
            "train tensor([0.1734, 0.1686, 0.1916, 0.1620, 0.1623, 0.1422], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0] [3, 3, 2, 0, 2, 3, 0, 2, 4, 1, 3, 4, 2, 3, 3, 2]\n",
            "### lr:  3.138119509772916e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111575  [ 6256/61145]\n",
            "train tensor([0.1655, 0.1873, 0.1741, 0.1530, 0.1676, 0.1525], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [1, 2, 0, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2] [1, 3, 0, 3, 0, 3, 2, 3, 2, 3, 2, 0, 1, 2, 4, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111536  [ 6272/61145]\n",
            "train tensor([0.1680, 0.1712, 0.1801, 0.1729, 0.1658, 0.1420], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0] [3, 1, 4, 3, 2, 3, 4, 0, 0, 0, 2, 3, 2, 2, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111782  [ 6288/61145]\n",
            "train tensor([0.1740, 0.1770, 0.1747, 0.1714, 0.1607, 0.1423], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 3, 3, 2, 3, 2, 2, 2, 2, 0, 0, 2, 1, 2, 3, 1] [2, 4, 0, 4, 0, 3, 2, 1, 1, 0, 2, 2, 3, 3, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111600  [ 6304/61145]\n",
            "train tensor([0.1825, 0.1635, 0.1944, 0.1808, 0.1541, 0.1247], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2] [5, 2, 2, 1, 1, 2, 3, 2, 0, 1, 3, 2, 2, 4, 0, 1]\n",
            "### lr:  3.14094771656832e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111663  [ 6320/61145]\n",
            "train tensor([0.1748, 0.1584, 0.2053, 0.1643, 0.1516, 0.1456], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 0] [0, 0, 2, 1, 0, 0, 0, 4, 1, 1, 1, 0, 2, 2, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111474  [ 6336/61145]\n",
            "train tensor([0.1794, 0.1678, 0.1896, 0.1627, 0.1552, 0.1454], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 3, 2] [2, 3, 4, 2, 2, 3, 4, 2, 3, 3, 4, 2, 2, 3, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111673  [ 6352/61145]\n",
            "train tensor([0.1865, 0.1782, 0.1778, 0.1579, 0.1592, 0.1404], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2] [2, 0, 2, 2, 3, 1, 4, 4, 0, 2, 4, 2, 0, 4, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111673  [ 6368/61145]\n",
            "train tensor([0.1779, 0.1749, 0.1866, 0.1705, 0.1530, 0.1371], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [4, 2, 0, 0, 2, 3, 2, 2, 3, 4, 2, 4, 2, 2, 1, 2]\n",
            "### lr:  3.1438044346374186e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111277  [ 6384/61145]\n",
            "train tensor([0.1741, 0.1681, 0.1855, 0.1547, 0.1640, 0.1535], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 0, 0, 4, 2, 2, 2, 2, 1, 2, 2, 2, 4, 2, 2, 0] [3, 2, 3, 0, 0, 2, 4, 0, 4, 3, 2, 1, 4, 2, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111683  [ 6400/61145]\n",
            "train tensor([0.1766, 0.1691, 0.1811, 0.1733, 0.1562, 0.1437], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2] [0, 0, 3, 2, 2, 0, 2, 0, 2, 2, 1, 2, 5, 3, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111396  [ 6416/61145]\n",
            "train tensor([0.1789, 0.1644, 0.1804, 0.1694, 0.1598, 0.1471], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2] [0, 2, 1, 0, 0, 2, 0, 2, 4, 0, 2, 0, 2, 0, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111410  [ 6432/61145]\n",
            "train tensor([0.1758, 0.1629, 0.1810, 0.1757, 0.1577, 0.1469], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 0, 2, 0, 2, 1, 2, 2, 2, 2, 0, 1, 2, 2, 2] [2, 1, 3, 0, 4, 3, 2, 2, 0, 3, 0, 3, 3, 3, 0, 3]\n",
            "### lr:  3.1466896578833325e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111488  [ 6448/61145]\n",
            "train tensor([0.1846, 0.1652, 0.1879, 0.1561, 0.1567, 0.1495], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2] [2, 3, 1, 2, 2, 0, 3, 3, 3, 0, 4, 1, 2, 0, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111162  [ 6464/61145]\n",
            "train tensor([0.1786, 0.1590, 0.1776, 0.1809, 0.1632, 0.1408], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2] [0, 4, 4, 0, 2, 1, 4, 2, 1, 3, 4, 1, 3, 3, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111667  [ 6480/61145]\n",
            "train tensor([0.1727, 0.1640, 0.1946, 0.1593, 0.1617, 0.1478], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2] [0, 2, 0, 4, 3, 2, 0, 0, 2, 4, 0, 0, 4, 4, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111457  [ 6496/61145]\n",
            "train tensor([0.1731, 0.1639, 0.1957, 0.1829, 0.1508, 0.1337], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 1, 0, 1, 2, 0, 2, 2, 3, 0, 0, 2, 2, 0, 0, 0] [4, 2, 1, 2, 1, 1, 3, 0, 3, 4, 1, 0, 2, 1, 3, 1]\n",
            "### lr:  3.1496033801483225e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111684  [ 6512/61145]\n",
            "train tensor([0.1797, 0.1589, 0.1890, 0.1573, 0.1644, 0.1508], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0] [2, 4, 3, 2, 0, 1, 4, 1, 3, 3, 1, 3, 0, 0, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111750  [ 6528/61145]\n",
            "train tensor([0.1795, 0.1920, 0.1847, 0.1673, 0.1425, 0.1339], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0] [2, 3, 0, 4, 2, 1, 4, 2, 0, 1, 3, 0, 2, 3, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111412  [ 6544/61145]\n",
            "train tensor([0.1861, 0.1648, 0.1878, 0.1607, 0.1617, 0.1389], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0] [3, 4, 2, 2, 0, 3, 3, 2, 2, 2, 3, 2, 0, 3, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111297  [ 6560/61145]\n",
            "train tensor([0.1944, 0.1675, 0.1916, 0.1624, 0.1461, 0.1380], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 3, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 3] [2, 0, 2, 2, 2, 0, 2, 4, 2, 1, 2, 3, 3, 1, 1, 1]\n",
            "### lr:  3.15254559521385e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111305  [ 6576/61145]\n",
            "train tensor([0.1829, 0.1515, 0.1978, 0.1640, 0.1610, 0.1428], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 0, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2] [4, 3, 3, 2, 0, 2, 2, 3, 3, 2, 3, 1, 2, 1, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111589  [ 6592/61145]\n",
            "train tensor([0.1903, 0.1696, 0.1826, 0.1577, 0.1548, 0.1449], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2] [3, 0, 3, 4, 4, 3, 0, 1, 4, 3, 0, 2, 3, 1, 1, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111869  [ 6608/61145]\n",
            "train tensor([0.1745, 0.1583, 0.1952, 0.1824, 0.1518, 0.1377], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2] [0, 2, 3, 0, 3, 1, 0, 3, 1, 3, 3, 1, 2, 0, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111435  [ 6624/61145]\n",
            "train tensor([0.1706, 0.1697, 0.1933, 0.1614, 0.1689, 0.1362], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0] [0, 2, 0, 4, 3, 3, 2, 2, 5, 3, 2, 2, 2, 0, 1, 0]\n",
            "### lr:  3.15551629680055e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111582  [ 6640/61145]\n",
            "train tensor([0.1733, 0.1664, 0.1824, 0.1759, 0.1585, 0.1436], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 0, 3, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2] [3, 0, 0, 0, 4, 2, 0, 4, 1, 4, 1, 2, 2, 2, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111394  [ 6656/61145]\n",
            "train tensor([0.1821, 0.1615, 0.1772, 0.1723, 0.1543, 0.1526], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "9 [0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2] [0, 2, 2, 2, 2, 2, 0, 1, 0, 3, 3, 0, 0, 2, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111008  [ 6672/61145]\n",
            "train tensor([0.1709, 0.1720, 0.1949, 0.1534, 0.1631, 0.1456], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0] [2, 3, 2, 0, 2, 0, 0, 3, 4, 2, 3, 0, 1, 2, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111170  [ 6688/61145]\n",
            "train tensor([0.1778, 0.1777, 0.1726, 0.1664, 0.1709, 0.1345], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 2, 2, 0, 3, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2] [2, 0, 3, 2, 4, 2, 1, 4, 3, 2, 1, 0, 3, 1, 4, 1]\n",
            "### lr:  3.1585154785682625e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111939  [ 6704/61145]\n",
            "train tensor([0.1719, 0.1670, 0.2057, 0.1678, 0.1506, 0.1371], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2] [2, 2, 1, 0, 4, 4, 3, 0, 3, 2, 3, 2, 0, 2, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111155  [ 6720/61145]\n",
            "train tensor([0.1725, 0.1638, 0.1918, 0.1688, 0.1606, 0.1425], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 0, 2, 2, 0] [3, 3, 3, 0, 0, 3, 2, 1, 4, 1, 0, 2, 4, 2, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111568  [ 6736/61145]\n",
            "train tensor([0.1792, 0.1687, 0.1854, 0.1561, 0.1726, 0.1380], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2] [3, 2, 2, 2, 2, 2, 2, 3, 3, 0, 4, 0, 1, 2, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111162  [ 6752/61145]\n",
            "train tensor([0.1822, 0.1680, 0.1817, 0.1619, 0.1620, 0.1441], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [0, 2, 0, 2, 2, 2, 2, 3, 0, 0, 2, 2, 2, 0, 2, 2] [2, 0, 3, 3, 2, 3, 1, 3, 3, 3, 1, 3, 4, 1, 3, 1]\n",
            "### lr:  3.161543134116053e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111711  [ 6768/61145]\n",
            "train tensor([0.1758, 0.1621, 0.1778, 0.1728, 0.1655, 0.1460], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 0, 2, 3, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2] [2, 5, 3, 2, 2, 0, 2, 3, 4, 2, 3, 4, 3, 0, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111741  [ 6784/61145]\n",
            "train tensor([0.1824, 0.1495, 0.1840, 0.1519, 0.1826, 0.1497], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 0, 2] [2, 4, 3, 2, 1, 4, 0, 2, 3, 2, 3, 2, 4, 2, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111540  [ 6800/61145]\n",
            "train tensor([0.1703, 0.1743, 0.2187, 0.1701, 0.1453, 0.1213], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "9 [2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2] [2, 2, 1, 2, 0, 0, 3, 2, 1, 3, 2, 2, 4, 0, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.110982  [ 6816/61145]\n",
            "train tensor([0.1721, 0.1672, 0.1806, 0.1662, 0.1727, 0.1412], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2] [4, 3, 1, 2, 2, 4, 3, 2, 4, 0, 3, 3, 0, 3, 2, 2]\n",
            "### lr:  3.164599256982212e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111509  [ 6832/61145]\n",
            "train tensor([0.1750, 0.1701, 0.1951, 0.1622, 0.1534, 0.1443], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2] [0, 0, 1, 0, 3, 3, 0, 0, 3, 4, 1, 4, 3, 1, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111704  [ 6848/61145]\n",
            "train tensor([0.1818, 0.1705, 0.1834, 0.1624, 0.1576, 0.1443], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [2, 3, 2, 4, 3, 2, 4, 2, 0, 3, 3, 4, 0, 4, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111482  [ 6864/61145]\n",
            "train tensor([0.1670, 0.1682, 0.1946, 0.1734, 0.1537, 0.1432], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2] [5, 2, 1, 2, 3, 0, 3, 3, 0, 0, 2, 0, 0, 3, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111612  [ 6880/61145]\n",
            "train tensor([0.1657, 0.1736, 0.1771, 0.1684, 0.1545, 0.1607], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 3, 4, 0, 3, 3, 2, 4, 3, 4, 0, 2, 0, 2, 3, 4]\n",
            "### lr:  3.1676838406442634e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111821  [ 6896/61145]\n",
            "train tensor([0.1802, 0.1598, 0.1778, 0.1640, 0.1696, 0.1486], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [0, 2, 2, 2, 2, 2, 3, 0, 2, 2, 2, 2, 2, 0, 0, 2] [0, 2, 0, 3, 2, 3, 2, 0, 0, 1, 0, 2, 1, 3, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111200  [ 6912/61145]\n",
            "train tensor([0.1650, 0.1532, 0.2050, 0.1584, 0.1620, 0.1565], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2] [2, 0, 3, 4, 1, 1, 0, 0, 2, 0, 3, 2, 2, 2, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111480  [ 6928/61145]\n",
            "train tensor([0.1799, 0.1598, 0.1843, 0.1560, 0.1744, 0.1455], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 3, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 2, 1, 2, 2] [0, 2, 4, 3, 2, 3, 3, 4, 2, 1, 4, 3, 1, 4, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111884  [ 6944/61145]\n",
            "train tensor([0.1739, 0.1649, 0.1961, 0.1657, 0.1605, 0.1388], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 3, 2, 2, 2, 4, 2, 2, 2, 0, 2, 2, 2, 2, 2] [3, 2, 0, 4, 3, 0, 4, 1, 0, 4, 0, 4, 0, 2, 2, 2]\n",
            "### lr:  3.170796878519017e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111317  [ 6960/61145]\n",
            "train tensor([0.1738, 0.1758, 0.1838, 0.1849, 0.1458, 0.1359], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [3, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2] [2, 2, 3, 2, 3, 3, 3, 1, 3, 0, 4, 0, 2, 1, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111457  [ 6976/61145]\n",
            "train tensor([0.1724, 0.1768, 0.1885, 0.1748, 0.1464, 0.1411], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2] [2, 1, 4, 2, 1, 4, 3, 4, 2, 1, 2, 1, 1, 4, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111702  [ 6992/61145]\n",
            "train tensor([0.1823, 0.1566, 0.1792, 0.1703, 0.1644, 0.1473], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 0, 2, 2, 2, 0, 2, 3, 3, 2, 2, 2, 2, 2, 4, 2] [1, 4, 0, 2, 0, 1, 3, 1, 4, 1, 1, 3, 2, 0, 4, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111630  [ 7008/61145]\n",
            "train tensor([0.1674, 0.1660, 0.2016, 0.1644, 0.1532, 0.1475], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 3, 4, 3, 0, 1, 1, 2, 2, 2, 2, 3, 0, 3, 0, 2]\n",
            "### lr:  3.173938363962528e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111344  [ 7024/61145]\n",
            "train tensor([0.1709, 0.1579, 0.2058, 0.1683, 0.1637, 0.1334], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 0, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2] [3, 1, 3, 3, 2, 3, 2, 0, 2, 4, 0, 3, 1, 3, 4, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111683  [ 7040/61145]\n",
            "train tensor([0.1879, 0.1487, 0.1916, 0.1820, 0.1556, 0.1342], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1] [4, 4, 3, 1, 2, 1, 0, 4, 0, 1, 1, 3, 2, 2, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111397  [ 7056/61145]\n",
            "train tensor([0.1825, 0.1603, 0.1885, 0.1608, 0.1670, 0.1408], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 1, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 4, 0, 2, 2] [2, 3, 4, 0, 2, 2, 2, 0, 0, 1, 4, 4, 0, 3, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111508  [ 7072/61145]\n",
            "train tensor([0.1879, 0.1549, 0.1950, 0.1552, 0.1544, 0.1526], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2] [2, 3, 3, 4, 2, 0, 2, 1, 2, 0, 3, 4, 4, 0, 1, 3]\n",
            "### lr:  3.177108290270146e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111489  [ 7088/61145]\n",
            "train tensor([0.1874, 0.1583, 0.1836, 0.1592, 0.1608, 0.1507], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2] [2, 3, 2, 3, 0, 4, 0, 0, 1, 4, 1, 4, 4, 4, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111805  [ 7104/61145]\n",
            "train tensor([0.1860, 0.1496, 0.2028, 0.1694, 0.1574, 0.1348], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 3, 2] [3, 3, 1, 3, 1, 0, 4, 3, 2, 0, 3, 2, 3, 3, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111725  [ 7120/61145]\n",
            "train tensor([0.1912, 0.1642, 0.1822, 0.1666, 0.1491, 0.1466], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1] [3, 1, 2, 2, 2, 4, 2, 0, 0, 4, 2, 2, 3, 3, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111442  [ 7136/61145]\n",
            "train tensor([0.1818, 0.1662, 0.1886, 0.1617, 0.1601, 0.1416], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "8 [2, 2, 2, 2, 2, 0, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2] [0, 0, 4, 1, 1, 3, 0, 2, 3, 2, 2, 2, 2, 2, 2, 4]\n",
            "### lr:  3.1803066506765287e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111184  [ 7152/61145]\n",
            "train tensor([0.1961, 0.1702, 0.1764, 0.1690, 0.1498, 0.1385], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 0, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 0, 0] [3, 3, 2, 3, 4, 0, 3, 3, 0, 4, 2, 2, 2, 0, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111541  [ 7168/61145]\n",
            "train tensor([0.1750, 0.1718, 0.1792, 0.1671, 0.1685, 0.1384], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2] [1, 3, 0, 0, 4, 2, 4, 2, 2, 0, 2, 2, 0, 0, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111063  [ 7184/61145]\n",
            "train tensor([0.1764, 0.1549, 0.1943, 0.1723, 0.1498, 0.1522], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0] [0, 4, 2, 3, 0, 2, 2, 3, 2, 0, 0, 0, 0, 1, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111561  [ 7200/61145]\n",
            "train tensor([0.1669, 0.1634, 0.1956, 0.1691, 0.1612, 0.1438], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2] [0, 3, 0, 3, 2, 0, 4, 2, 2, 3, 2, 0, 2, 1, 4, 4]\n",
            "### lr:  3.1835334383556417e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111549  [ 7216/61145]\n",
            "train tensor([0.1757, 0.1633, 0.1895, 0.1671, 0.1608, 0.1436], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 0, 1, 2, 2, 2, 3, 0, 2, 2, 2, 3, 0, 2] [1, 4, 3, 2, 0, 3, 2, 2, 4, 4, 2, 1, 3, 3, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111474  [ 7232/61145]\n",
            "train tensor([0.1914, 0.1736, 0.1729, 0.1787, 0.1520, 0.1314], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 3, 2, 2] [0, 0, 1, 0, 4, 1, 3, 3, 0, 2, 2, 4, 2, 2, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111320  [ 7248/61145]\n",
            "train tensor([0.1607, 0.1709, 0.1909, 0.1755, 0.1560, 0.1460], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2] [3, 1, 0, 4, 2, 4, 2, 1, 2, 1, 4, 3, 2, 1, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111668  [ 7264/61145]\n",
            "train tensor([0.1754, 0.1618, 0.1995, 0.1617, 0.1604, 0.1411], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 0, 2, 2, 2, 2, 2] [0, 3, 3, 1, 4, 3, 3, 2, 0, 1, 4, 3, 0, 2, 4, 1]\n",
            "### lr:  3.186788646420781e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.112067  [ 7280/61145]\n",
            "train tensor([0.1738, 0.1588, 0.2053, 0.1871, 0.1391, 0.1358], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2] [4, 0, 4, 2, 4, 1, 4, 0, 2, 2, 4, 2, 2, 3, 4, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111959  [ 7296/61145]\n",
            "train tensor([0.1785, 0.1642, 0.1845, 0.1771, 0.1566, 0.1391], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2] [0, 3, 0, 0, 3, 2, 0, 0, 2, 2, 2, 4, 2, 3, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111465  [ 7312/61145]\n",
            "train tensor([0.1676, 0.1691, 0.1997, 0.1684, 0.1465, 0.1488], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2] [3, 2, 1, 3, 3, 0, 3, 0, 2, 1, 3, 2, 3, 0, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111556  [ 7328/61145]\n",
            "train tensor([0.1713, 0.1671, 0.2144, 0.1677, 0.1336, 0.1459], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2] [2, 4, 0, 3, 0, 2, 1, 3, 3, 3, 4, 2, 4, 4, 2, 3]\n",
            "### lr:  3.190072267924586e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111423  [ 7344/61145]\n",
            "train tensor([0.1768, 0.1794, 0.1767, 0.1701, 0.1572, 0.1399], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 0, 2] [1, 2, 3, 0, 2, 1, 2, 2, 0, 5, 3, 1, 0, 0, 2, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111716  [ 7360/61145]\n",
            "train tensor([0.1703, 0.1617, 0.1949, 0.1783, 0.1586, 0.1362], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2] [3, 0, 2, 3, 0, 4, 2, 2, 1, 4, 3, 3, 4, 2, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111479  [ 7376/61145]\n",
            "train tensor([0.1788, 0.1642, 0.1851, 0.1632, 0.1696, 0.1391], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2] [2, 3, 4, 3, 3, 3, 2, 2, 1, 0, 2, 3, 2, 3, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111580  [ 7392/61145]\n",
            "train tensor([0.1655, 0.1630, 0.1992, 0.1664, 0.1554, 0.1505], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0] [3, 3, 2, 2, 2, 1, 1, 4, 3, 0, 4, 2, 2, 4, 1, 1]\n",
            "### lr:  3.1933842958590584e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111662  [ 7408/61145]\n",
            "train tensor([0.1792, 0.1668, 0.1840, 0.1608, 0.1604, 0.1489], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 2, 0, 4, 3, 0, 1, 0, 0, 3, 2, 3, 3, 0, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111779  [ 7424/61145]\n",
            "train tensor([0.1881, 0.1609, 0.1855, 0.1603, 0.1621, 0.1431], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2] [3, 2, 2, 1, 0, 3, 2, 2, 3, 4, 4, 4, 1, 2, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111804  [ 7440/61145]\n",
            "train tensor([0.1789, 0.1736, 0.1913, 0.1758, 0.1387, 0.1417], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [2, 3, 2, 0, 0, 0, 1, 3, 2, 3, 3, 4, 0, 2, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111294  [ 7456/61145]\n",
            "train tensor([0.1870, 0.1711, 0.1805, 0.1657, 0.1534, 0.1423], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2] [3, 0, 1, 2, 4, 3, 3, 0, 0, 0, 0, 0, 1, 3, 2, 4]\n",
            "### lr:  3.1967247231555765e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111534  [ 7472/61145]\n",
            "train tensor([0.1767, 0.1704, 0.1819, 0.1624, 0.1614, 0.1472], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "1 [2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2] [0, 3, 1, 0, 3, 0, 3, 1, 1, 1, 2, 4, 3, 3, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111887  [ 7488/61145]\n",
            "train tensor([0.1740, 0.1668, 0.1909, 0.1654, 0.1555, 0.1474], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2] [2, 4, 2, 2, 0, 2, 3, 2, 0, 3, 3, 2, 0, 2, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111263  [ 7504/61145]\n",
            "train tensor([0.1847, 0.1813, 0.1836, 0.1549, 0.1604, 0.1351], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 3, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [4, 3, 3, 2, 0, 3, 4, 2, 0, 1, 1, 0, 0, 0, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111421  [ 7520/61145]\n",
            "train tensor([0.1798, 0.1598, 0.2055, 0.1619, 0.1562, 0.1367], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2] [2, 0, 2, 0, 1, 2, 1, 2, 4, 4, 2, 3, 2, 1, 0, 4]\n",
            "### lr:  3.200093542684901e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111186  [ 7536/61145]\n",
            "train tensor([0.1776, 0.1675, 0.1887, 0.1776, 0.1499, 0.1387], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2] [0, 0, 0, 2, 2, 0, 1, 4, 0, 2, 3, 2, 0, 0, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111194  [ 7552/61145]\n",
            "train tensor([0.1742, 0.1644, 0.2033, 0.1704, 0.1599, 0.1278], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3] [4, 1, 3, 0, 0, 4, 0, 2, 0, 0, 2, 3, 0, 2, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111364  [ 7568/61145]\n",
            "train tensor([0.1838, 0.1558, 0.1896, 0.1714, 0.1463, 0.1531], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2] [1, 4, 0, 2, 3, 2, 3, 1, 3, 1, 3, 4, 0, 1, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111829  [ 7584/61145]\n",
            "train tensor([0.1715, 0.1748, 0.1759, 0.1686, 0.1637, 0.1455], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 1, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2] [4, 1, 3, 3, 4, 3, 4, 3, 0, 1, 3, 2, 0, 2, 4, 2]\n",
            "### lr:  3.203490747257201e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111723  [ 7600/61145]\n",
            "train tensor([0.1637, 0.1659, 0.1862, 0.1807, 0.1654, 0.1380], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 0] [4, 0, 3, 3, 0, 3, 2, 0, 5, 3, 2, 1, 0, 2, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111407  [ 7616/61145]\n",
            "train tensor([0.1799, 0.1771, 0.1849, 0.1715, 0.1512, 0.1354], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 3, 2, 0, 2, 2, 0, 2, 0, 0, 2, 3, 2, 2, 2] [3, 2, 0, 3, 4, 3, 2, 2, 0, 2, 3, 4, 2, 2, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111512  [ 7632/61145]\n",
            "train tensor([0.1890, 0.1505, 0.2033, 0.1723, 0.1493, 0.1357], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2] [3, 3, 4, 1, 4, 2, 2, 1, 4, 4, 0, 4, 0, 1, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111829  [ 7648/61145]\n",
            "train tensor([0.1908, 0.1701, 0.1872, 0.1763, 0.1501, 0.1256], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0] [0, 0, 2, 2, 2, 2, 3, 0, 3, 4, 1, 0, 1, 2, 4, 4]\n",
            "### lr:  3.20691632962206e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111415  [ 7664/61145]\n",
            "train tensor([0.1683, 0.1658, 0.1836, 0.1751, 0.1689, 0.1383], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2] [4, 3, 2, 3, 2, 0, 0, 0, 3, 0, 0, 4, 3, 3, 3, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111591  [ 7680/61145]\n",
            "train tensor([0.1752, 0.1667, 0.1971, 0.1684, 0.1591, 0.1336], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 0, 0, 3, 2] [4, 2, 1, 0, 3, 3, 0, 3, 0, 2, 2, 0, 4, 1, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111048  [ 7696/61145]\n",
            "train tensor([0.1783, 0.1755, 0.1895, 0.1627, 0.1519, 0.1422], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 1, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0] [1, 1, 0, 0, 2, 0, 2, 3, 2, 3, 1, 4, 4, 0, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111333  [ 7712/61145]\n",
            "train tensor([0.1730, 0.1718, 0.1745, 0.1691, 0.1594, 0.1521], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2] [0, 1, 0, 3, 2, 2, 3, 4, 4, 2, 3, 0, 3, 0, 0, 3]\n",
            "### lr:  3.210370282468513e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111054  [ 7728/61145]\n",
            "train tensor([0.1731, 0.1610, 0.2030, 0.1691, 0.1472, 0.1465], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 2, 3, 2, 2] [4, 0, 1, 0, 3, 0, 0, 4, 4, 4, 1, 3, 0, 1, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111789  [ 7744/61145]\n",
            "train tensor([0.1728, 0.1713, 0.1928, 0.1541, 0.1648, 0.1442], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2] [2, 0, 4, 2, 4, 0, 4, 3, 2, 1, 2, 0, 2, 0, 1, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111451  [ 7760/61145]\n",
            "train tensor([0.1801, 0.1676, 0.1895, 0.1648, 0.1635, 0.1345], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [2, 2, 0, 0, 0, 3, 3, 3, 4, 2, 3, 3, 4, 3, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111459  [ 7776/61145]\n",
            "train tensor([0.1800, 0.1827, 0.1812, 0.1770, 0.1480, 0.1311], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 2, 2, 3, 2, 2, 4, 3, 2, 4, 2, 0, 3, 0, 2, 3]\n",
            "### lr:  3.2138525984250217e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111130  [ 7792/61145]\n",
            "train tensor([0.1639, 0.1675, 0.1775, 0.1832, 0.1575, 0.1504], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2] [2, 2, 1, 0, 2, 0, 3, 2, 3, 4, 2, 2, 2, 0, 2, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111391  [ 7808/61145]\n",
            "train tensor([0.1788, 0.1648, 0.1735, 0.1765, 0.1655, 0.1409], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2] [3, 0, 2, 0, 1, 4, 0, 0, 2, 3, 2, 2, 0, 3, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111314  [ 7824/61145]\n",
            "train tensor([0.1617, 0.1780, 0.1904, 0.1703, 0.1631, 0.1367], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0] [2, 0, 3, 3, 0, 2, 4, 3, 2, 2, 4, 3, 2, 2, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111173  [ 7840/61145]\n",
            "train tensor([0.2072, 0.1701, 0.1921, 0.1582, 0.1516, 0.1207], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 3, 2, 3, 2] [0, 3, 3, 2, 1, 2, 2, 4, 3, 0, 2, 3, 4, 2, 1, 0]\n",
            "### lr:  3.217363270059538e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111373  [ 7856/61145]\n",
            "train tensor([0.1817, 0.1647, 0.1916, 0.1702, 0.1505, 0.1412], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2] [0, 3, 3, 3, 2, 3, 0, 4, 0, 2, 2, 0, 4, 3, 1, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111332  [ 7872/61145]\n",
            "train tensor([0.1725, 0.1696, 0.1846, 0.1687, 0.1616, 0.1432], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [2, 2, 1, 2, 1, 3, 3, 0, 3, 2, 2, 4, 3, 4, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111478  [ 7888/61145]\n",
            "train tensor([0.1739, 0.1722, 0.1854, 0.1605, 0.1642, 0.1438], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0] [1, 1, 2, 3, 0, 0, 3, 0, 0, 3, 0, 4, 3, 0, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111564  [ 7904/61145]\n",
            "train tensor([0.1810, 0.1688, 0.1649, 0.1631, 0.1825, 0.1397], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [4, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2] [4, 3, 2, 3, 0, 3, 2, 3, 4, 2, 1, 1, 3, 3, 0, 0]\n",
            "### lr:  3.2209022898794744e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111529  [ 7920/61145]\n",
            "train tensor([0.1618, 0.1631, 0.1911, 0.1657, 0.1676, 0.1506], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [2, 2, 3, 2, 3, 0, 1, 2, 2, 2, 0, 3, 0, 4, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111184  [ 7936/61145]\n",
            "train tensor([0.1768, 0.1609, 0.1932, 0.1776, 0.1520, 0.1394], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 0, 2] [4, 4, 4, 0, 0, 2, 3, 0, 0, 2, 4, 1, 2, 2, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111428  [ 7952/61145]\n",
            "train tensor([0.1778, 0.1498, 0.1854, 0.1693, 0.1664, 0.1512], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2] [2, 0, 3, 2, 2, 0, 0, 3, 3, 2, 2, 2, 2, 3, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111426  [ 7968/61145]\n",
            "train tensor([0.1642, 0.1570, 0.2073, 0.1696, 0.1516, 0.1504], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 0] [2, 3, 2, 2, 0, 3, 4, 4, 0, 2, 2, 4, 2, 0, 3, 1]\n",
            "### lr:  3.2244696503317667e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111748  [ 7984/61145]\n",
            "train tensor([0.1556, 0.1627, 0.1969, 0.1897, 0.1575, 0.1376], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 1, 2, 2, 2, 2, 3, 0, 3, 2, 2, 0, 2, 2, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111034  [ 8000/61145]\n",
            "train tensor([0.1693, 0.1678, 0.1920, 0.1813, 0.1520, 0.1376], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [4, 0, 0, 3, 3, 1, 4, 0, 2, 2, 2, 0, 1, 2, 3, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111451  [ 8016/61145]\n",
            "train tensor([0.1846, 0.1593, 0.1975, 0.1712, 0.1475, 0.1398], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2] [0, 2, 3, 1, 4, 1, 1, 2, 3, 2, 2, 3, 2, 0, 0, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111095  [ 8032/61145]\n",
            "train tensor([0.1864, 0.1652, 0.1848, 0.1708, 0.1633, 0.1295], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0] [0, 0, 3, 4, 0, 0, 0, 3, 2, 0, 2, 1, 4, 2, 2, 3]\n",
            "### lr:  3.228065343802838e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111552  [ 8048/61145]\n",
            "train tensor([0.1709, 0.1643, 0.1902, 0.1805, 0.1531, 0.1409], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0] [0, 5, 0, 0, 2, 4, 4, 2, 4, 0, 2, 0, 0, 0, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111470  [ 8064/61145]\n",
            "train tensor([0.1742, 0.1670, 0.2008, 0.1842, 0.1428, 0.1310], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2] [0, 3, 0, 2, 3, 4, 3, 2, 1, 2, 1, 3, 4, 3, 0, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111583  [ 8080/61145]\n",
            "train tensor([0.1744, 0.1570, 0.1741, 0.1906, 0.1604, 0.1435], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2] [2, 4, 0, 3, 2, 0, 2, 4, 1, 0, 3, 4, 2, 3, 2, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111433  [ 8096/61145]\n",
            "train tensor([0.1812, 0.1709, 0.1900, 0.1782, 0.1495, 0.1302], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2] [0, 0, 3, 2, 2, 2, 2, 2, 4, 3, 0, 4, 0, 2, 0, 1]\n",
            "### lr:  3.231689362618667e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111006  [ 8112/61145]\n",
            "train tensor([0.1834, 0.1744, 0.1932, 0.1629, 0.1560, 0.1301], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0] [2, 2, 2, 0, 4, 2, 4, 2, 1, 1, 2, 2, 1, 4, 1, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111324  [ 8128/61145]\n",
            "train tensor([0.1674, 0.1651, 0.2018, 0.1803, 0.1536, 0.1318], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [0, 3, 2, 2, 2, 2, 2, 4, 4, 2, 4, 2, 0, 4, 3, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111123  [ 8144/61145]\n",
            "train tensor([0.1760, 0.1602, 0.1857, 0.1571, 0.1744, 0.1465], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0] [2, 3, 2, 2, 4, 3, 2, 1, 3, 2, 0, 3, 0, 1, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111172  [ 8160/61145]\n",
            "train tensor([0.1739, 0.1475, 0.2153, 0.1728, 0.1499, 0.1406], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 1, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0] [2, 5, 0, 4, 1, 3, 3, 0, 0, 0, 2, 4, 2, 3, 1, 2]\n",
            "### lr:  3.235341699044759e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111502  [ 8176/61145]\n",
            "train tensor([0.1824, 0.1698, 0.1899, 0.1711, 0.1590, 0.1278], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0] [2, 1, 2, 3, 4, 0, 3, 3, 2, 3, 3, 2, 2, 2, 2, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111008  [ 8192/61145]\n",
            "train tensor([0.1685, 0.1591, 0.1839, 0.1765, 0.1736, 0.1384], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "5 [2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2] [2, 3, 4, 0, 4, 2, 4, 1, 2, 2, 3, 0, 2, 0, 0, 4]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111626  [ 8208/61145]\n",
            "train tensor([0.1835, 0.1672, 0.1764, 0.1724, 0.1601, 0.1404], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [0, 1, 1, 2, 1, 0, 3, 3, 1, 3, 0, 4, 4, 4, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111816  [ 8224/61145]\n",
            "train tensor([0.1593, 0.1661, 0.2022, 0.1851, 0.1350, 0.1523], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 3, 4, 3, 2, 1, 0, 3, 3, 3, 2, 2, 3, 2, 0, 4]\n",
            "### lr:  3.2390223452861954e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111487  [ 8240/61145]\n",
            "train tensor([0.1720, 0.1588, 0.1866, 0.1759, 0.1570, 0.1496], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "2 [2, 2, 2, 3, 0, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2] [0, 3, 4, 4, 2, 0, 0, 2, 2, 1, 4, 1, 1, 2, 3, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111661  [ 8256/61145]\n",
            "train tensor([0.1810, 0.1635, 0.1851, 0.1741, 0.1524, 0.1438], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2] [3, 2, 2, 4, 4, 4, 2, 1, 1, 2, 1, 2, 0, 0, 0, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111459  [ 8272/61145]\n",
            "train tensor([0.1758, 0.1620, 0.1935, 0.1725, 0.1500, 0.1462], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "7 [2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [4, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 0, 2, 2, 0, 1]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111166  [ 8288/61145]\n",
            "train tensor([0.1753, 0.1594, 0.1997, 0.1642, 0.1701, 0.1314], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "3 [2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0] [3, 3, 4, 2, 1, 0, 4, 3, 4, 2, 3, 0, 2, 2, 1, 3]\n",
            "### lr:  3.242731293487644e-07\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111862  [ 8304/61145]\n",
            "train tensor([0.1716, 0.1692, 0.1918, 0.1619, 0.1636, 0.1418], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 3, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0] [0, 2, 0, 4, 3, 3, 2, 3, 4, 3, 0, 0, 0, 1, 4, 0]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111272  [ 8320/61145]\n",
            "train tensor([0.1819, 0.1719, 0.1927, 0.1640, 0.1490, 0.1405], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "6 [2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2] [4, 1, 2, 4, 3, 4, 2, 4, 2, 3, 2, 4, 0, 0, 2, 2]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111281  [ 8336/61145]\n",
            "train tensor([0.1770, 0.1672, 0.2011, 0.1614, 0.1649, 0.1285], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "4 [2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0] [2, 3, 0, 4, 2, 0, 2, 3, 0, 3, 2, 0, 1, 0, 4, 3]\n",
            "tensor(-0.0045, device='cuda:0')\n",
            "loss: 0.111541  [ 8352/61145]\n",
            "train "
          ]
        }
      ],
      "source": [
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "# scheduler = PolynomialLR(optimizer, total_iters=4, power=1.0)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=10**(-1/2))\n",
        "# for epoch in range(5):\n",
        "#     scheduler.step()\n",
        "for t in range(tp,epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    lr=optimizer.param_groups[0][\"lr\"]\n",
        "    print(lr)\n",
        "    train_ls = strain(train_loader, model, loss_fn, optimizer, scheduler)\n",
        "    # train_ls = strain(train_loader, model, loss_fn, optimizer)\n",
        "    correct, test_loss = test(test_loader, model, loss_fn)\n",
        "    train_lst.extend(train_ls)\n",
        "    test_lst.append(test_loss)\n",
        "    acc_lst.append(correct)\n",
        "\n",
        "    # checkpoint = { # https://discuss.pytorch.org/t/saving-model-and-optimiser-and-scheduler/52030\n",
        "    # 'epoch': t+1,\n",
        "    # 'model': model.state_dict(),\n",
        "    # 'optimizer': optimizer.state_dict(),\n",
        "    # 'lr_sched': scheduler.state_dict()}\n",
        "    # torch.save(checkpoint, pth)\n",
        "    # # torch.save(model.state_dict(), pth)\n",
        "\n",
        "# print(\"Done!\")\n",
        "\n",
        "# end = time.time()\n",
        "# print(\"time: \",end - start)\n",
        "\n",
        "# print(len(train_lst), len(test_lst))\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(train_lst)\n",
        "# plt.plot(np.linspace(0,len(train_lst),len(test_lst)), test_lst)\n",
        "# plt.show()\n",
        "# plt.plot(acc_lst)\n",
        "# plt.show()\n",
        "# plt.close()\n",
        "\n",
        "\n",
        "# torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "# resnet 18, 60/61 38.4%, 528s\n",
        "# resnet 18, 58/61 39.8%, 523s\n",
        "# resnet 18 compile , 58/61 40.4%, 555s\n",
        "# resnet 18 compile augment , 58/61 36.4%, 1941 # augment on cpu, takes longer\n",
        "# resnet 18 augment lr3e-4:3e-3, 58/61 37.7%, 1863s\n",
        "# resnet 18 augment 10epoch lr1e-5:3e-4, 58/61 33.5%, 3387s\n",
        "# resnet 18 compile lr1e-5:3e-4, 58/61 35.0%, 493s\n",
        "# resnet 18 compile scratch lr1e-5:1e-3, 58/61 26.8%, 475s\n",
        "# resnet 18 compile lr1e-5:1e-3, 55/61 47.3%, 480s\n",
        "# resnet 18 compile lr1e-5:1e-3, 52/61 51.7% 503s\n",
        "# resnet 18 compile lr1e-5:1e-3, unfreeze 51.0%, 550s\n",
        "# resnet 18 compile lr1e-5:1e-4, unfreeze 52.7%, 518s\n",
        "# resnet 34 compile lr1e-5:1e-4, unfreeze bitsadamW batch16*4\n",
        "# resnet 152 compileoverhead lr3e-7:3e-6, bitsadamW batch16*4 ckpt 53.8%, 2066s\n",
        "# resnet 152 from53.8% augment+cutout lr3e-7:3e-6, 53.8%, 2088s\n",
        "# resnet 152 comile augment+cutout lr1e-5 /4 1epoch 48.3%, 454s\n",
        "# resnet 152 comile augment+cutout lr1e-5 1epoch 48.4%, 446s\n",
        "# resnet 152 comilemaxautotue augment+cutout lr1e-5 1epoch 47.7%, 448\n",
        "# resnet 152 clipclean comilemax augment+cutout lr1e-5 10epoch 45.1%, 1585 *2\n",
        "# resnet 152 clipclean comilemax augmax lr1e-6:3e-5 20epoch\n",
        "# resnet 152 clipclean compilemax lr3e-7:1e-5,\n",
        "# resnet 152 70k augment compilemax lr3e-7:3e-6 5epoch, 65.4% 11585s*5/3=19300s = 5h20m\n",
        "\n",
        "# resnet 152 70k augment compile adamw const lr3e-6, 59.8%\n",
        "# resnet 152 70k augment compile adamw const3e-6 stepdown\n",
        "\n",
        "\n",
        "\n",
        "# resnet 152 70k augment compile lamb lr1e-2 not learning\n",
        "# resnet 152 70k augment compile lamb lr3e-3 not learning\n",
        "# resnet 152 70k augment compile lamb lr1e-3:1e-2 5epoch,\n",
        "# 2/5epochwarmup 55.0%\n",
        "\n",
        "# resnet 152 70kg augment1 cut1,-1 compilemax adamw lr3e-7:3e-6 1/5epoch 31.1% ty\n",
        "# resnet 152 70k augment1 cut1,-1 compilemax adamw lr3e-7:3e-6 1/5epoch 28.1% A\n",
        "\n",
        "# resnet 152 70k dataold augment1 cut1,0 compilemax adamw lr3e-7:3e-6 M nantest\n",
        "# resnet 152 70kg augment1 cut1,0 compilemax adamw lr3e-7:3e-6 B\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# vit b16 lr1e-5 5epochs 41.3%, 466s # 4.4ram, 5.5vram\n",
        "# vit l16 lr1e-5 5epochs # 32.0%, 1242s 4.5ram, 8.0vram\n",
        "# vit l16 lr3e-7;1e-5 5epochs # 45.4%, 1315s 4.5ram, 8.0vram\n",
        "# vit l32 lr1e-5 5epochs # .ram, .vram\n",
        "# vit_large_patch16_384\n",
        "# vit_base_patch16_224 maxcompile nockpt lr3e-7;1e-5 5epochs # 45.2%, 2272s 5.3ram, 11.0vram\n",
        "# vit_base_patch16_224 maxcompile nockpt gradacc batch16 1e-5, 1e-2 explode\n",
        "# vit_base_patch16_224 maxcompile nockpt gradacc batch16 1e-6, 1e-5 low acc, test nan\n",
        "# vit_base_patch16_224 maxcompile nockpt gradacc batch16 3e-7, 3e-6 4/5 epoch50%\n",
        "# vit_base_patch16_224 maxcompile nockpt gradacc batch16 1e-6, 1e-5 0.5aug\n",
        "\n",
        "\n",
        "\n",
        "# inception\n",
        "# inception og 10kclean 1e-7, 3e-5 batch64 nockpt 5epochs 0.020348  51.4%, 0.024312 20m; 1st 40.5% max 52.1\n",
        "# inception hid 10kclean 1e-7, 3e-5 batch64 nockpt 1/5epochs 0.019635 53.6%, 0.024120 1st 32.8%, max 53.6%\n",
        "# inception og 10kclean 1e-7, 1e-4 batch64 nockpt 2/10epochs 0.020348  0.020923 39.9%, 0.026105\n",
        "# inception og 70kg 1e-7 nope\n",
        "# inception og 70kg 3e-6 3e-5 17%\n",
        "# inception og 70kg 1e-6, 1e-5\n",
        "# inception og 70kg 3e-6 3e-5 0.5aug\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86I4ghMp-dgP",
        "outputId": "6e0370b7-d4bd-4010-e57f-76f296b4b3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0009999999999999992\n"
          ]
        }
      ],
      "source": [
        "scheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer, total_iters=4, power=1.0)\n",
        "for epoch in range(100):\n",
        "    print(optimizer.param_groups[0][\"lr\"])\n",
        "    scheduler.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFsnIRVz7Xp5",
        "outputId": "79e6e4af-e296-4b74-a985-4898ed03df7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 49.1%, Avg loss: 1.536100\n",
            "0.4909090909090909 1.5360995966654558\n"
          ]
        }
      ],
      "source": [
        "correct, test_loss = test(test_loader, model, loss_fn)\n",
        "print(correct, test_loss)\n",
        "\n",
        "# # https://discuss.pytorch.org/t/model-predictions-changing-with-no-grad-and-eval/126543/2\n",
        "# self.drop_layer = nn.Dropout(p = .5)\n",
        "# out = F.dropout(x, training=self.training)\n",
        "# # https://discuss.pytorch.org/t/trained-resnet-doesnt-work-in-eval-mode-behaves-strangely/121242/8\n",
        "# self.bn = torch.nn.BatchNorm2d(input_features,track_running_stats=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyVU_i594fMh",
        "outputId": "34e9f18d-c411-4b90-bd36-521188a7de3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6794\n",
            "425\n"
          ]
        }
      ],
      "source": [
        "print(len(test_loader.dataset))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "GWt4B_YoCxKB",
        "outputId": "e4a16890-8621-4273-8e9c-b59e0a5b9dd8",
        "cellView": "form"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbsAAAHACAYAAAA7jMYcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+2klEQVR4nO3dd1gU1xrA4d9SBaxUe++xoKLYe6LG2DX2rlFjx95bIkZj7733GntDsSsKCqiIqLEkShe7SNn7BzerKwuyuCu6+733mee5nP3mzPkywtlz5syMQqlUKhFCCCEMmElaN0AIIYTQN+nshBBCGDzp7IQQQhg86eyEEEIYPOnshBBCGDzp7IQQQhg86eyEEEIYPOnshBBCGDzp7IQQQhg8s7RugD68WeGW1k3QqfZT7qR1E3TK//W/ad0EnXnyKjKtm6BTsfFxad0EnVJiOA+Iin77SKf1xYTf01ld5vb5dVaXvhhkZyeEEOITDOyLzafINKYQQgiDJyM7IYQwRsr4tG7BFyWdnRBCGKN44+rsZBpTCCGEwZORnRBCGCGlTGMKIYQweDKNKYQQQhgWGdkJIYQxkmlMIYQQBk9uKhdCCCEMi4zshBDCGMk0phBCCIMnqzGFEEIIwyIjOyGEMEJyU7kQQgjDJ9OYQgghhGGRkZ0QQhgjmcYUQghh8OSmciGEEMKwyMhOCCGMkUxjCiGEMHiyGlMIIYQwLDKyE0IIYyTTmEIIIQyeTGMary0+92mw9AQVZh2iw4Zz+D+JSjb++dsYph67Tt1Fxyk/6xCNV3hy5l6o6vOVF+/Qbv1ZKs85TK2Fxxi0+wr3I1/qOYsE9Tv9yJKzy9kSuINpe2ZQsHShJGNzFcrFsCUjWXJ2Obse7OWnbo0TxZiYmNB2SHsWn13O5sDtLDq9lFYDWuszBTXtu7XipPc+rj86z47DaylV5rtk4+s3rsvh8zu5/ug8+09tpUbdKmqf2znY8sf8iZz1P4zfg3Os3DqfPPlz6TMFNb/06siNgDOER97i5KndlHMpnWx8s2Y/4nP1OOGRt7jkdYgf6tVMMnbuvN94+fpvfu3bVcet1qxXr04EBp4jKuo2p0//hcsncmnevCG+vieIirrNlStHqVevltrnY8cOxtf3BBERt3jyxJ+DBzdRvryzHjNQ17tXZwIDz/MsKogzp/fi4pL8sZs3b4if70meRQXhfeUY9TXk4+d7ksiIQIKf+HPoC+cjEkhn939Hbj1mpmcAvSoXYnOnqhR2yMCv2y8R+SpaY3xMXDy9t1/i8fPXzGhclj3dazC+Xkkc06dTxXg/iqR1mTys61CFJa1ciY2Pp892L968i9VrLlV+qkrXsd3ZNncLQ38azP2A+4xfP4lMdpk0xltaWRLyMJj1f6zjaWikxphmfVpQr0MDVoxfyoA6fVk/bS1NezXjxy4/6TMVAH5s+j2jJ7ux4M9lNK3TnoAbt1m1bQG29lk0xpcpX4rZS39nx8Y9NKndjuOHPFm0diaFihZQxSxeO5NceXLQp6MbTWq34/GjJ6zdsRgr63Qa69SlFi0a4j5tDO5T51K18k9c9w9gz19rcXCw0xjv6lqW1WvnsnbtNqpUasj+/cfYsnUpxYsXThTbqPEPlK9QhsePg/WdBgAtWzZi+vRx/P77HCpWbIi/fwD79m1IMpeKFcuxbt181qzZiqvrj+zbd4Tt25er5RIUdI/Bg8fj4vIDtWu34MGDR+zfvwF7e9svmo9rxR/x97/J/n3rk81n/boFrFmzBVfXBuzdd4Tt21dQvHiRD/L5m0GDx1HO5Xtq1W7B/Qf/cGD/xi+ST3KUyjidbd8ChVKpVKZ1I3TtzQo3rffpsOEc32XNxKi6JQCIVyqpt8SDtmXz0s21YKL47dcesNbrHru718DcNGXfGSJfR1N74XFWtqlIuVyaf3k0aT/lTopjAabtmcEdvzusGL8UAIVCwbKLqzi4Zj+7F+9Mdt8lZ5ezf9U+9q/aq1Y+etU4osKjWDR8vqps2JKRvHv7jrmDZmnVPv/X/2oVv+PwWvyu3WDyyOlAQj6nfQ+yfsVWls1bkyh+znJ3rK2t+KX9IFXZ9kNrCLgeyPhh7uTNn5tjl3bToGor7gTeU9V54cZRZk5dyPYNe1LctievNH85SM7JU7vx8fZjiNsE1bEDg86zZPFaZs1ckih+7br5WNtY0apFD1XZCc9d+PvdZOCAsaqybNmd8Dy1m6aNO7Nj1yoWLljFooWrtWpbrJY3Gp8+/Rfe3r4MHjxelcudO5dYvHgNf/65KFH8+vULsbGxpnnz96POU6f24Od3k/79R2s8RoYM6QkLu0mDBm05efKcVu1Tot2ftzOn9+Lt7cugweOAhHzu3vFi0eLVGvPZsH4RNjZWNPsgn9On/sLP7wb9ksknPCyA+g3aaJVP9NtHWuXyKW+v7ddZXemc9f+l93PJyI6EUVpA8DNc89irykwUClzz2OP3OErjPp53QiiVPTPux69Te+ExWqw+xYqLd4iLT/qX62V0woguUzoLnbb/Q2bmZhQoWRC/s9dUZUqlEr+zvhQpWzTV9QZ636JU5VJky5cdgLzF8lLMpThXPb0/t8nJMjc347vSRTl/yktVplQqOX/aizIuJTXuU8alFOdPX1IrO3PyAs4upQCwsEz47/8u+p1ane/evcPF1VnHGagzNzenTJkSnDx5Vu3YJ0+co4JrWY37VHAtw8kT6n8UPY6fpkKF9/EKhYIVK2Yxd/YyAgKC9NP4j5ibm1O2bElOnPgol5NncU0il4oVy6rFAxw/fjrJeHNzc7p3b0dU1DP8/G7qrvFJHEtTPidOnqGiazmN+7hqyOfY8VO4JhFvbm5Oj+7tv0g+Qp0sUAGevnlHnFKJnbWlWrmdtSX3I19p3OffZ6+5/PANPxbPzoIWFXgU9Yqpx64TGxdP7yqJp5filUpmnLiJc44sFHTIoJc8ADJkyYipmSlR4VFq5VHhUeQokCPV9e5atAOr9FbMP7GI+Lh4TExN2DRjA6f3nPrMFicvi21mzMzMCA+LUCuPCI2gQMG8Gvexd7Qj/KPp2PCwSBwcE0bT94Lu8++jJwwZ249xQ37nzes3dO3dnmw5suLgZK+pSp2xs8+CmZkZoSHhauWhoeEULlJA4z5OTg6EhSaOd3JyUP3sNqQ3sbFxLFq0RudtToq9vW1CLh+1LSQknMKFk84lNDTso/gwtVwAGjSow/r1C7C2tuLJk1AaNmxPRMRT3Sbwkf/yCfmofaEh4RQpnHh2ByCrkwMhH5+bkPBE+fzYoA7r1y9U5fPjF8jnk2SBytfj0aNHdOvWLdmY6Ohonj9/rrZFx+j3mhhAvBJsrS0Y90MpimfNRL2i2elRsSA7fB9qjHc/dp074S/4o1EZvbdNHyr/VJXqTWswe8BMhjYczHy3OTT5pSk1W9RO66ZpLTY2lr5dhpKvQG6873ji9/AcrlVd8Dx+lvhv8A+Ac5kS/Nq3K716DU3rpujMqVPnqVChPjVrNuPYMU82blyU5HWzb4Hn//OpUbMpR495sulryEcZr7vtG/BVd3aRkZGsXbs22Rh3d3cyZcqkts04dFmr42SxssBUoSDitfpilIjX0djbWGrcx8HGkjxZbDA1UajK8tmlJ/xVNDFx6iff/fh1Tt8LZUXrijhlsNKqbdp68fQ5cbFxZLbPrFae2T4zUWFRqa638+gu7Fq8k3P7zvAw8AGndnuyb+Vemv/a8vMa/AlPI6OIjY3F/qM/DHaOdolGO/8JD43A3lH94r+9gy1hoe9Hhzf8btG4VjvK5K9BlRL16N66P1myZObRA+2uJ2orIvwpsbGxOH40gnR0tCckJEzjPiEhYTg4Jh1fuXJ5HBzsuBV4jqjnQUQ9DyJPnpy4TxvDjYAz+kkECA+PTMjlo7Y5OSWfi6Ojw0fxDoniX79+w717D/Dyukrv3sOJjY2jS5c2uk3gI//l4/RR+xyTySc4JAynj8+NhvjXr99w9979/+cz7Ivk87VbuHAhefPmJV26dLi6uuLl5ZVkbM2aNVEoFIm2hg0bpvh4adrZ7d27N9nt5MmTn6xj1KhRPHv2TG0b1qC8Vu0wNzWhWNZMeD14/8czXqnE60EEpbJn1rhP6RxZeBj1mvgP1vc8ePoKBxtL1YIVpVKJ+/HrnAgKZlnriuTIbK1Vu1IjNiaWu/53KFXl/fJvhUJBqSqlCPS5lep6La0sUX50PTI+Lh6TDzp7fYiJieWG7y0qVX9/ThUKBZWrlefqFX+N+1y94kelahXUyqrUcOXaFb9EsS9fvCQyIoo8+XNRwrkYHof0Oy0bExPD1avXqVnz/a0QCoWCmrUq43XJR+M+XpeuUrOW+q0TtWpXxcsrIX7L5t1UrNCAyhUbqrbHj4OZM3sZTRt31msuPj7+1Kr1US41q3ApiVwuXvRRiweoXbtqkvH/MTExwdJSf9e6Iel8atWsysVLmq9NX9KQT53a1biURPx/vkQ+nxQfp7tNS1u3bsXNzY0JEybg4+ND6dKlqVevHqGhoRrjd+3axZMnT1Tb9evXMTU1pVWrVik+Zppes2vatCkKhYLkFoQqFMn/MbW0tMTSUn309cZc+7Q6uuRj3EFfimfNTIlsmdh45T5vYmJpUiLh3quxB67hmCEdA6onLPL42TkPW68+YLrHDdqWzcuDp69YefEObcvmVdU59fh1DgU8Zk4zF2zMTQl/+RaA9JbmpDM31bqNKbVvxV/0nzmIO353CPK9TaNujbG0TseJ7R4ADJg1iIjgSDZOXwckLGrJWSghTzMLM2yz2pK3eD7evnpL8IMnAFw+fpmW/VoR/jiMh7cfkv+7/DTq0YQT247rLY//rFqygenzJ3H9WgB+Ptfp0qsdVtZW7NycsGJ0+oJJhASHMfO3BQCsXbaZjX8tp1ufDngeO0vDZj9Qwrk4Y4f8rqqzfuO6RIY/5cm/wRQuVpCxvw/l+CFPznpe1Hs+C+atYOnymfj4+OF9xZe+/bphbW3NhvU7AFi2fCaPHwczccIMABYtXM3ho1voP6AHRw6foGWrRpQtW5IB/RJW+0VGRhEZGaV2jJiYWEJCwggKuqfXXObNW8GKFTPx8fHn8uVr9O/fHRsba9at2wbAypWzefw4mHHj/gBg4cJVHDu2jYEDe3Lo0Al+/rkx5cqVom/fkQBYW1sxcmR/9u8/RnBwKHZ2tvTu3Yns2Z3YufOAXnMBmDtvOStXzMLbx48rqnysksxnwcKVHD+2nUEDf+HQIQ9a/T+fX9XyGcD+/Uc/yKfzF8snWWk4/Thr1ix69uxJ164Jq1iXLFnCgQMHWLVqFSNHjkwUb2urPlOzZcsWrK2tv53OLlu2bCxatIgmTZpo/PzatWuUK6d5VZOu1Suanaev37H43G3CX0VTxDEji1pWwO7/05hPXrxR63izZrRiUcsK/HnyJq3WnMExfTralctH1wrvL8xvv5Zw/a7HFvU/oJMalFJ1ovpwbv9ZMtploq1bOzI7ZOHvm/eY0mkiz/6/aMU+uwPxH4zSsjjZMuvQXNXPTXs1p2mv5ly/4M/4NmMAWDFhGe2GtOeXKb3JaJ+JpyGRHN10mO1zt+otj/8c3HMMW7ssDBzRGwdHOwKu36Z76/5EhCUsQsmeM6vaF6arl/1w6z2GwaP6MGRMX+7fe8ivnYcQdOuuKsbRyZ7Rkwdj52BHWEg4e7YdYOHM5XrPBWDnzgPYO9gxdpwbTk72+PkF0KxpF9VCj1y5sqtdO7x0yYduXQYxbsIQJk4ayt0792nTuhc3b97+Iu1Nzo4d+7C3t2X8eDecnBzw9b1J48Ydk8zl4kVvOncewMSJQ5k8eTh37tynVaueqlzi4uIpXLgAmze3xN4+CxERUXh7+1KnTksCAvSf744d+3Cwt2X8+CFk/X8+jdTyyaH2u3PxojedOvdn0sRhH+TTg5s3A1X5FClcgA6bl6nlU/sL5fOlREdHEx2tfhlI00AE4N27d3h7ezNq1ChVmYmJCXXr1uXChQspOt7KlStp06YNNjY2KW5jmt5n17hxY5ydnZk8ebLGz319fSlTpozWiwZSc5/d10zb++y+dtreZ/c1S819dl8zbe+z+9ppe5/d10zn99ld1N0X1WmHA5g0aZJa2YQJE5g4cWKi2MePH5MjRw7Onz9PpUqVVOXDhw/n1KlTXLp0KdE+H/Ly8sLV1ZVLly5RoUKFZGM/lKYju2HDhvHqleal/QAFCxZM0XU7IYQQWtLhNOaoUaNwc1MfZGga1enCypUrKVmypFYdHaRxZ1etWrVkP7exsaFGjRpfqDVCCCFSI6kpS03s7e0xNTUlJCRErTwkJISsWbMmu++rV6/YsmVLkrOByfmqbz0QQgihJ/Hxutu0YGFhQbly5fDw8PigKfF4eHioTWtqsn37dqKjo+nQoYPW6coTVIQQwhil4QMU3Nzc6Ny5My4uLlSoUIE5c+bw6tUr1erMTp06kSNHDtzd3dX2W7lyJU2bNsXOTvsb8qWzE0II8UW1bt2asLAwxo8fT3BwMM7Ozhw+fBgnJycAHj58iImJ+sRjYGAgZ8+e5ejRo6k6pnR2QghhhNL61Tz9+vWjX79+Gj/z9PRMVFakSJFk78n+FOnshBDCGH2Dz4H9HLJARQghhMGTkZ0QQhijb+RtBboinZ0QQhgjmcYUQgghDIuM7IQQwhjJNKYQQgiDJ9OYQgghhGGRkZ0QQhgjmcYUQghh8GQaUwghhDAsMrITQghjZGQjO+nshBDCGBnZNTuZxhRCCGHwZGQnhBDGSKYxhRBCGDyZxhRCCCEMi4zshBDCGMk0phBCCIMn05hCCCGEYZGRnRBCGCOZxvz29ZxyP62boFNr6r5J6yboVOujjmndBJ0Jef00rZsgkqFAkdZN+HoZWWcn05hCCCEMnkGO7IQQQnyCUpnWLfiipLMTQghjJNOYQgghhGGRkZ0QQhgjIxvZSWcnhBDGSG4qF0IIIQyLjOyEEMIYyTSmEEIIg2dktx7INKYQQgiDJyM7IYQwRjKNKYQQwuAZWWcn05hCCCEMnozshBDCGBnZfXbS2QkhhBFSxstqTCGEEMKgyMhOCCGMkZEtUJHOTgghjJGRXbOTaUwhhBBf3MKFC8mbNy/p0qXD1dUVLy+vZOOjoqLo27cv2bJlw9LSksKFC3Pw4MEUH09GdkIIYYzScIHK1q1bcXNzY8mSJbi6ujJnzhzq1atHYGAgjo6OieLfvXvH999/j6OjIzt27CBHjhw8ePCAzJkzp/iY0tkJIYQxSsNrdrNmzaJnz5507doVgCVLlnDgwAFWrVrFyJEjE8WvWrWKyMhIzp8/j7m5OQB58+bV6pgyjSmEEOKzREdH8/z5c7UtOjpaY+y7d+/w9vambt26qjITExPq1q3LhQsXNO6zd+9eKlWqRN++fXFycqJEiRJMnTqVuLi4FLdROjshhDBG8fE629zd3cmUKZPa5u7urvGw4eHhxMXF4eTkpFbu5OREcHCwxn3u3bvHjh07iIuL4+DBg4wbN46ZM2fy22+/pThdmcYUQghjpMNX/IwaNQo3Nze1MktLS53VHx8fj6OjI8uWLcPU1JRy5crx77//MmPGDCZMmJCiOqSzE0II8VksLS1T3LnZ29tjampKSEiIWnlISAhZs2bVuE+2bNkwNzfH1NRUVVasWDGCg4N59+4dFhYWnzyuTGN+oG6n+sw+u4RVgVuYuGca+UsXTDK2Zpu6jNv+G0v91rHUbx0jN07QGN/CrQ0LLq9kVeBmRm6cgFPebPpMQcW8VmPS/7GeDEsOYDNmHib5iiQdW+UHMq48prZlWHLgfYCpKZYte2AzaRkZFu0l/cwtpOs+HEVmuy+QSYKfOv/EmvNr+CvoL2bvnU1h58JJxuYunJsxS8ew5vwaDj06RNPuTTXG2WW1Y9jcYWz128qeoD0sOraIQqUK6SkDdT1/6Yj/zdOERgRwwnMX5cqVSja+abMGXPE5RmhEABe8DvFDvZpqny9eOp3nr+6pbbv2rNZjBu/16tWJwMBzREXd5vTpv3BxKZ1sfPPmDfH1PUFU1G2uXDlKvXq11D4fO3Ywvr4niIi4xZMn/hw8uIny5Z31mIE6Q8snSTqcxtSGhYUF5cqVw8PD44OmxOPh4UGlSpU07lOlShXu3LlD/AfHun37NtmyZUtRRwfS2am4/lSF9mO7snvuNsb+NJSHAfcZsX48Ge0yaYwvVqkEF/ae5fc245nYbBSRjyMYsX4CWZxsVTE/9W7GD10asmr0EiY0GUn062hGrB+HuaW5XnMxK1+DdK17Eb13A68m9SHu0T1sBrujyJA5yX2Ur1/xYvDPqu3l8PbvP7SwxDR3QaL3beDVpF95s3ASpllzYt1/sl7z+E/1RtX5ZdwvbJyzkf4/9ufvm3/z2/rfyJTEuUlnlY7gh8GsnraayJBIjTHpM6Vn5q6ZxMbGMq7TOHrV7sWKKSt4+eylPlMBoHmLhkydNppp7vOoVqUR/v4B7PprLfYOmr88VHAty6o1c1m3bhtVK//EgX1H2bRlCcWKq3f4x456UjB/BdXWrctAvefSsmUjpk8fx++/z6FixYb4+wewb98GHJLIpWLFcqxbN581a7bi6voj+/YdYfv25RT/IJegoHsMHjweF5cfqF27BQ8ePGL//g3Y29tqrFPySaV4pe42Lbm5ubF8+XLWrl1LQEAAffr04dWrV6rVmZ06dWLUqFGq+D59+hAZGcnAgQO5ffs2Bw4cYOrUqfTt2zfFx1QolYb3bvYOeZprvc/EPdO453eHdeNXAKBQKJh7cRnH1hxk3+Ldn9xfYWLCMr91rB2/grO7PAFYcHklB5fv5eCyvwCwymDNwiurWDZ0Phf3nUtx2xbVfaFVLjZj5hH3923eblrw/8YpSD9jE+889vDu0NZE8eZVfiBdmz686N8sxccwyVuY9OMW8mJYO5SRYVq1r/VR7WbPZ++dzW3f2ywetxhIODfrvNaxd/Veti/anuy+a86vYc/KPexZuUetvOvIrhQvX5xhLYZp1ZaPnYsM1HqfE5678PH2Y+iQiUBCPgG3z7F0yTpmz1ySKH712nnY2Fjzc8seqjKPkzvx8wtg8MCxQMLILlOmjLRr0zt1ifzfu7hYreJPn/4Lb29fBg8eDyTkcufOJRYvXsOffy5KFL9+/UJsbKxp3ryrquzUqT34+d2kf//RGo+RIUN6wsJu0qBBW06eTPnvTWp8zfm8fftQy2yS9/rPHp8OSiHroSu03mfBggXMmDGD4OBgnJ2dmTdvHq6urgDUrFmTvHnzsmbNGlX8hQsXGDx4MNeuXSNHjhx0796dESNGqE1tJkdGdoCpuRn5Shbgxlk/VZlSqeTGWT8Klk16+u9DllYWmJqb8jIqoWNyyOVEZscsXD/rq4p58+I1d68FUSiFdaaKqRkmeQoTG+DzvkypJPamD6YFiie9n6UV6advIP2MjVj1m4RJ9jzJHkZhZYMyPh7l61c6arhmZuZmFCpZiGtnr6nKlEol185co1i5Yqmut+L3FQnyC2L04tFsvrqZBYcWUL9tfR20OHnm5uY4lymh9kdOqVTiefIcFSqU0bhPBdeyeH70R9Hj+BkquKrHV61Wkbv3vfC+epxZc6Zga5tZ5+3/kLm5OWXLluTEibOqMqVSycmTZ3F1Latxn4oVy6rFAxw/fjrJeHNzc7p3b0dU1DP8/G7qrvFJHMuQ8vkkZbzutlTo168fDx48IDo6mkuXLqk6OgBPT0+1jg6gUqVKXLx4kbdv33L37l1Gjx6d4o4OZIEKABmyZMDUzJRn4VFq5c/Co8hWIEeK6mgzqhNPQ55y41xCh5nZMTMAz8OfqcU9D48ik0OWz25zUhQZMqEwNUX5/KlaufL5U0yz5dK4T3zwI96u/pO4f/5GYWWDRb2W2Iyay8vxPVA+DU+8g5k56Vr2INbrJLx9rY80VDLaZsTUzJSnYer5PA1/Ss6COVNdb9bcWWnYoSG7Vuxi64KtFC5dmN6TexMbE8vxHcc/t9lJsrPLgpmZGWGh6v9dQ0PDKVy4gMZ9nJzsCdUQ7+TkoPr5+LHT7P3rCA8e/EO+fLmZMHEoO3evpk6tFmrXOXTJ3t4WMzOzRG0LCUkuFwdCQ8M+ig9TywWgQYM6rF+/AGtrK548CaVhw/ZERKj/G9A1Q8vnk4zsFT9p3tm9efMGb29vbG1tKV5cfeTx9u1btm3bRqdOnZLcPzo6OtHNi3HKOEwVKe/xP1ejPs2o2KgKv7ceT0x0zBc7rq7E3Q0g7m6A6uc3d2+QfspKLGo0JHrPWvVgU1Os+owDhYI36+d94ZbqjsJEQZBfEGv/SMjv7o275CmShx87/KjXzk5fdu7Yr/r/N28EcuP6LfxunKJa9Yqc8jyfhi1LnVOnzlOhQn3s7W3p1q0tGzcuolq1JoSFRaR101LF0PL5FqXpNObt27cpVqwY1atXp2TJktSoUYMnT56oPn/27JnqgmVSNN3MeOPZba3a8eLpC+Ji48hkn1mtPJN9Zp6FRSW774+/NOGnPs35o8NkHt16oCqPCk3YL6O9+iKKjPaZeRamv290yhfPUMbFocioPnpUZMxC/LMUHjcujrhHdzFx/GhUa2qKVe+xmNg58nrmCL2P6gCeRz4nLjaOLB+NhrPYZ0k02tNGZGgkD4PUr4E8uvMIhxwOSeyhGxERT4mNjcXB0V6t3NHRnpAQzdc+Q0LCcdQiHuD+/UeEh0WQP3/y09GfIzw8ktjY2ERtc3JKLpcwHB0dPop3SBT/+vUb7t17gJfXVXr3Hk5sbBxdurTRbQIfMbR8PkUZH6+z7VuQpp3diBEjKFGiBKGhoQQGBpIhQwaqVKnCw4cpvxA7atQonj17prZ9lynpZemaxMXE8rf/Xb6r8n75t0Kh4Lsqpbjjk/QChIa9mtK0f0umd57C3/531T4LexRCVOhTtTqt0ltRwLkQQcnU+dniYol/cBuzYh9cz1EoMCtWhri7KbxGoDDBJEde4p998K3zv47OKQev/xyB8pV2i2ZSKzYmliD/IJyrOL9vnkKBc1VnArwDkt7xE25euUnOAurToDny5yD0n9BU15kSMTExXLt6nZo1K6vKFAoFNWpWxsvrqsZ9vC75UOODeIBatavgdUlzPED27FmxtctCcLD+8omJicHHx59ataqoyhQKBTVrVuHSJR+N+1y86KMWD1C7dtUk4/9jYmKCpWXKlpinlqHl80lpuBozLaTpNOb58+c5fvw49vb22Nvbs2/fPn799VeqVavGyZMnsbGx+WQdmm5mTM0U5qEV++g1sz9/+93hrm8Q9bs1wtLaklPbTwDQa9YAngZHsG36RiDhtoIWbm1YNHA24f+EkskhMwBvX70l+vVbAA6v3E/T/i0J+fsJoY9CaDmkLVGhkXgfTf5VFp8r+uhOrLoPJ+7+beL+DsSibjMUlumIOXcEgHTdh6N8Gk70rlUAWDTqQNy9AOJD/kVhnR7L+j9jYudEzOlDCRWammLVZzymeQryeu44MDFRjRyVr16Aliv4tLV7+W6GzBpCkF8QgdcCadq9KZZWlhzbdgyAIbOHEBEcwZo/1gAJi1pyF8qd8P8tzLDLakf+4vl58/oNT+4nzBzsWbGHmbtn0rpfa07vP00R5yI0aNeAeSP0PzW7YP5Kliz7k6tX/blyxZdf+3bF2tqaDet3ALB0+Z88fhzCpAkzAFi8aA2Hjmym34DuHDl8kpYtG1GmbEkG9B8DgI2NNSNHD2DvnsOEhISRL38eJv82gnt3H+Bx/Ixec5k3bwUrVszEx8efy5ev0b9/d2xsrFm3bhsAK1fO5vHjYMaN+wOAhQtXcezYNgYO7MmhQyf4+efGlCtXir59Ex7+a21txciR/dm//xjBwaHY2dnSu3cnsmd3YufOA0m2Q/IRn5Kmnd2bN28wM3vfBIVCweLFi+nXrx81atRg06ZNX6wtl/afI6NdRlq4tSWTQ2Ye3Pyb6Z2mqBaY2Ge3Vxuu1+lQD3NLcwYuGa5Wz67ZW9k1J2F5//4lu7G0tqSbe2+sM9pw+0oA0ztN0ft1vdjLp3ibITOWTTsnTF8+usvr2aNRPo8CwMTWkfgP7jhRWKfHqvNgFBmzoHz9krgHQbxyH0j8k4QRtiKzPeZlEkYW6SctVTvWq+lDiAv0Q59O7ztNJttMdBjSAVsHW+7evMu4juOI+v+CIsccjnx4B42tky0LjyxU/dyyd0ta9m6J3wU/Rvw8AoDbvreZ0nMKXUZ2od3AdgQ/CmbpxKWc3HNSr7kA7Np5AHt7W0aPHYyTkz3+fgG0aNpFtWglZ87saotKvC750L3rIMaNH8KEiUO5e/c+7dr0JuBmwnR9XFwcJUoUpV375mTKlJEnT0I54XGG36bM5t27d3rNZceOfdjb2zJ+vBtOTg74+t6kceOOqkUeuXKp53LxojedOw9g4sShTJ48nDt37tOqVU9uqnKJp3DhAmze3BJ7+yxERETh7e1LnTotCQjQ7vKE5PMJRvby1jS9z65ChQr079+fjh07JvqsX79+bNy4kefPn2v1ZGtI3X12XzNt77P72ml7n93XLDX32X3NtL3PTnw5ur7P7tXk9p8OSiGb8Rt1Vpe+pOk1u2bNmrF582aNny1YsIC2bdtigPe8CyGE+MLStLMbNWpUsq9VX7Rokd7uERJCCKOWRs/GTCuGM58khBAi5b6RVZS6Io8LE0IIYfBkZCeEEMbIyFZjSmcnhBDGSKYxhRBCCMMiIzshhDBC38ozLXVFRnZCCCEMnozshBDCGBnZNTvp7IQQwhgZWWcn05hCCCEMnozshBDCGMl9dkIIIQyeTGMKIYQQhkVGdkIIYYSURjayk85OCCGMkZF1djKNKYQQwuDJyE4IIYyRkT0uTDo7IYQwRjKNKYQQQhgWGdkJIYQxMrKRnXR2QghhhJRK4+rsZBpTCCGEwZORnRBCGCOZxhRCCGHwjKyzk2lMIYQQBs8gR3YHI/3Tugk6VfdQ9rRugk6dWtYgrZugM2W7RaR1E3Tq3vMnad0EnYo3shuntSHPxhRCCGH4jKyzk2lMIYQQBk9GdkIIYYyMbIZXOjshhDBCxnbNTqYxhRBCGDwZ2QkhhDGSkZ0QQgiDF6/DLRUWLlxI3rx5SZcuHa6urnh5eSUZu2bNGhQKhdqWLl06rY4nnZ0QQogvauvWrbi5uTFhwgR8fHwoXbo09erVIzQ0NMl9MmbMyJMnT1TbgwcPtDqmdHZCCGGElPFKnW3amjVrFj179qRr164UL16cJUuWYG1tzapVq5LcR6FQkDVrVtXm5OSk1TGlsxNCCGOkw2nM6Ohonj9/rrZFR0drPOy7d+/w9vambt26qjITExPq1q3LhQsXkmzuy5cvyZMnD7ly5aJJkybcuHFDq3SlsxNCCPFZ3N3dyZQpk9rm7u6uMTY8PJy4uLhEIzMnJyeCg4M17lOkSBFWrVrFX3/9xYYNG4iPj6dy5cr8888/KW6jrMYUQggjpMv77EaNGoWbm5tamaWlpc7qr1SpEpUqVVL9XLlyZYoVK8bSpUuZMmVKiuqQzk4IIYyRDp+gYmlpmeLOzd7eHlNTU0JCQtTKQ0JCyJo1a4rqMDc3p0yZMty5cyfFbZRpTCGEEF+MhYUF5cqVw8PDQ1UWHx+Ph4eH2ugtOXFxcfj7+5MtW7YUH1dGdkIIYYSUafhsTDc3Nzp37oyLiwsVKlRgzpw5vHr1iq5duwLQqVMncuTIobruN3nyZCpWrEjBggWJiopixowZPHjwgB49eqT4mNLZCSGEMUrDzq5169aEhYUxfvx4goODcXZ25vDhw6pFKw8fPsTE5P3E49OnT+nZsyfBwcFkyZKFcuXKcf78eYoXL57iYyqUSqXBPTPGNkOhtG6CThXMYGgvb22S1k3QmbLdtqR1E3RKXt769Yp5969O64toWENnddkdOKWzuvRFRnZCCGGE0nIaMy1IZyeEEMbIyDo7WY0phBDC4MnITgghjJBMYwohhDB4xtbZyTSmEEIIgycjOyGEMELGNrKTzk4IIYyRUpHWLfiiZBrzA917tufa9ZM8DrvOsRM7KFuuVLLxTZrW56L3YR6HXefsxf3U/UH9Js0FS/4g8kWQ2rZ910p9pqDSsktT9lzawpl7R1m1fzHFnYsmGZu/cF6mLZ/Mnktb8Hp8ijY9WiaKadGpCRuPr+JE4EFOBB5k5d5FVKrlqs8U1Gw5e50Gv22kwogVdJi7G/+HSb/RGOD5m2im7jxD3YnrKT98OY3dt3Am4KFaTMizV4ze6EGNcWtwHbGCljO2c+NRmD7TUGnXrSXHr+zh2sMzbDm0ipJlkn4SRMEi+Zm7ahrHr+whINSLTr+0+ew6dal3r84EBp7nWVQQZ07vxcXFOdn45s0b4ud7kmdRQXhfOUb9erXUPh87djB+vieJjAgk+Ik/hw5uonz55OvUpT69OxN0+yIvnt/l3Nl9lP9EPi1a/IS//ylePL/LVZ/j1K9fW+3zcePc8Pc/RdTTIEJDbnD40BYqlC+jxwyEJtLZ/V+z5j/ym/topk9bQK2qTbl+PYAdu1dhb2+rMb6CaxmWr57NxnU7qFm1CQf3H2fD5kUUK6b+9JbjR09RtEAl1daj22C951K3cS0GTejLillr6VSvJ0E37zJv059kscusMd7SKh3/PnzMwqnLCA+J0BgT8iSMhVOX0rl+T7o0+IUr53z4c/Xv5C+cV3+J/N+Rq3eYufcCvX4ox+bBLSic3ZZflx0g8sUbjfExsXH0XnqAx09fMqPz9+wZ2YbxP1fHMZONKub562i6zN+DmakJC3r+yK7hP+PWuCIZrSz0nk+DJnUZMWkQC/9cQYu6nQi8EcTyrfOwtc+iMT6dlSWPHvzLrN8WEhYSrpM6daVly0ZMnz6O33+fg2vFH/H3v8n+fetxcLDTGF+xYjnWr1vAmjVbcHVtwN59R9i+fQXFixdRxQQF/c2gweMo5/I9tWq34P6Dfziwf2OSv4u61KpVY2bMmMBvv82igmt9/PxucuDAxiTzqVTRhQ3rF7J69WbKV6jHX3uPsHPHSr777sN87jFw4FjKlK1DzVrNePDgEQcPbvoi+SRHGa+77Vsgjwv7v2MnduDj48eIoZOBhFfA+986zfKl65k7a1mi+JVr5mBtY03bVr+oyo6e2I6/XwBDBo0HEkZ2mTJloGPbX1OZSQJtHxe2av9ibvre4s8xc4GEXPZd2c621btYt2BTsvvuubSFLct3sGXFjk8e59iNfcz/bTF7Nx/Uqn3aPi6sw9zdfJfLgVHNqwIQH6+k3pQNtK1agm51En9D3n7+Jms9fdk94mfMTU011jl3/yWu3Q9mdb/Pe3RZah4XtuXQKq5fu8lvo/4EEs7PyWv72LBiGyvmr0t23+NX9rBu2RbWLVM/7ufU+SFtHxd25vRevL19GTR4nOq4d+94sWjxav78c1Gi+A3rF2FjY0Wz5l1VZadP/YWf3w369R+t8RgZMqQnPCyA+g3acPLkOa3ap+3jws6d3ceVK74MHDQWSMjn73uXWbhoNTNmLEwUv3HjYmysrWnarLOq7OyZffj63qBvv5Eaj5EhQ3oiIwL5oV5rTp48m+K26fpxYU+q1vp0UAplO3tSZ3Xpi4zsSHg3Uuky33HK87yqTKlUcsrzPOUraJ5uKF+hDKdOnlcrO3H8DOUrOKuVVa3qSuC9i1zyOcKfsyeRxTazrpuvxszcjKKlCnP5jLeqTKlUcvmMNyXLfaeTY5iYmPB9k9pYWafD/8oNndSZlJjYOAL+CcO1UI4Pjq/AtXBO/B6EaNzH88Z9SuVxxH3XWWpPWEeLGdtYcdyHuA/+8J26eZ/iuRwYuvYYtSaspfXMHey8GKDXXADMzc34rnRRLpy+rCpTKpVcOH0ZZ5eSX02dKTuuOWXLluTEifd/sJVKJSdOnqGiazmN+7hWLKsWD3Ds+Clck4g3NzenR/f2REU9w8/vpu4an8SxypYthceJM6oypVLJiRNnqVhRc/squpbjxAfxAEePeSYZb25uTo8e/+Wj398doU4WqAB2dlkwMzMjLFR9iigsNILChQpo3MfRyZ7Qj+JDQ8NxdHJQ/Xzi2Gn27z3Cg/v/kC9/bsZNGMK2nSuoV+dnvT2gNrNtJszMzIgMe6pWHhn+lDwFc39W3QWK5mflvoVYWFrw5tUbhncfy99BDz6rzk95+uotcfFK7DJYqZXbpbfifmiUxn3+jXjB5TuP+bFsQRb0aMCj8GdM3XWW2Lh4etdzAeCfiBdsP3+TDjVK0qNOGa4/CmX67nOYm5rQuHwRjfXqQmbbzJiZmRERFqlWHhEWSb6Ceb6aOlPC3t4WMzMzQkLVr3OGhoRTpHBBjftkdXIg5OPfm5BwnD74vQH4sUEd1q9fiLW1FU+ehPJjw/ZERKj/m9a1//IJ/WiqOCQ0jCJFNP8dyJrVQWP+ifL5sS4bNyz6fz4hNGjQVu/5fMq3Mv2oK2ne2QUEBHDx4kUqVapE0aJFuXXrFnPnziU6OpoOHTpQu3btZPePjo4mOjparUypVKJQpP1Ko107D6j+f8DN29y4HshV/xNUrebK6VMX0rBlqfPg7kM6fN+D9BlsqP1TDSbMHU3v5gP03uFpK16pxDa9FeNaVcfUxITiuRwIff6atSd9VZ1dvFJJ8ZwODPgxYZFN0Zz23A1+yo4LN/Xa2YmU8Tx1ngoV6mNnn4Vu3dqxaeMiqlZrTFiY5mvKXztPz3O4lP8Beztbundvx6ZNS6hS9ac0zUcpqzG/nMOHD+Ps7MzQoUMpU6YMhw8fpnr16ty5c4cHDx7www8/cOLEiWTrcHd3J1OmTGrb23eRye7zsYiIp8TGxuLgaK9W7uBol+hb239CQ8Jx/Cje0dGe0JCkV/M9uP+I8PBI8uXX37ftqMhnxMbGYuugvjDB1j5Lom/+2oqNieWf+/9yy/82i9yXE3TzDq01rNzUpSw26TA1URDx0WKUiJdvsP9otPcfh4zW5HHIhOkH78PK55iZ8BeviYmNU8UUcFL/b5TPKTNPnr7UcQbqoiKjiI2Nxc5BfXGCnYMt4aGp+8OnjzpTIjw8ktjYWJwc1Ucxjk72hCTxexAcEobTx783GuJfv37D3Xv38fK6Su/ew4iNjaNLF82rUHXlv3wcndTb5+ToQHBS+QSHpSj/16/fcPfufS55+fBLr6HExsbRtWtb3SYgkpWmnd3kyZMZNmwYERERrF69mnbt2tGzZ0+OHTuGh4cHw4YNY9q0acnWMWrUKJ49e6a2pbPQbpVTTEwMvldvUL3G+1fCKxQKatSozGWvqxr3uex1leo11V8hX7N2FS57XUvyONmzZ8XWNjMhIckvm/8csTGx3PK7Tfmq768ZKBQKXKqWxd9bt9cITBQmWFiY67TOj5mbmVIspwNeQe8vzsfHK/EK+pdSeZw07lM6nxMPw58RH/9+7dWDsGc4ZLTG3CxhwUrpvFm5Hxaltt+DsGdky5JB90l8ICYmlhu+t6hYrbyqTKFQULGaC9eu+H81dabsuDH4+PhTq1YVtePWqlmVi5e8Ne5z6aKPWjxAndrVuJRE/H9MTEywtNTvStmEfPyoXauqqkyhUFCrVlUuXtTcvouXvKlVu6paWd061ZOM/4+JiULv+XyKsa3GTNPO7saNG3Tp0gWAn3/+mRcvXtCy5fuRQvv27fHz80u2DktLSzJmzKi2pWYKc9GCVXTq0po27ZpRuEgBZs6ZjLW1FZvW70z4fOl0xk0coopfungtdepWo2//bhQqnJ8Ro/rjXKYEK5auB8DGxppJv43ApbwzuXLnoHqNSmzYsph79x5w4njKV2ClxqZl22jSriENW9Ujb8E8jJjmhpW1Ffu3HAJg4tzR/DqqpyrezNyMQt8VpNB3BTE3N8chmz2FvitIzrzvF4X8OqonZVxLkS1nVgoUzc+vo3pStrIzh3cf12suAB2rl2TXpVvsvRzIvZCn/L7zDG/exdCkQsJ049hNJ5h34JIq/udK3/H8dTTT95zjQVgUp28+YKXHVX6u8n6BTofqJfF/EMqK4z48DH/GQZ8gdl4MoHUV3SziSc7aJZto1aEJTVo3JH+hvEyYMQIrayt2b9kPwLQFExk85v0KXnNzM4qWKETREoUwtzDHMZsDRUsUIne+nCmuU1/mzltOt25t6dChJUWLFGTB/KnY2Fixbt02AFaunM2UKSNU8QsWruSHH2oyaOAvFClcgLFjB1OuXCkWLV4LgLW1FZMnj6BChTLkzp2DMmVKsnTpn2TP7sTODy4L6Mucucvp3r0dHTu2omjRgixcMA0bGyvWrt0KwOpVc/ntt/erLBfMX0m9H2oyaFAvihQpwLhxbv/PZ7UqnylTRuJaoSy5c+egbJmSLF82kxw5srJzp37Pzaco4xU6274FaX7N7r+OycTEhHTp0pEpUybVZxkyZODZs2dfpB27dx3Ezt6WUWMG4ujkwHW/AFo1766aU8+ZKzvxH9yl4XXpKr90c2P0+MGMnTCEe3fv06HtrwQEBAEQFxfHd98VoU27ZmTKlIHgJ6GcPHGWqVPm8O7dO73mcnzvSbLYZeaXYd2wc7Dl9o07DGw/jMjwhAviTjkc1RbIODjZs/HY+5vdO/ZpS8c+bfE+f5U+LQcBCdOgE+aNxt7RjpcvXnEn4C4D2g3D6/QVveYCUK9MQZ6+esviI1cIf/6aIjnsWdTzR+wyWAPwJOql2hecrFnSs+iXH/nzrwu0+nMHjplsaFetBF1rO6tiSuR2ZFbXH5h3wItlx3zIYZuBYU0q07Cc/t9yf+iv42Sxy8KA4b9g72hHwPXb/NJmoGqaOVsOJ/Xzk9WB3Sc2qn7u3rcj3ft2xOucN52b9UlRnfqyY8c+HOxtGT9+CFmdHPD1vUmjxh1Vi7dy5cqhNsK+eNGbTp37M2niMCZPHs6dO/dp1aoHN28GAhAXF0+RwgXosHkZ9vZZiIiIwtvbl9p1WhIQcFuvuQBs374XB3tbJowfStasDvj63uCnnzp8kE92tXNz4eIVOnbqx6RJw/ltygiC7vxNi5bduXHjg3yKFKBjh2XY29sSEfGUK96+1KrVnJs39Z+PeC9N77MrXbo0f/zxB/Xr1wfg+vXrFC1aFDOzhD74zJkzdO7cmXv37mlVb2rus/uaaXuf3ddO2/vsvmapuc/ua6btfXZfO32tek4Lur7P7qFLHZ3VlfuKh87q0pc0Hdn16dOHuLg41c8lSpRQ+/zQoUOfXI0phBBCe9/K9KOupGln17t372Q/nzp16hdqiRBCCEOW5tfshBBCfHkyshNCCGHwDO+pyMmTZ2MKIYQweDKyE0IIIyTTmEIIIQyePBtTCCGEMDApGtnt3bs3xRU2btw41Y0RQgjxZXwrz7TUlRR1dk2bNk1RZQqFQu0mcSGEEF+neCObxkxRZ2dIj9wRQghhfGSBihBCGCFjW6CSqs7u1atXnDp1iocPHyZ6gv+AAQN00jAhhBD6I7cefMLVq1f58ccfef36Na9evcLW1pbw8HCsra1xdHSUzk4IIcRXR+tbDwYPHkyjRo14+vQpVlZWXLx4kQcPHlCuXDn+/PNPfbRRCCGEjimVutu+BVp3dteuXWPIkCGYmJhgampKdHQ0uXLlYvr06YwePVofbRRCCKFjxvamcq07O3Nzc0xMEnZzdHTk4cOHAGTKlIlHjx7ptnVCCCGEDmh9za5MmTJcvnyZQoUKUaNGDcaPH094eDjr169P9PJVIYQQXydju89O65Hd1KlTyZYtGwC///47WbJkoU+fPoSFhbFs2TKdN1AIIYTuKZUKnW3fAq1Hdi4uLqr/7+joyOHDh3XaICGEEELX5KZyIYQwQt/KKkpd0XoaM1++fOTPnz/JTQghxNcvXqnQ2ZYaCxcuJG/evKRLlw5XV1e8vLxStN+WLVtQKBQpfmbzf7Qe2Q0aNEjt55iYGK5evcrhw4cZNmyYttUJIYQwMlu3bsXNzY0lS5bg6urKnDlzqFevHoGBgTg6Oia53/379xk6dCjVqlXT+phad3YDBw7UWL5w4UKuXLmidQOEEEJ8eWm5sGTWrFn07NmTrl27ArBkyRIOHDjAqlWrGDlypMZ94uLiaN++PZMmTeLMmTNERUVpdUydvby1QYMG7Ny5U1fVCSGE0CNdPkElOjqa58+fq23R0dEaj/vu3Tu8vb2pW7euqszExIS6dety4cKFJNs7efJkHB0d6d69e6ry1Vlnt2PHDmxtbXVVnRBCiG+Eu7s7mTJlUtvc3d01xoaHhxMXF4eTk5NauZOTE8HBwRr3OXv2LCtXrmT58uWpbmOqbipXKN4Pf5VKJcHBwYSFhbFo0aJUN0QIIcSXo8ubykeNGoWbm5tamaWlpU7qfvHiBR07dmT58uXY29unuh6tO7smTZqodXYmJiY4ODhQs2ZNihYtmuqG6FIGC6u0boJOhb97ntZN0KkmfY6mdRN05lRJw/q31vm2YT0F6WTYjbRuwldLl9fsLC0tU9y52dvbY2pqSkhIiFp5SEgIWbNmTRR/9+5d7t+/T6NGjVRl/71Q3MzMjMDAQAoUKPDJ42rd2U2cOFHbXYQQQggALCwsKFeuHB4eHqrbB+Lj4/Hw8KBfv36J4osWLYq/v79a2dixY3nx4gVz584lV65cKTqu1p2dqakpT548SbQ8NCIiAkdHR+Li4rStUgghxBeWls/GdHNzo3Pnzri4uFChQgXmzJnDq1evVKszO3XqRI4cOXB3dyddunSJnrucOXNmAK2ex6x1Z6dM4rb76OhoLCwstK1OCCFEGkjLB6i0bt2asLAwxo8fT3BwMM7Ozhw+fFi1aOXhw4eqt+voSoo7u3nz5gGgUChYsWIF6dOnV30WFxfH6dOnv5prdkIIIb5u/fr10zhtCeDp6ZnsvmvWrNH6eCnu7GbPng0kjOyWLFmCqamp6jMLCwvy5s3LkiVLtG6AEEKIL8/YXvGT4s7u77//BqBWrVrs2rWLLFmy6K1RQggh9OtbeTWPrmh9ze7kyZP6aIcQQgihN1pfAWzRogV//PFHovLp06fTqlUrnTRKCCGEfsXrcPsWaN3ZnT59mh9//DFReYMGDTh9+rROGiWEEEK/lCh0tn0LtO7sXr58qfEWA3Nzc54/N6wnfQghhDAMWnd2JUuWZOvWrYnKt2zZQvHixXXSKCGEEPoVr9Td9i3QeoHKuHHjaN68OXfv3qV27doAeHh4sGnTJnbs2KHzBgohhNC9+G9k+lFXtO7sGjVqxJ49e5g6dSo7duzAysqK0qVLc+LECXnFjxBCiK+S1p0dQMOGDWnYsCEAz58/Z/PmzQwdOhRvb295NqYQQnwDvpWFJbqS6oePnT59ms6dO5M9e3ZmzpxJ7dq1uXjxoi7bJoQQQk+M7dYDrUZ2wcHBrFmzhpUrV/L8+XN+/vlnoqOj2bNnjyxOEUII8dVK8ciuUaNGFClSBD8/P+bMmcPjx4+ZP3++PtsmhBBCT4ztPrsUj+wOHTrEgAED6NOnD4UKFdJnm4QQQujZtzL9qCspHtmdPXuWFy9eUK5cOVxdXVmwYAHh4eH6bJsQQgihEynu7CpWrMjy5ct58uQJvXr1YsuWLWTPnp34+HiOHTvGixcv9NlOIYQQOmRsC1S0Xo1pY2NDt27dOHv2LP7+/gwZMoRp06bh6OhI48aN9dFGIYQQOmZs1+w+673nRYoUYfr06fzzzz9s3rxZV20SQgghdCpVN5V/zNTUlKZNm9K0aVNdVCeEEELP4r+NAZnO6KSzE0II8W0xtmdjftY0phBCCPEtkJGdEEIYoW/kzTw6IyO7D3Tq3pqzVw8R+O9l9hzdSOmyJZKN/7Hx93hc/IvAfy9z5MxOatWtqva5tY0Vk/8YxUX/YwT+48Xx87tp36WVPlNQ6djtZ077HCDgn4vsOrKOUmW+Sza+QeO6HLuwi4B/LnLo9DZqfpSLvYMt0+dP4sL1o9x4eJ7VWxeQN39ufaagplHnRqw7v5b9QXuZt3cORZwLJxmbp3Aexi0dy7rzazn66DDNujfVGGeX1Y4Rc4ezw28b+4L+YumxxRQq9WUemGDVpCl2G7fgcOgoWRYsxqxI0RTtZ1mrNo4ep8g0+Te1ckU6K9L3H4jdlu04HDyK7aq1pPvpy6yO/qnzT6w5v4a/gv5i9t7ZFE7m3OQunJsxS8ew5vwaDj06RNNkzs2wucPY6reVPUF7WHRs0Rc7N716dSIw8BxRUbc5ffovXFxKJxvfvHlDfH1PEBV1mytXjlKvXi21z8eOHYyv7wkiIm7x5Ik/Bw9uonx5Zz1mkDJy64GR+qlpPcZOGcbcGUv4qXZrAq4Hsn77EuzsNb+2qFz50sxf/gfbNuymYa2fOXrwBMvWz6Vw0YKqmHFThlGjdhUG9R5FnUpNWblkA5P/GEXd+jX1mkvDpj8wesoQ5s1YSqPa7Qi4cZu12xdhZ59FY3zZ8qWZu8ydbRv38FOtthw96MmSdbMoXLSAKmbJutnkzpuTXh0H8VPttvz7zxPW71yClXU6veYCUKNRdXqN68mGORv49cd+3Lt5j6nrfyezXSaN8ZZWlgQ/DGbVtFVEhERqjEmfKT2zd80iNjaWMZ3G0rP2LyybspyXz17qM5WE9tWsRfrefXm1bi2RvXsSe/cumf/4E0XmzMnuZ+KUlfS9+vDOzzfRZ+n79MWifAWeu/9ORNdOvN65gwwDBmJRqbKeskhQvVF1fhn3CxvnbKT/j/35++bf/Lb+NzIlcW7SWaUj+GEwq6etJjKZczNz10xiY2MZ12kcvWr3YsWUFV/k3LRs2Yjp08fx++9zqFixIf7+AezbtwEHBzuN8RUrlmPduvmsWbMVV9cf2bfvCNu3L6d48fcdflDQPQYPHo+Lyw/Urt2CBw8esX//BuyT+Nsi9EOhVCq/qtGsUqlEofi8C6d57Eppvc+eoxvxu3qd8SPcAVAoFFz0P8qa5ZtZPHdVovgFK6ZjbW1Ft3b9VWW7j2zgpv8txgxN+NZ99Owu9u8+zLyZy1Qx+z224Olxlj+nLkhx20wVplrlsuvIOvyu3mDiyD9UuZzzO8y65VtYMm91ovh5K6ZhbW1Fj3YDVWU7D68l4Pptxg79nXwFcuNx6S/qVWlBUOA9VZ2Xbh7nz98XsG3Dbq3aV9DKSav4eXvnEOh7m4XjFqmOvdFrPX+t3svWRduS3Xfd+bXsXrmb3Sv3qJV3G9mV78p/x5AWQ7Vqy8c2FH6j9T5ZFiwmJvAWL+fPTShQKLDbsp03u3fxessmzTuZmJB59jzeHj6IeclSmKRPz7PxY1Uf265YzVvPk7zesO79cRYv453XJV6tXpnitnW+ba1VLrP3zua2720Wj1v8/1QUrPNax97Ve9m+aHuy+645v4Y9K/ew56Nz03VkV4qXL86wFsO0aosmJ8NuaBV/+vRfeHv7MnjweCAhnzt3LrF48Rr+/HNRovj16xdiY2NN8+ZdVWWnTu3Bz+8m/fuP1niMDBnSExZ2kwYN2nLy5LkUt+3t24da5fIpO7K111ldLZ9s1Fld+vLVjewsLS0JCAj4osc0NzejZOlinD31/hVFSqWSs6cuUba85imMsuVLc/bUJbWy0yfOq8V7e12jboOaOGVzBKBS1fLkK5iH0ycv6CGLBObmZpQoXYxzH7RNqVRy7tQlypTX/CWgrEsptXiAMycvUMYlId7CwgKA6Oh3anW+e/cOF1dnHWegzszcjEIlC3H17FW1Y189c5Vi5Yqlut5K31ckyO82YxePYdvVLSw6tIAGbevrosnJMzPDrHBh3vl4vy9TKnnn44158aSnmm06dkYZFcXbQwc1fh5z4waWlapgYm8PgLlzGUxz5uLdlcs6bf6H/js3185eU5UplUqunbn2Weem4vcVCfILYvTi0Wy+upkFhxZQ/wucG3Nzc8qWLcmJE2dVZUqlkpMnz+LqWlZzWyuWVYsHOH78dJLx5ubmdO/ejqioZ/j53dRd41NBqcPtW5BmC1Tc3Nw0lsfFxTFt2jTs7BKmDWbNmpVsPdHR0URHR6uVKZXxKBQp78ez2GXBzMyM8NAItfLw0AgKFMqncR8HR3vCwz6KD4vAwdFe9fOEke64z56A1/XjxMTEEB+vZOTgSXhd8P64Op1R5RKmPkUUHhZBgUJ5Ne5j72ifOD40AgfHhHNwN+g+/z56wrCx/Rkz5DfevH5Dt94dyJ4jK45O9pqq1JmMthkxNTPlaViUWvnT8ChyFcyV6nqz5c7GTx1+YueKXWxesIUipQvz6+Q+xMbEcmzH8c9sddJMMmVCYWpG/NOnauXxT59ilkvzNVDzEiVJ1+BHIn/pkWS9LxbMJYPbUOy37kQZGwvx8byY9Scx/n46bf+H3p8b9Vyehj8lZ8Gcqa43a+6sNOzQkF0rdrF1wVYKly5M78m9iY2J5bgez429vS1mZmaEhqo/8zckJJzChQto3MfJyYHQ0LCP4sNwcnJQK2vQoA7r1y/A2tqKJ09CadiwPRER6v/dhH6lWWc3Z84cSpcuTeaPrlMolUoCAgKwsbFJ0XSmu7s7kyZNUivLmM6RzNbaTZXpQ5ee7SjjUopu7frz76PHuFYux5TpowkJDk00kvqaxcbG0qfLEKbNmcC1u6eJjY3l3KlLeB47C5855ZxWFCYKbvsFsfqPNQDcvXGXvEXy0rBDQ712dtpSWFmRceQYXsz6E+XzZ0nGWTVtjnmx4kSNHUVcSDAWJUuTfsAg4iLCifHR35crfVCYKAjyC2LtH2uBhHOTp0gefuzwo147O306deo8FSrUx97elm7d2rJx4yKqVWtC2EdfmL+kb2Vhia6kWWc3depUli1bpnrL+X/Mzc1Zs2ZNil8GO2rUqESjxBJ5tbso/zTiKbGxsdg7ql+Etne0IyxU85sdwkLDsf/oorW9w/t4y3SWDBs7gF6dBnHi2BkAbt0MoniJovzSt4veOjtVLg7qF78T2qb5Fys8NDxxvKN6/HXfAH6q1YYMGdJjbmFOZMRTdh1Zh/81/U7FPI98TlxsHFkcMquVZ7HPTGRY6r8ZR4ZG8jBI/RrIwzsPqfpjlVTXmRLxz56hjIvFJIv6YiGTLFmIj0y8YMM0ew5Ms2Uj029T3xf+f9bC4agHkZ07EhcRTvruPXk2YSzvLiVMxb+5dw+zggWxbtWaZ3rq7N6fG/VcsthnSTTa04amc/PoziOq6PnchIdHEhsbi6Oj+myFk5M9ISFhGvcJCQnD0dHho3iHRPGvX7/h3r0H3Lv3AC+vq1y/foouXdowY8ZC3SahBWN7gkqaXbMbOXIkW7dupU+fPgwdOpSYmJhU1WNpaUnGjBnVNm2mMAFiYmLx9w2gSnVXVZlCoaBKdVd8Lide+Qbgc9lXLR6gWs2KqnhzczMsLMyJj1ef0Y6Li8PERH//ymJiYrnuG0Dlj3KpXL0CVy9rntLyueJH5eoV1Mqq1KjI1SuJ41+8eElkxFPy5s9NSefiHDvkqdP2fyw2JpYg/yCcqziryhQKBc5VnQnwTv213RtXbpKzgPpUW878OQj5JzTVdaZIbCyxt29jUabc+zKFAosyZYm5mXgxRezDh0R070LkLz1U27sL54i5dpXIX3oQFxaKwswMhbk5fLzWLD4ehYn+fsX1dW5uajg3OfLnIFTP5yYmJgYfH39q1XrfqSoUCmrWrMKlSz4a97l40UctHqB27apJxv/HxMQES0uLz2+0SLE0XaBSvnx5vL29CQsLw8XFhevXr3/2SszUWrFoHW06tqBFm8YULJyP3/8ci7W1Fds37QFg1qLfGT5ugCp+9dKN1KhTmZ6/dqJAobwMGt6Hks7fsXbFFgBevnjFhbOXGT3JjYpVXMiVOwct2zamRetGHDlwQq+5rFy8gTYdm9G8dSMKFMrHlD9HY21txY7NfwHw58IpDBv7fhXpmqWbqV67Mt1/7Uj+gnkZOLwXJZ2Ls+7/uUDCfXiuVcqRK08O6jaoybodizl20JOznhcTHV/Xdi7fxY9tG/B9y7rkKpiLAVP7k84qHUe2HQVg2OyhdBvxfjWcmbkZ+YvnJ3/x/JhbmGGf1Z78xfOTPW82VcyuFbspVqYobfq1JnvebNRqWpMf2/3IvrX79J7P6x3bsGrYkHQ/1MM0dx4yDHJDkc6KN0cOAZBhxGhsuvdMCI55R9z9v9W2+JcvUb55Tdz9vyE2FuXr17y7dpX0v/TGvLQzJlmzkq5efdJ9X4/os2f0msvu5bup37Y+df9/bvpN7YellSXHth0DYMjsIXQZ0UUV/+G5MbMwwy6rHfmL5yfbB+dmz4o9FC1TlNb9WpMtbzZqNq1Jg3YN2L92v15zAZg3bwXdurWlQ4eWFClSkPnzp2JjY826dQmrfleunM2UKSNU8QsXruKHH2owcGBPChcuwNixgylXrhSLF68BwNraismTh1OhQhly585BmTIlWbp0BtmzO7Fz5wG955OceBQ6274Faf4ElfTp07N27Vq2bNlC3bp1iYuLS5N27N9zBDv7LLiN/BUHR3tuXg+k0899VAs3sufISnz8+1lu78u+DPhlJEPH9GfY2AHcv/eQXzoO5PatO6qY/j2HM3zcQOYudSdz5kz8888TZvw+nw2rk18u/7kO7DmKrV0WBo/sg72jHQHXA+nyc9/3ueRUz8Xnsi+Deo1myOi+DB3Tj/v3HtK7kxu3b91VxTg6OTBmypCE6dCQcHZt3c+CD26p0KdT+06TyTYTnYZ0JItDFu7dvMeYjmOJCo9KaFsORz68g8bOyY4lR94vE2/VuyWterfE94Ifw34eDsBt39tM6jmZbiO70mFge4IfBbN44hJO7Dmp93yiPU/yMlNmbLp0wySLLbF37xA1chjK/y9aMXV0BKV2V1Se/zYZmx6/kHH0WEwyZCQuJJiXq1bwZt9f+khB5fT/z02HIR2wdbDl7s27jOs4LslzY+tky8Ij76fuWvZuScveLfG74MeInxM6kdu+t5nScwpdRnah3cB2BD8KZunEpZz8Audmx4592NvbMn68G05ODvj63qRx446qRSu5cmVX+925eNGbzp0HMHHiUCZPHs6dO/dp1aonN2/eBiAuLp7ChQuweXNL7O2zEBERhbe3L3XqtCQg4Lbe80nOt7KKUle+qvvs/vnnH7y9valbty42Njapric199l9zbS9z+5rp+19dl+z1Nxn9zXT9j67r52299l9zXR9n92G7B10VleHxxt0Vpe+pPnI7kM5c+YkZ87UL1kWQgiRMsa2QOWr6uyEEEJ8GcZ268FX9wQVIYQQQtdkZCeEEEboq1ms8YVIZyeEEEbI2K7ZyTSmEEIIgycjOyGEMEKyQEUIIYTBS+s3lS9cuJC8efOSLl06XF1d8fLySjJ2165duLi4kDlzZmxsbHB2dmb9+vVaHU86OyGEEF/U1q1bcXNzY8KECfj4+FC6dGnq1atHaKjm55/a2toyZswYLly4gJ+fH127dqVr164cOXIkxceUzk4IIYyQUqG7TVuzZs2iZ8+edO3aleLFi7NkyRKsra1ZtWqVxviaNWvSrFkzihUrRoECBRg4cCClSpXi7NmzGuM1kc5OCCGMkC6nMaOjo3n+/Lna9vFLtf/z7t071WMh/2NiYkLdunW5cOHCJ9utVCrx8PAgMDCQ6tWrpzhf6eyEEEJ8Fnd3dzJlyqS2ubu7a4wNDw8nLi4OJyf1Z+Q6OTkRHByc5DGePXtG+vTpsbCwoGHDhsyfP5/vv/8+xW2U1ZhCCGGEdLkaU9NLtC0tLXV4BMiQIQPXrl3j5cuXeHh44ObmRv78+alZs2aK9pfOTgghjJAun6BiaWmZ4s7N3t4eU1NTQkJC1MpDQkLImjVrkvuZmJhQsGBBAJydnQkICMDd3T3FnZ1MYwohhPhiLCwsKFeuHB4eHqqy+Ph4PDw8qFSpUorriY+PT/K6oCYyshNCCCOUlo8Lc3Nzo3Pnzri4uFChQgXmzJnDq1ev6Nq1KwCdOnUiR44cqut+7u7uuLi4UKBAAaKjozl48CDr169n8eLFKT6mdHZCCGGE0vIJKq1btyYsLIzx48cTHByMs7Mzhw8fVi1aefjwISYm7yceX716xa+//so///yDlZUVRYsWZcOGDbRu3TrFx/yq3lSuK/Km8q+bvKn86yVvKv966fpN5bNz6+5N5YMfypvKhRBCfIWM7dmY0tkJIYQRMrgpvU+Q1ZhCCCEMnozshBDCCBnby1ulsxNCCCNkbNfsZBpTCCGEwZORnRBCGCFjW6AinZ0QQhiheCPr7gyys4uNj0vrJujU85jXad0EnbpqQPk0DDCcG+QBPLtnSOsm6FStlfnSugniK2GQnZ0QQojkGdsCFenshBDCCBnXJKasxhRCCGEEZGQnhBBGSKYxhRBCGDxje4KKTGMKIYQweDKyE0IIIyT32QkhhDB4xtXVyTSmEEIIIyAjOyGEMEKyGlMIIYTBM7ZrdjKNKYQQwuDJyE4IIYyQcY3rpLMTQgijZGzX7GQaUwghhMGTkZ0QQhghY1ugIp2dEEIYIePq6mQaUwghhBGQkZ0QQhghY1ugIp2dEEIYIaWRTWTKNKYQQgiDJyM7IYQwQjKNKYQQwuAZ260HMo0phBDC4MnITgghjJBxjeuksxNCCKMk05hGrHOPtlz0PcrdJz7sO7YZ57Ilk43/qckPnLq0j7tPfDh+bje1v6+m9vm/T29o3Hr376rPNADo8UsHfG948iT8BsdO7qBsuVLJxjdp1oBLPkd4En6Dc5cO8P0PNdQ+X7jkD56+vKO2bd+9Sp8pqOnWox3efh48CvHjsMc2ynzi3DRuWp/zlw/xKMSPU+f3Uvf76oliChXOz/rNi7n78Ar3H1/l6Mkd5MiZTV8pqGnVpRl/XdrK2XvHWL1/CcWdiyUZm79wXv5YPoW/Lm3l8uPTtO3RKlFMl37tWXtwKZ63D3PE7y9mrPqdPAVy6TMFFbMK9bByW4D1+A2k++V3THIUSDq2TA1spmxT26zHb0gUp3DIgWX74ViPWYP1uHWk6zUVRSY7faah0rJLU/Zc2sKZe0dZtX8xxZ2LJhmbv3Bepi2fzJ5LW/B6fIo2PVomimnRqQkbj6/iROBBTgQeZOXeRVSq5arPFIQG0tn9X+Nm9Znw23Bm/bGI+jVbcfN6IBt3LsXO3lZjvEsFZxaumMHmDbuoV6MlRw6cYOWG+RQpVlAV41ykhto2uO8Y4uPjObj3mF5zadbiR35zH80f7vOpWbUJ16/fYuee1dg7aM6lgmsZVqyezYa126lRpTEH9h9jw5bFFCteSC3u+NFTFMlfUbX16DpIr3n8p2nzBkyeOoo//1hInerNuHH9Ftt2r8Q+iXNTvkIZlq6cycb1O6hdrSmHDniwdtNCihZ7n0/efLnYf2QTQUH3aPpTR2pWaczM6YuIfhut93y+b1ybQRP6smLWGjrW60HQzTvM3/QnWewya4xPZ5WOfx8+ZsHUpYSHRGiMKVvJme1rdtPtp970a+OGmZkZ8zfPJJ1VOj1mAqYlKmHRoBMxJ3fwZvEI4oMfkK7zGLDJmOQ+yrevef1Hz/fbzL5qnyuyOGHVYzLxYf/ydtVE3iwYRsypnShjY/SaC0DdxrX+f27W0qleT4Ju3mVeMufG8v/nZuHUZUmem5AnYSycupTO9XvSpcEvXDnnw5+rfyd/4bz6SyQF4nW4fQsUSqXS4MayObJ8p/U++45txvfqdcYO/x0AhULB5eserF6+iYVzViSKX7zyT6xtrOjc5v0v6r6jm7hx/RYj3SZrPMbKDfNIn96G1k27a9W21zHa/QE+dnIHV338GT5kEpCQy/XAMyxfsp45s5YmbtfaudhYW9Gm1S+qsqMndnDd/yZuA8cDCSO7TJky0qFtH63aoomZqalW8Yc9tnHNx5+Rw6YACfn43jzFimXrmTd7eaL45atnY21tRfvWvVVlh45v5br/LYYNngDAslWziImJpW+v4Z+RCeS1cdJ6n9X7l3DT9xYzxswBEvLZf2UH21bvYu2Cjcnu+9elrWxZvoPNK7YnG5fZNhPHru/jl2b9uXrJN8Vt8+yeNcWxAOl++Z34f+/y7sD/R/kKBVZDFxN78RAxZ/5KFG9WpgYWDbrwemrSsxuWPw+EuDiidy7Qqi2a1FoZolX8qv2Luel7iz/HzAUSzs2+K9vZtnoX6xZsSnbfPZe2sGX5Dras2PHJ4xy7sY/5vy1m7+aDKW6b1+NTKY5NiR55E49CU2vF/U/nnNZkZAeYm5tTyrk4ZzwvqMqUSiVnT12kXPnSGvcpV8GZM54X1co8T5yjXHlnjfH2DnbU+aE6mzfs0lm7NTE3N8e5TAk8T55TlSmVSk6dPE/5CmU07lOhQhk8T55XKzvhcSZRfNVqrtz++xJePkeZOWcSWWwz67z9HzM3N6e083ec8nzfPqVSyWnP87iU15yPS3lnTn9wLgFOepzF5f/nRqFQ8P0PNbl75z7bdq3g5p3zHPbYRoOGdfSWx3/MzM0oWqowXmeuqMqUSiVeZ7wpWU77L2lJSZ8xPQDPo57rrM5ETE0xyZ6fuHv+78uUSuLu+mOSq3DS+1mkw2rIQqyGLsKy3TAUjjnff6ZQYFq4LPERT7DsNBrrEctJ98vvmBYrr788/u+/c3P5jLeqTKlUclmH58bExITvm9TGyjod/ldu6KROkTJfVWf36tUrVq9ezZgxY1iwYAEREZqnBT4UHR3N8+fP1TalUruBta1dZszMzAgPUz9eWFgEDo72GvdxcLQn7KP48LAIHBw1X1do1bYJL1++5tA+/U5h2tllwczMjLDQj3IJDcfRSXMujk72hIWFa4h3UP3scfw0fX4ZRtOfOjJx/HQqV3Vl+66VmJjo95+QbRL5hIZFJJtPaOhH+XwQ7+BgR/oMNgwY3BOP42f4uVk3Du4/xpoNC6hcRb9/VDPbZsLMzIzIsKdq5ZHhkdglMc2sLYVCgduk/lzz8uNu4N86qVPjcawzojA1RfkySq1c+TIKRfrMGveJD3/Muz2Lid44negd80FhglXP31BkTMhdYZMRhaUV5tWaEBfky9u1vxEX4IVlmyGY5E36uqYuJH1unn72uSlQND+eQYc4e/8YI6e5Mbz7WP4OevBZdX4uY5vGTNPVmMWLF+fs2bPY2try6NEjqlevztOnTylcuDB3795lypQpXLx4kXz58iVZh7u7O5MmTVIrS29pT0YrR303Xytt2jdj9/b9REe/S+umpMquHQdU///mjdvcuB7ItesnqVrdNdEo6mun+H8HffigB0sXrQXguv8tylcoS+dubTh/7nJaNu+zDZ86mAJF89Gzab+0bkoi8Y+CiH8UpPo5+uFtrAbMxqz898R4bAVFwrmJu3WF2AsJ/+bigx9gkrsI5uV/IPp+QJq0+3M9uPuQDt/3IH0GG2r/VIMJc0fTu/mANO3w5NmYX9CtW7eIjY0FYNSoUWTPnp0HDx7g5eXFgwcPKFWqFGPGjEm2jlGjRvHs2TO1LUM6zd/4kxIZEUVsbCz2DuqjMgcHO8I+GiH8Jyw0HIeP4u0d7BKNQAAqVCpLwcL52bx+p1btSo2IiKfExsYmGmE6ONoTGqI5l9CQcBwc7DXEhyV5nAf3HxEeHkn+/Hk+v9HJiEwiH0cHu2TzcfxoRO7wQXxkxFNiYmK4feuuWszt23fJmTO7DlufWFTkM2JjY7F1yKJWbmtvS0RY5GfXP+z3QVT7vjJ9Wg4i9EnS508XlK+fo4yLSzSKU6TPnGi0l6T4OOKf/I2JbdYP6owlPvQf9bCwf/W+GjPpc5Pls89NbEws/9z/l1v+t1nkvpygm3dorWHlpjFZuHAhefPmJV26dLi6uuLl5ZVk7PLly6lWrRpZsmQhS5Ys1K1bN9l4Tb6aacwLFy4wceJEMmXKBED69OmZNGkSZ8+eTXY/S0tLMmbMqLYpFNqlFRMTg9+1m1StUVFVplAoqFrdFe/Lmi/ue3tdU4sHqF6rEt6XryWKbduhBb5Xr3PzeqBW7UqNmJgYrl29To2alVVlCoWC6jUrc9nrqsZ9vLyuqsUD1KpVJcl4gOzZs2Jrm5mQYP3+QY2JicH32g2q16ikKlMoFFSrUYkrlzW378rla1T76NzUqFWZK/8/NzExMVz18adAIfUZgwIF8vLo0b+6TeAjsTGx3PK7Tfmq5VRlCoWC8lXL4u/9eddwhv0+iJr1q9Gn1SAeP3ryuU39tLg44h/fwzR/ifdlCgWm+UsQ/+h2yupQKDBxyo3yxdP3df57FxN79S8dJnbZUD7T/OVGV5I6Ny46ODcfM1GYYGFhrtM6tZWW05hbt27Fzc2NCRMm4OPjQ+nSpalXrx6hoaEa4z09PWnbti0nT57kwoUL5MqVix9++IF//03572uad3YKhQKAt2/fki2b+j1OOXLkICxMv39M/7N80VradWpJqzZNKFg4P9NmjcfKxoqtG3cDMHfxVEaOH6SKX7l0AzXrVKFX384UKJQPtxG/Usq5BKuXq6/YSp/Bhp+a/PBFRnX/WbRgFZ26tKZNu2YULlKAWXMnY2NtxcYNCSumFi+bwfiJQ1XxSxetoc731ejbvzuFCudnxOgBOJctwfKl6wGwsbFm8m8jcCnvTK7cOahesxIbty7h3t0HeBw/o/d8lixcTYfOP9O6bVMKFc7PjNkTsbaxUi32WbDkD8ZOcFPFL1u8jtp1q9GnX1cKFsrPsJH9cC5TgpXL3t/PtXDeSpo2b0CHzq3Ilz833Xu2p16DWqxesVnv+Wxato2m7X6iYav65C2Yh5HThmBlbcW+LQkr8ybOHU3fUe9XxpqZm1H4u4IU/q4g5ubmOGSzp/B3BcmZN4cqZsTUwTRo/j3j+k7m9cvX2DnYYudgi2U6C73mEnN+P2bl6mDmXAOFQw4sGvVAYWFJjI8nABYt+mL+fVtVvHnNFpgWKIUiiyMm2fJh2XIAiswOxHh7vK/z7F5MS1TGrFwdFLZOmLnWw7RIOWIuHdFrLpBwbpq0a0jDVvXIWzAPI6a5YWVtxf4th4CEc/PrqJ6qeDNzMwp9V5BCH5ybQh+dm19H9aSMaymy5cxKgaL5+XVUT8pWdubw7uN6zyc58UqlzjZtzZo1i549e9K1a1eKFy/OkiVLsLa2ZtUqzffubty4kV9//RVnZ2eKFi3KihUriI+Px8PDQ2O8Jmn+BJU6depgZmbG8+fPCQwMpESJ998SHzx4gJ3dl7mRdO/uw9ja2zJ0dD8cHO254X+LDi17qRatZM+Zjfj49yf1itc1+vUczvAxAxgxbhB/33tA9w79CQy4o1Zvk+Y/olAo2LMz5UuMP9funQext7dj9NhBODo54O93k5bNuqmmWHPmyk58/PvvY16XrtKzmxtjxg1m3MQh3Lt7nw5t+hBwM+HaSlxcHMVLFKVN++ZkypSB4CehnDhxlqlTZvPunf6vQe7ZdQg7O1tGjB6Ao5MD1/0DaN28h2qBUM6c2VB+kM9lr6v07jGUUWMHMWa8G/fu3qdzu77cCnh/rejg/uMMGzyRgW6/MPWPsdwN+puuHQdw6aJ3ouPr2rG9J8hsl5lew7ph52DL7Rt3GNB+KJHhCaObrDmcUH7wb83ByZ6Nx97/EejYpy0d+7TF+/xVerccCEDLLs0AWLprvtqxJg2ayv5th/WWS9z1C7yzyYh5nZ+xSJ+Z+Cf3ebtuKrx6BoBJJnu13xuFVXosmvZKmOp884r4x/d4u3wsyrD339DjAi7zbt9yzKs3xaJhV+LDHxO9ZSbxD/U/M3J870my2GXmlw/OzcD2w1TnximHo9rvTsK5Wan6+cNz06flICBhGnTCvNHYO9rx8sUr7gTcZUC7YXidvoKhiI6OJjpa/RYpS0tLLC0tE8W+e/cOb29vRo0apSozMTGhbt26XLiQsuv/r1+/JiYmBlvblC8cStP77D5eWFKxYkXq1aun+nnYsGH8888/bN6s3bft1Nxn9zXT9j67r52299l9zVJzn93XTNv77L522t5n9zXT9X12HfI011ldBbuWSvT3fMKECUycODFR7OPHj8mRIwfnz5+nUqX3lyeGDx/OqVOnuHTp0ieP9+uvv3LkyBFu3LhBunQpe3BCmo7sJkyYkOznM2bM+EItEUII46LLZ2OOGjUKNzc3tTJNozpdmDZtGlu2bMHT0zPFHR18BdOYQgghvm1JTVlqYm9vj6mpKSEh6qPukJAQsmZNfmbhzz//ZNq0aRw/fpxSpZJ/3u/H0nyBihBCiC9PqcP/acPCwoJy5cqpLS75b7HJh9OaH5s+fTpTpkzh8OHDuLi4aJ2vjOyEEMIIpeWTT9zc3OjcuTMuLi5UqFCBOXPm8OrVK7p2TXhmaqdOnciRIwfu7u4A/PHHH4wfP55NmzaRN29egoODgYRb1NKnT5+iY0pnJ4QQ4otq3bo1YWFhjB8/nuDgYJydnTl8+DBOTgkLvh4+fKj2KMLFixfz7t07WrZUvxE/qUUwmkhnJ4QQRiitX97ar18/+vXT/Eg7T09PtZ/v37//2ceTa3ZCCCEMnozshBDCCBnbg6ClsxNCCCP0rbyaR1dkGlMIIYTBk5GdEEIYoTR8UmSakM5OCCGMUFqvxvzSZBpTCCGEwZORnRBCGCFjW6AinZ0QQhghY7v1QKYxhRBCGDwZ2QkhhBEytgUq0tkJIYQRMrZbD2QaUwghhMGTkZ0QQhghWY0phBDC4MlqTCGEEMLAyMhOCCGMkKzGFEIIYfBkNaYQQghhYGRkJ4QQRkimMYUQQhg8Y1uNaZCdXWx8XFo3QacsTA3rNL2KiU7rJujM1fC7ad0EnXKa+Sitm6BTTx96pHUTxFfCsP6KCiGESJF4I1ugIp2dEEIYIePq6mQ1phBCCCMgIzshhDBCshpTCCGEwTO2zk6mMYUQQhg8GdkJIYQRMrbHhUlnJ4QQRkimMYUQQggDIyM7IYQwQvK4MCGEEAbP2K7ZyTSmEEIIgycjOyGEMELGtkBFOjshhDBCMo0phBBCGBgZ2QkhhBGSaUwhhBAGz9huPZBpTCGEEAZPOjshhDBC8UqlzrbUWLhwIXnz5iVdunS4urri5eWVZOyNGzdo0aIFefPmRaFQMGfOHK2PJ52dEEIYIaUO/6etrVu34ubmxoQJE/Dx8aF06dLUq1eP0NBQjfGvX78mf/78TJs2jaxZs6YqX+nshBBCfFGzZs2iZ8+edO3aleLFi7NkyRKsra1ZtWqVxvjy5cszY8YM2rRpg6WlZaqOKQtUhBDCCKV2+lGT6OhooqOj1cosLS01dkzv3r3D29ubUaNGqcpMTEyoW7cuFy5c0FmbPiYjOyGEMEK6nMZ0d3cnU6ZMapu7u7vG44aHhxMXF4eTk5NauZOTE8HBwXrLV0Z2QgghPsuoUaNwc3NTK0vtdKO+SGcnhBBGSJfTmElNWWpib2+PqakpISEhauUhISGpXnySEjKN+YGuPdpx2c+DByG+HPLYSpmyJZONb9S0HmcvH+RBiC+e5/dS5/vqiWIKFc7Pus2LCHp4mb8f+3D45HZy5MymrxRUDCkXgF96deRGwBnCI29x8tRuyrmUTja+WbMf8bl6nPDIW1zyOsQP9WomGTt33m+8fP03v/btquNWJ61P787cuX2Rl8/vcv7sPsq7OCcb36LFT1z3P8XL53e56nOcBvVrqz4zMzPDfeporvoc59nTIB7e92b1qrlky+aUTI26Y2jnZvPOffzQojNlazWmbc9B+N8MTDK2S7/hlKjSINHWZ+h4VYymz0tUacCqjTu+RDpJSqvVmBYWFpQrVw4PDw9VWXx8PB4eHlSqVEnXaapIZ/d/TZo3YNLUkcz8YyHfV2/OjeuBbNm9Ant7W43xLhXKsGTlTDat30Hdas04dOA4azYtoGixQqqYPPlysffIJoKC7tHsp07UrNKE2dMXEf02WmOdkotmLVo0xH3aGNynzqVq5Z+47h/Anr/W4uBgpzHe1bUsq9fOZe3abVSp1JD9+4+xZetSihcvnCi2UeMfKF+hDI8f6+9awcdatWrMnzMmMOW3WZR3rY+v300OHtiYZD6VKrqwcf1CVq/ejEuFeuzde4SdO1by3XdFALC2tqKMc0l+nzqX8q71afVzT4oUzs/uXav1nouhnZtDx08xff4y+nRrz/ZV8ylSMB+93MYS8TRKY/zcqePw3LtRte1ZvwRTUxPq1aqmivnwc8+9G5kyejAKhYLva1b5Qll9fdzc3Fi+fDlr164lICCAPn368OrVK7p2TfhS06lTJ7UFLO/evePatWtcu3aNd+/e8e+//3Lt2jXu3LmT4mMqlAb46GunTEW13ueQx1au+lxn9LApACgUCq7e9GTlsg3Mn708Ufyy1bOwtramQ+veqrKDx7dw3f8WwwdPBGDpqpnExMTSr9eI1CWSSl97Lq9itOsgT57ajY+3H0PcJgAJ+QQGnWfJ4rXMmrkkUfzadfOxtrGiVYseqrITnrvw97vJwAFjVWXZsjvheWo3TRt3ZseuVSxcsIpFC7XrIN7GvtMqHuD82X1cvuLLwEFjVfncv3eZhYtWM33GwkTxmzYuxsbamibNOqvKzp3ZxzXfG/TtN1LjMVzKlebihYPkK1CeR48ep7ht6cwstMrlaz43AE8fenw66ANtew6iRNHCjBnyK5Aw4qjbrBPtWjamR8efP7n/+q27WbBiPSf3bsLaKp3GmAEjJ/Pq9WtWzpumVdvM7fNrFf8pBezL6qyuu+E+Wu+zYMECZsyYQXBwMM7OzsybNw9XV1cAatasSd68eVmzZg0A9+/fJ1++fInqqFGjBp6enik6nozsAHNzc0o5f8cZz/OqMqVSyWnPC7iUd9a4T7nyzpz+IB7gpMc5VbxCoaDuDzW5e+c+W3at4Madcxzy2EqDhnX0lQZgWLlAQj5lypTg5MmzqjKlUsnJE+eo4Kr5l7WCaxlOnjinVuZx/DQVKryPVygUrFgxi7mzlxEQEKSfxmtgbm5O2bKl8DhxRlWmVCrxOHGWihXLadynoms5tXiAo8c8k4wHyJQpI/Hx8URFPddNwzUwtHMTExPDzcAgKn7we2JiYkJFF2d8rwekqI5d+4/SoG6NJDu68MinnD7vRfOf6umiyZ8lLW8qB+jXrx8PHjwgOjqaS5cuqTo6AE9PT1VHB5A3b16USmWiLaUdHaRxZ+fj48Pff/+t+nn9+vVUqVKFXLlyUbVqVbZs2fJF2mFrlwUzMzPCQiPUysPCwnF0ste4j6OTfbLx9g52pM9gw4DBPTl5/Aw/N+vOwf3HWbVhPpWqlNdPIhhWLgB29gn5hIaEq5WHhobj5OSgcR8nJwfCQpOPdxvSm9jYOBYtWqPzNifH3t42iXzCyJpEPlmzOhASGqZWFhISnmS8paUlU6eOZsvWPbx48VI3DdfA0M7N06jnxMXFY2ebRa3czjYL4ZFPP7m//81Agu7dp0Wj+knG7D10HGtrK+rWMN4pzLSSpqsxu3btysyZM8mXLx8rVqxgwIAB9OzZk44dOxIYGEjPnj15/fo13bp1S7IOTTczKpXxKBRpO2g1MUk4/uGDJ1i6aC0AN/xvUb5CGTp3a8OFc5fTsnlaMaRcAJzLlODXvl2pUvmntG6KzpmZmbFl8xIUCgV9+4369A5fmW/53Ozaf4RCBfJSsniRJGN27z/KTz/UwtJSu+lifVAq49O6CV9UmvYIQUFBFCqUsAhi0aJFzJ07l7lz59K7d29mz57N0qVLmTlzZrJ1aLqZ8VV0pFbtiIx4SmxsLA6O6hfVHRzsE31r/U9oSHiy8ZERT4mJieH2LfULqLdv39XrCkZDygUgIjwhn49HpY6O9oSEhGncJyQkDAfHpOMrVy6Pg4MdtwLPEfU8iKjnQeTJkxP3aWO4EXBGU5U6Ex4emUQ+DgQnkU9wcBhOjuojJScn+0Tx/3V0uXPnpH6Dtnod1YHhnZssmTNiampCxEejuIjIp9h/NNr72Os3bzl0/FSy05Pe167z98N/aJ7MyO9Likeps+1bkKadnbW1NeHhCX9Q//33XypUqKD2uaurq9o0pyajRo3i2bNnapuNpeZVh0mJiYnB79oNqtV4v+xVoVBQrUZFrly+pnEf78vX1OIBatSqrIqPiYnhms91ChRSv6haoEBe/tFiwYC2DCmX/4599ep1an6wck2hUFCzVmW8Lmm+KO516So1a6lPE9WqXRUvr4T4LZt3U7FCAypXbKjaHj8OZs7sZTRt3FlTlToTExODj48ftWtVVZUpFApq16rKxYveGve5eMmb2rWrqpXVrVNdLf6/jq5gwXzUq9+ayBRMu30uQzs35ubmFC9SiEtXrqnK4uPjueR9jdIliiW779ETZ3gXE0OjerWTjNm1/wjFixSiaCHdLjQRKZOm05gNGjRg8eLFrFixgho1arBjxw5Kl35/j862bdsoWLBgsnVoupkxNVOYSxauYd7iaVy7ep2r3n788mtnrG2s2LJhFwDzl0wj+Ekov0+aBcCyxevZc3Advft15fgRT5q2aEjpMt8xdOD7+2sWzlvJstWzuHj+CmfPXKJ2nWr80KAWzRp20rp9xpoLwIJ5K1i6fCY+Pn54X/Glb79uWFtbs2F9wn1Ky5bP5PHjYCZOmAHAooWrOXx0C/0H9ODI4RO0bNWIsmVLMqDfaAAiI6OIjIxSO0ZMTCwhIWEEBd3Tez6z5y5n9crZePv4cfnyVQb074mNjRVr1m4FYPWquTx+/IQxYxNW682fv5ITHjsYPKgXBw8dp/XPTShXrhS9fx0OJHR027Yuo4xzSZo064ypqanqGlhkZBQxMTF6y8XQzk2n1s0Y8/tMvitaiBLFi7Bh2x7evI2macPvARg15U8c7e0Y3Ef9vr9d+49Qu1olMmfKqLHel69ecfTkGYb266n3HFLKABfiJytNO7s//viDKlWqUKNGDVxcXJg5cyaenp4UK1aMwMBALl68yO7du79IW/7adQg7O1uGj+6Po5MDN/wDaNu8J2FhCQs3cuTMTnz8+38cV7yu0qfHUEaOHcTo8YP5++59urTrx60PVo8d2n+c4YMnMsDtF377Ywx3g/6me8cBeF3UfpmuseYCsHPnAewd7Bg7zg0nJ3v8/AJo1rQLof9f6JArV3bi499ff7h0yYduXQYxbsIQJk4ayt0792nTuhc3b97We1tTYvv2vTjY2zJx/FCyZnXA1/cGDX/qoMon90f5XLh4hQ6d+jF50nB+mzKCoDt/06Jld27cSLjZOUeOrDRulDB95nPlmNqx6tRtyanT+nu4rqGdmwZ1a/A06hkLVmwgPDKSooUKsGTmFNU05pOQUEwUCrV9/n7wDz5+N1g2+/ck6z10/BRKJfz4fU19Nl8r38r0o66k+X12UVFRTJs2jX379nHv3j3i4+PJli0bVapUYfDgwbi4uGhdZ2rusxNfjrb32X3NUnOf3ddM2/vsvnba3mf3NdP1fXY5bUvorK5/Iq/rrC59SfPOTh+ks/u6SWf39ZLO7uul684uR5bvdFbXv09v6KwufZEHQQshhBHS5YOgvwXyBBUhhBAGT0Z2QghhhFL7mK9vlXR2QghhhAxwuUayZBpTCCGEwZORnRBCGCFju89OOjshhDBCMo0phBBCGBgZ2QkhhBEytvvspLMTQggjJNOYQgghhIGRkZ0QQhghWY0phBDC4Mk0phBCCGFgZGQnhBBGSFZjCiGEMHjG9iBomcYUQghh8GRkJ4QQRkimMYUQQhg8WY0phBBCGBgZ2QkhhBEytgUq0tkJIYQRkmlMIYQQwsDIyE4IIYyQsY3spLMTQggjZFxdnUxjCiGEMAZKkSpv375VTpgwQfn27du0bopOGFI+hpSLUin5fM0MKRdDp1AqjWziVkeeP39OpkyZePbsGRkzZkzr5nw2Q8rHkHIByedrZki5GDqZxhRCCGHwpLMTQghh8KSzE0IIYfCks0slS0tLJkyYgKWlZVo3RScMKR9DygUkn6+ZIeVi6GSBihBCCIMnIzshhBAGTzo7IYQQBk86OyGEEAZPOjshhBAGTzo7LZ0+fZpGjRqRPXt2FAoFe/bsSesmpZq7uzvly5cnQ4YMODo60rRpUwIDA9O6Wam2ePFiSpUqRcaMGcmYMSOVKlXi0KFDad0snZg2bRoKhYJBgwaldVNSZeLEiSgUCrWtaNGiad2sz/Lvv//SoUMH7OzssLKyomTJkly5ciWtmyWSIJ2dll69ekXp0qVZuHBhWjfls506dYq+ffty8eJFjh07RkxMDD/88AOvXr1K66alSs6cOZk2bRre3t5cuXKF2rVr06RJE27cuJHWTfssly9fZunSpZQqVSqtm/JZvvvuO548eaLazp49m9ZNSrWnT59SpUoVzM3NOXToEDdv3mTmzJlkyZIlrZsmkiCv+NFSgwYNaNCgQVo3QycOHz6s9vOaNWtwdHTE29ub6tWrp1GrUq9Ro0ZqP//+++8sXryYixcv8t1336VRqz7Py5cvad++PcuXL+e3335L6+Z8FjMzM7JmzZrWzdCJP/74g1y5crF69WpVWb58+dKwReJTZGQnVJ49ewaAra1tGrfk88XFxbFlyxZevXpFpUqV0ro5qda3b18aNmxI3bp107opny0oKIjs2bOTP39+2rdvz8OHD9O6Sam2d+9eXFxcaNWqFY6OjpQpU4bly5endbNEMmRkJwCIj49n0KBBVKlShRIlSqR1c1LN39+fSpUq8fbtW9KnT8/u3bspXrx4WjcrVbZs2YKPjw+XL19O66Z8NldXV9asWUORIkV48uQJkyZNolq1aly/fp0MGTKkdfO0du/ePRYvXoybmxujR4/m8uXLDBgwAAsLCzp37pzWzRMaSGcngIQRxPXr17/p6ygARYoU4dq1azx79owdO3bQuXNnTp069c11eI8ePWLgwIEcO3aMdOnSpXVzPtuHU/+lSpXC1dWVPHnysG3bNrp3756GLUud+Ph4XFxcmDp1KgBlypTh+vXrLFmyRDq7r5RMYwr69evH/v37OXnyJDlz5kzr5nwWCwsLChYsSLly5XB3d6d06dLMnTs3rZulNW9vb0JDQylbtixmZmaYmZlx6tQp5s2bh5mZGXFxcWndxM+SOXNmChcuzJ07d9K6KamSLVu2RF+gihUr9k1PzRo6GdkZMaVSSf/+/dm9ezeenp4GeYE9Pj6e6OjotG6G1urUqYO/v79aWdeuXSlatCgjRozA1NQ0jVqmGy9fvuTu3bt07NgxrZuSKlWqVEl0m87t27fJkydPGrVIfIp0dlp6+fKl2rfRv//+m2vXrmFra0vu3LnTsGXa69u3L5s2beKvv/4iQ4YMBAcHA5ApUyasrKzSuHXaGzVqFA0aNCB37ty8ePGCTZs24enpyZEjR9K6aVrLkCFDomunNjY22NnZfZPXVIcOHUqjRo3IkycPjx8/ZsKECZiamtK2bdu0blqqDB48mMqVKzN16lR+/vlnvLy8WLZsGcuWLUvrpomkKIVWTp48qQQSbZ07d07rpmlNUx6AcvXq1WndtFTp1q2bMk+ePEoLCwulg4ODsk6dOsqjR4+mdbN0pkaNGsqBAwemdTNSpXXr1sps2bIpLSwslDly5FC2bt1aeefOnbRu1mfZt2+fskSJEkpLS0tl0aJFlcuWLUvrJolkyCt+hBBCGDxZoCKEEMLgSWcnhBDC4ElnJ4QQwuBJZyeEEMLgSWcnhBDC4ElnJ4QQwuBJZyeEEMLgSWcnRAp16dKFpk2bqn6uWbNmmrw53NPTE4VCQVRU1Bc/thDfKunsxDevS5cuKBQKFAqF6kHQkydPJjY2Vq/H3bVrF1OmTElRrHRQQqQteTamMAj169dn9erVREdHc/DgQfr27Yu5uTmjRo1Si3v37h0WFhY6OaYhvORWCGMhIzthECwtLcmaNSt58uShT58+1K1bl71796qmHn///XeyZ89OkSJFgIT3xf38889kzpwZW1tbmjRpwv3791X1xcXF4ebmRubMmbGzs2P48OF8/GS9j6cxo6OjGTFiBLly5cLS0pKCBQuycuVK7t+/T61atQDIkiULCoWCLl26AAlvZXB3dydfvnxYWVlRunRpduzYoXacgwcPUrhwYaysrKhVq5ZaO4UQKSOdnTBIVlZWvHv3DgAPDw8CAwM5duwY+/fvJyYmhnr16pEhQwbOnDnDuXPnSJ8+PfXr11ftM3PmTNasWcOqVas4e/YskZGR7N69O9ljdurUic2bNzNv3jwCAgJYunQp6dOnJ1euXOzcuROAwMBAnjx5onrHnru7O+vWrWPJkiXcuHGDwYMH06FDB06dOgUkdMrNmzenUaNGXLt2jR49ejBy5Eh9/WcTwnCl8YOohfhsnTt3VjZp0kSpVCqV8fHxymPHjiktLS2VQ4cOVXbu3Fnp5OSkjI6OVsWvX79eWaRIEWV8fLyqLDo6WmllZaU8cuSIUqlUKrNly6acPn266vOYmBhlzpw5VcdRKtXfQhAYGKgElMeOHdPYxv/elvH06VNV2du3b5XW1tbK8+fPq8V2795d2bZtW6VSqVSOGjVKWbx4cbXPR4wYkaguIUTy5JqdMAj79+8nffr0xMTEEB8fT7t27Zg4cSJ9+/alZMmSatfpfH19uXPnDhkyZFCr4+3bt9y9e5dnz57x5MkTXF1dVZ+ZmZnh4uKSaCrzP9euXcPU1JQaNWqkuM137tzh9evXfP/992rl7969o0yZMgAEBASotQOgUqVKKT6GECKBdHbCINSqVYvFixdjYWFB9uzZMTN7/0/bxsZGLfbly5eUK1eOjRs3JqrHwcEhVcdPzctuX758CcCBAwfIkSOH2meWlpapaocQQjPp7IRBsLGxoWDBgimKLVu2LFu3bsXR0ZGMGTNqjMmWLRuXLl2ievXqAMTGxuLt7U3ZsmU1xpcsWZL4+HhOnTpF3bp1E33+38gyLi5OVVa8eHEsLS15+PBhkiPCYsWKsXfvXrWyixcvfjpJIYQaWaAijE779u2xt7enSZMmnDlzhr///htPT08GDBjAP//8A8DAgQOZNm0ae/bs4datW/z666/J3iOXN29eOnfuTLdu3dizZ4+qzm3btgGQJ08eFAoF+/fvJywsjJcvX5IhQwaGDh3K4MGDWbt2LXfv3sXHx4f58+ezdu1aAHr37k1QUBDDhg0jMDCQTZs2sWbNGn3/JxLC4EhnJ4yOtbU1p0+fJnfu3DRv3pxixYrRvXt33r59qxrpDRkyhI4dO9K5c2cqVapEhgwZaNasWbL1Ll68mJYtW/Lrr79StGhRevbsyatXrwDIkSMHkyZNYuTIkTg5OdGvXz8ApkyZwrhx43B3d6dYsWLUr1+fAwcOkC9fPgBy587Nzp072bNnD6VLl2bJkiVMnTpVj/91hDBMCmVSV9yFEEIIAyEjOyGEEAZPOjshhBAGTzo7IYQQBk86OyGEEAZPOjshhBAGTzo7IYQQBk86OyGEEAZPOjshhBAGTzo7IYQQBk86OyGEEAZPOjshhBAGTzo7IYQQBu9/PeaS56Yr+DMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# model.eval()\n",
        "# y_true, y_pred = [], []\n",
        "# img,label=next(iter(test_loader))\n",
        "# # img=\n",
        "# with torch.no_grad():\n",
        "#     # print(img.shape) # [16, 3, 400, 640]\n",
        "#     img=img.to(device)\n",
        "#     pimg = model(img)\n",
        "#     for x, y in test_loader:\n",
        "#         x, y = x.to(device), y.to(device)\n",
        "#         pred = model(x)\n",
        "#         correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "def confusion(dataloader, model, loss_fn, verbose=True):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    # y_true, y_pred = [], []\n",
        "    # y_true, y_pred = torch.empty(0), torch.empty(0)\n",
        "    y_true, y_pred = torch.empty(0, device=device), torch.empty(0, device=device)\n",
        "    # test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            # print(pred[0])\n",
        "            # loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            # test_loss += loss_fn(pred, y).item()\n",
        "            print((pred.argmax(1)==y).sum().item(), pred.argmax(1).tolist(), y.tolist())\n",
        "            # y_true(pred.argmax(1)), y_pred(y)\n",
        "            y_pred = torch.cat((y_pred, pred.argmax(1)), 0)\n",
        "            y_true = torch.cat((y_true, y), 0)\n",
        "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    # test_loss /= num_batches\n",
        "    # correct /= size\n",
        "    # should not use weighted rand sampler for test?\n",
        "    # if verbose: print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
        "    # return correct, test_loss\n",
        "    return y_true, y_pred\n",
        "    # y_true, y_pred = y_true(), y_pred.cpu()\n",
        "    # cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
        "    # cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    # fig, ax = plt.subplots(figsize=(5,5))\n",
        "    # sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=['1','2','3','4','5','6',], yticklabels=['1','2','3','4','5','6',])\n",
        "    # plt.ylabel('Actual')\n",
        "    # plt.xlabel('Predicted')\n",
        "    # plt.show()\n",
        "\n",
        "# y_true, y_pred = confusion(test_loader, model, loss_fn)\n",
        "\n",
        "y_true, y_pred = y_true.cpu(), y_pred.cpu()\n",
        "cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
        "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=['1','2','3','4','5','6',], yticklabels=['1','2','3','4','5','6',])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayRePbr_rq9F"
      },
      "outputs": [],
      "source": [
        "# pytorch release gpu ram after training\n",
        "# https://discuss.pytorch.org/t/free-all-gpu-memory-used-in-between-runs/168202/2\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# correct, test_loss = test(test_loader, model, loss_fn)\n",
        "# train_lst.extend(train_ls)\n",
        "# test_lst.append(test_loss)\n",
        "# acc_lst.append(correct)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q_3Cttn1qHcc"
      },
      "outputs": [],
      "source": [
        "# @title trash\n",
        "\n",
        "model.eval()\n",
        "count=0\n",
        "i=138\n",
        "rong_lst=[]\n",
        "\n",
        "while count<20:\n",
        "    img,label=test_data[i]\n",
        "    pred=model(img.unsqueeze(0).to(device))\n",
        "    pred_probab = nn.Softmax(dim=1)(pred)\n",
        "    y_pred = pred_probab.argmax(1)\n",
        "    if y_pred.item() != label:\n",
        "        print(\"pred: \",y_pred.item(),\", actual: \",label)\n",
        "        # plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "        # plt.show()\n",
        "        imshow(img)\n",
        "        rong_lst.append(img)\n",
        "        count+=1\n",
        "    i+=1\n",
        "\n",
        "\n",
        "# 20/137 wrong\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJs2bVL0rXnG"
      },
      "outputs": [],
      "source": [
        "print(i)\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=4))\n",
        "# print(torch.stack(rong_lst).shape)\n",
        "# print(len(rong_lst))\n",
        "# print(rong_lst[0].shape)\n",
        "imshow(torchvision.utils.make_grid(torch.stack(rong_lst),nrow=4))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}