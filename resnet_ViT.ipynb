{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/resnet_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2kQGpnynh2oQ"
      },
      "outputs": [],
      "source": [
        "# @title download\n",
        "# original 10k\n",
        "# # https://drive.google.com/file/d/1NkCNecLpFG3i7bo3Vl9RQSwzBpSRQ29q/view?usp=sharing\n",
        "# !gdown 1NkCNecLpFG3i7bo3Vl9RQSwzBpSRQ29q -O gsv.zip\n",
        "# !unzip /content/gsv.zip -d /content\n",
        "# import shutil\n",
        "# shutil.rmtree('/content/google_street_view/meta_data', ignore_errors=True) # delete the meta_data folder\n",
        "\n",
        "# # clip cleaned\n",
        "# # https://drive.google.com/file/d/1-xcHyVAMeTkY7SUdUyQRVAn_FFXPSDGB/view?usp=share_link\n",
        "# !gdown 1-xcHyVAMeTkY7SUdUyQRVAn_FFXPSDGB -O gsv.zip\n",
        "# !unzip /content/gsv.zip -d /\n",
        "# !rm -R /content/gsv/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/01/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/02/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/03/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/04/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/05/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv/06/.ipynb_checkpoints\n",
        "\n",
        "# # gsv 70k\n",
        "# # https://drive.google.com/file/d/1-7ZC29k4VxXQkpnOuLfj7Ag_SFTM4LV8/view?usp=share_link\n",
        "# !gdown 1-7ZC29k4VxXQkpnOuLfj7Ag_SFTM4LV8 -O gsv.zip\n",
        "# !unzip /content/gsv.zip -d /\n",
        "\n",
        "# # # !ls\n",
        "# !ls -a /content/gsv70k\n",
        "# !rm -R /content/gsv70k/.ipynb_checkpoints\n",
        "# # # !rm -R /content/gsv/06/.ipynb_checkpoints\n",
        "\n",
        "# # 70k+gmap\n",
        "# # https://drive.google.com/file/d/1-CZp7TbhJLeRQpbKQCyT8ofGg89Yt137/view?usp=sharing\n",
        "!gdown 1-CZp7TbhJLeRQpbKQCyT8ofGg89Yt137 -O gsv.zip\n",
        "!unzip /content/gsv.zip -d /\n",
        "!rm -R /content/gsv70kg/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/01/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/02/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/03/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/04/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/05/.ipynb_checkpoints\n",
        "!rm -R /content/gsv70kg/06/.ipynb_checkpoints\n",
        "\n",
        "# # https://bestasoff.medium.com/how-to-fine-tune-very-large-model-if-it-doesnt-fit-on-your-gpu-3561e50859af\n",
        "!pip install bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title torch augment\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.RandomApply([transforms.Compose([\n",
        "        # self.transform = transforms.Compose([\n",
        "                transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                transforms.RandomResizedCrop((400,640), scale=(0.7, 1.0), ratio=(0.8, 1.25), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(p=0.5), # 0.5\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,), # brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8\n",
        "                transforms.RandomGrayscale(p=0.2), # 0.2\n",
        "                # transforms.RandomChoice(transforms.ColorJitter , transforms.RandomGrayscale(p=1.)\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.5)\n",
        "                transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "                # transforms.ToTensor(), # ToTensored at dataset level, no need to ToTensor again\n",
        "                # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalised at dataset level. default 0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225\n",
        "                ])\n",
        "            ], p=1.)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "        x1 = self.transform(sample)\n",
        "        return x1\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yjix6KhUqxY1"
      },
      "outputs": [],
      "source": [
        "# @title data (old)\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "dir='/content/gsv70kg'\n",
        "\n",
        "data = datasets.ImageFolder(dir, transform=transform)\n",
        "# data = datasets.ImageFolder(dir, transform=None)\n",
        "torch.manual_seed(0)\n",
        "train_data, test_data = torch.utils.data.random_split(data, [.9,.1])\n",
        "\n",
        "batch_size = 16 # 64\n",
        "num_batches=int(np.ceil(len(train_data)/batch_size))\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "del data, train_data, test_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqw5n--6WYEG",
        "outputId": "83962b99-9d86-4386-8929-d8f05fe6bb84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# dataset has PILImage images of range [0, 1], transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "# transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# dir='/content/gsv'\n",
        "dir='/content/gsv70kg'\n",
        "\n",
        "# data = datasets.ImageFolder(dir, transform=transform)\n",
        "data = datasets.ImageFolder(dir, transform=None)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# split data manually so that can work with weighted random sampler\n",
        "# train_data, test_data = torch.utils.data.random_split(data, [.85,.15])\n",
        "# https://www.scaler.com/topics/pytorch/how-to-split-a-torch-dataset/\n",
        "data_size = len(data)\n",
        "indices = np.arange(data_size)\n",
        "np.random.shuffle(indices)\n",
        "split_index = int(np.floor(0.9 * data_size))\n",
        "train_idx, test_idx = indices[:split_index], indices[split_index:]\n",
        "train_data = torch.utils.data.Subset(data, train_idx)\n",
        "test_data = torch.utils.data.Subset(data, test_idx)\n",
        "targets = np.array(data.targets)\n",
        "train_targets = targets[train_idx]\n",
        "test_targets = targets[test_idx]\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "class DatasetWrap(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super(DatasetWrap, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "# dataset wrapper in order to apply transforms to train data only\n",
        "# train_data = DatasetWrap(train_data, TrainTransform()) # apply data augmentation to train dataset only\n",
        "train_data = DatasetWrap(train_data, transform) # apply transform during training to use gpu\n",
        "test_data = DatasetWrap(test_data, transform)\n",
        "\n",
        "# use batch size 16 for resnet 152/ vit with grad accumulation\n",
        "# can use batch size 64 for inception v3 without grad accumulation?\n",
        "batch_size = 16 # 64/16\n",
        "num_batches=int(np.ceil(len(train_data)/batch_size))\n",
        "\n",
        "# oversampling\n",
        "# https://stackoverflow.com/questions/62319228/number-of-instances-per-class-in-pytorch-dataset\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data.targets).values()))\n",
        "weights=1./class_count\n",
        "# weights=sum(class_count)/class_count\n",
        "# print(weights)\n",
        "# https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler\n",
        "\n",
        "train_weight = weights[train_targets]\n",
        "test_weight = weights[test_targets]\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(train_weight, len(train_weight))\n",
        "test_sampler = torch.utils.data.WeightedRandomSampler(test_weight, len(test_weight))\n",
        "# train_sampler = torch.utils.data.WeightedRandomSampler(train_weight, 70000)\n",
        "# test_sampler = torch.utils.data.WeightedRandomSampler(test_weight, 7000)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "del data, train_data, test_data\n",
        "\n",
        "\n",
        "# test oversampling: occurence of each class should be roughly equal\n",
        "# c=0\n",
        "# print(len(test_loader))\n",
        "# # for batch, (x, y) in enumerate(train_loader):\n",
        "# for batch, (x, y) in enumerate(test_loader):\n",
        "#     print(torch.bincount(y)) # torch count number of elements with value in tensor\n",
        "#     c+=1\n",
        "#     if c>5: break\n",
        "\n",
        "# display img from torch tensor\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = next(dataiter)\n",
        "# images=trs(images)\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=4))\n",
        "# del dataiter\n",
        "\n",
        "# print(labels)\n",
        "\n",
        "# dataiter = iter(test_loader)\n",
        "# images, labels = next(dataiter)\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=4))\n",
        "# del dataiter\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "images=trs(images)\n",
        "imshow(torchvision.utils.make_grid(images[:4],nrow=4))\n",
        "# del dataiter\n",
        "\n",
        "print(labels)\n"
      ],
      "metadata": {
        "id": "q8aE4nUhm4ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7oYDr8kuA5Bl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "# # https://pytorch.org/vision/0.12/models.html#id10\n",
        "model = models.resnet152(weights='DEFAULT') # 18 34 50 101 152\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential( # og (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "    nn.Linear(num_ftrs, 6),\n",
        "    nn.Softmax(dim=1),\n",
        "    )\n",
        "\n",
        "# print(model)\n",
        "\n",
        "# # model.mods = [module for k, module in model._modules.items()]\n",
        "# # modules = [module for k, module in model._modules.items()]\n",
        "\n",
        "# torch._dynamo.config.suppress_errors = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "model = torch.compile(model.to(device))\n",
        "# model = torch.compile(model.to(device),mode='reduce-overhead')\n",
        "# model = torch.compile(model.to(device),mode='max-autotune')\n",
        "\n",
        "# resnet152 batch16 compile gradacc nogradckpt lr3e-6,3e-5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rJw9_Ort2Sek"
      },
      "outputs": [],
      "source": [
        "# @title vit\n",
        "# https://arxiv.org/pdf/2010.11929.pdf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "# https://pytorch.org/vision/main/models/vision_transformer.html\n",
        "# https://pytorch.org/vision/main/models/generated/torchvision.models.vit_b_16.html#torchvision.models.vit_b_16\n",
        "# model = models.vit_l_16(weights='DEFAULT') # small vit_b_16 vit_b_32 vit_l_16 vit_l_32 vit_h_14 big\n",
        "# # VisionTransformer(image_size, patch_size, num_layers, num_heads, hidden_dim, mlp_dim)\n",
        "# num_ftrs = model.heads.head.in_features\n",
        "# # num_ftrs = model.heads[-1].in_features\n",
        "# model.heads = nn.Sequential(\n",
        "#     # nn.Dropout(0.2),\n",
        "#     nn.Linear(num_ftrs, 6, bias=False),\n",
        "#     nn.Softmax(dim=1),\n",
        "#     )\n",
        "\n",
        "\n",
        "!pip install timm\n",
        "# https://github.com/huggingface/pytorch-image-models/issues/908\n",
        "import timm\n",
        "# model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "model = timm.create_model('vit_base_patch16_224', img_size=(400, 640), pretrained=True)\n",
        "# [print(x) for x in timm.list_models('vit*',pretrained=True)]\n",
        "# https://huggingface.co/google/vit-base-patch16-224\n",
        "# https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/vision_transformer.py\n",
        "# vit_base_patch16_224 compile,no ckpt # patch_size=16, embed_dim=768, depth=12, num_heads=12\n",
        "# vit_base_patch16_384\n",
        "# vit_large_patch16_224 explodesgpu # patch_size=16, embed_dim=1024, depth=24, num_heads=16\n",
        "# vit_large_patch16_384 # patch_size=16, embed_dim=1024, depth=24, num_heads=16\n",
        "\n",
        "# or fine tune huge\n",
        "# vit_large_patch14_224 # patch_size=16, embed_dim=1024, depth=24, num_heads=16\n",
        "# vit_large_patch16_384\n",
        "\n",
        "\n",
        "num_ftrs = model.head.in_features\n",
        "model.head = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 6),\n",
        "    nn.Softmax(dim=1),\n",
        "    )\n",
        "# model.set_grad_checkpointing()\n",
        "\n",
        "# print(model.patch_embed.grid_size) # (25, 40)\n",
        "# print(model.pos_embed.shape) # [1, 1001, 768]\n",
        "# https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
        "\n",
        "# print(model)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "model = torch.compile(model.to(device))\n",
        "# model = torch.compile(model.to(device),mode='reduce-overhead')\n",
        "# model = torch.compile(model.to(device),mode='max-autotune')\n",
        "\n",
        "# vit_base_patch16_224 batch16 maxcompile nockpt gradacc lr1e-5,1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-oKYpG8n2fBI"
      },
      "outputs": [],
      "source": [
        "# @title inception\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "# # https://pytorch.org/vision/0.12/models.html#id10\n",
        "model = models.inception_v3(pretrained=True)\n",
        "# https://discuss.pytorch.org/t/inception-v3-is-not-working-very-well/38296/16\n",
        "# https://colab.research.google.com/github/CaoCharles/Deep-Learning-with-PyTorch/blob/master/2_Inception.ipynb\n",
        "model.aux_logits = False\n",
        "num_ftrs = model.fc.in_features # 2048\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 6), # og: (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "    # nn.Linear(num_ftrs, 128), nn.ReLU(), nn.Linear(128, 6),\n",
        "    nn.Softmax(dim=1),\n",
        "    )\n",
        "# pytorch \"inception\" v3 \"gradient checkpointing\" https://github.com/jianweif/OptimalGradCheckpointing\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "model = torch.compile(model.to(device))\n",
        "# model = torch.compile(model.to(device),mode='max-autotune')\n",
        "\n",
        "# inception batch64 compile nogradacc nogradckpt lr3e-6,3e-5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEZCFg5YSS9J",
        "outputId": "6bd41d04-a4aa-4f33-8edd-6a61197b2330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 6])\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# @title try\n",
        "\n",
        "# # check model's input and output dimensions are correct\n",
        "# X = torch.rand(64, 3, 32, 32, device=device)\n",
        "X = torch.rand(16, 3, 400, 640, device=device)\n",
        "# X = torch.rand(16, 3, 224, 224, device=device)\n",
        "model.eval()\n",
        "\n",
        "# 224x224\n",
        "# 16x16 / 32x32 patch\n",
        "# -> 14x14=196 7x7=49 seq length\n",
        "# 400x640 -> 25x40=1000 seq length\n",
        "\n",
        "\n",
        "logits = model(X)\n",
        "\n",
        "# modules = [module for k, module in model._modules.items()]\n",
        "# for i,x in enumerate(modules):\n",
        "#     print(i,x)\n",
        "\n",
        "# logits = checkpoint_sequential(functions=modules, segments=1, input=X)\n",
        "\n",
        "print(logits.shape)\n",
        "# print(logits[0])\n",
        "# print(logits[0].argmax(1))\n",
        "\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(y_pred)\n",
        "del X, logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "# https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/resnet_new.py\n",
        "from torch.utils.checkpoint import checkpoint, checkpoint_sequential\n",
        "\n",
        "trs=TrainTransform() # for image augmentation during train time\n",
        "# train function with automatic mixed precision\n",
        "def strain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "            x = trs(x) # image augmentation during train time to use gpu\n",
        "            pred = model(x) # default\n",
        "            print(\"train\",pred[0])\n",
        "            # modules = [module for k, module in model._modules.items()]\n",
        "            # pred = checkpoint_sequential(functions=modules, segments=1, input=x) # gradient checkpointing for resnet and inception only\n",
        "            # # # pred = checkpoint_sequential(functions=model.mods, segments=1, input=x)\n",
        "            print((pred.argmax(1)==y).sum().item(), pred.argmax(1).tolist(), y.tolist())\n",
        "            loss = loss_fn(pred, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        if ((batch + 1) % 4 == 0) or (batch + 1 == len(dataloader)): # gradient accumulation\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "                print(\"### lr: \", optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        # if (batch) % (size//(10* len(x))) == 0:\n",
        "        # loss, current = loss.item(), batch * len(x)\n",
        "        loss, current = loss.item()/len(y), batch * len(x)\n",
        "        if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def test(dataloader, model, loss_fn, verbose=True):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    # model.eval()\n",
        "    model.train()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            print(pred[0])\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            print((pred.argmax(1)==y).sum().item(), pred.argmax(1).tolist(), y.tolist())\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    # should not use weighted rand sampler for test?\n",
        "    if verbose: print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
        "    return correct, test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "a5CHCIMo7ZC5"
      },
      "outputs": [],
      "source": [
        "# @title Lamb\n",
        "# https://github.com/cybertronai/pytorch-lamb/blob/master/pytorch_lamb/lamb.py\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "class Lamb(Optimizer):\n",
        "    \"\"\"Large Batch Optimization for Deep Learning: Training BERT in 76 minutes: https://arxiv.org/abs/1904.00962\n",
        "        adam (bool, optional): always use trust ratio = 1, which turns this into Adam\"\"\"\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-6, weight_decay=0, adam=False): # eps=1e-8, weight_decay=0\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.adam = adam\n",
        "        super(Lamb, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None: loss = closure() # closure (callable, optional): A closure that reevaluates the model and returns the loss.\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None: continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse: raise RuntimeError('Lamb does not support sparse gradients, consider SparseAdam instad.')\n",
        "                state = self.state[p] # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data) # Exponential moving average of gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data) # Exponential moving average of squared gradient values\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "                state['step'] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1) # m_t\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2) # v_t\n",
        "\n",
        "                # Paper v3 does not use debiasing.\n",
        "                # bias_correction1 = 1 - beta1 ** state['step']\n",
        "                # bias_correction2 = 1 - beta2 ** state['step']\n",
        "                # Apply bias to lr to avoid broadcast.\n",
        "                step_size = group['lr'] # * math.sqrt(bias_correction2) / bias_correction1\n",
        "                weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)\n",
        "                adam_step = exp_avg / exp_avg_sq.sqrt().add(group['eps'])\n",
        "                if group['weight_decay'] != 0: adam_step.add_(p.data, alpha=group['weight_decay'])\n",
        "                adam_norm = adam_step.pow(2).sum().sqrt()\n",
        "                if weight_norm == 0 or adam_norm == 0: trust_ratio = 1\n",
        "                else: trust_ratio = weight_norm / adam_norm\n",
        "                state['weight_norm'] = weight_norm\n",
        "                state['adam_norm'] = adam_norm\n",
        "                state['trust_ratio'] = trust_ratio\n",
        "                if self.adam: trust_ratio = 1\n",
        "                p.data.add_(adam_step, alpha=-step_size * trust_ratio)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iuumbm2SB_lX"
      },
      "outputs": [],
      "source": [
        "# @title LR range test\n",
        "# gives insight into good LR range to use.\n",
        "# for accurate results, be sure to use a new model for range test;\n",
        "# also reset the model before training bec range test destroys the model\n",
        "# 1cycle super convergencehttps://arxiv.org/pdf/1708.07120.pdf\n",
        "# # cyclic lr https://arxiv.org/pdf/1506.01186.pdf\n",
        "# Note the learning rate value when the accuracy starts to\n",
        "# increase and when the accuracy slows, becomes ragged, or starts to fall\n",
        "\n",
        "# one training run of the network for a few epochs\n",
        "# pth='/content/lr.pth'\n",
        "# torch.save(model.state_dict(), pth) # save temporary model for lr finding\n",
        "# model.load_state_dict(torch.load(\"lr.pth\"))\n",
        "# torch.autograd.set_detect_anomaly(True)\n",
        "epochs=1\n",
        "min_lr= 1e-6\n",
        "max_lr= 1e-1 # 1e-2\n",
        "# 152: 1e-7 - 1e-4      result 3e-7 - 3e-6\n",
        "# inception: 1e-7 - 1e1      result 3e-7 - 3e-6\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=start_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=start_lr, momentum=0.9)\n",
        "# import bitsandbytes as bnb\n",
        "# optimizer = bnb.optim.AdamW(model.parameters(), lr=min_lr, betas=(0.9, 0.999), optim_bits=8)\n",
        "optimizer = Lamb(model.parameters(), lr=min_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "\n",
        "num_batches=len(test_loader)\n",
        "# num_batches=len(train_loader)\n",
        "\n",
        "# total_steps=int(num_batches*epochs)\n",
        "total_steps=int(np.ceil(num_batches/4)*epochs) # for grad accumulation\n",
        "\n",
        "# min_lr* gamma^total_steps = max_lr\n",
        "gamma = np.exp(np.log(max_lr/min_lr)/total_steps)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # 0.75(20)-0.9(100)\n",
        "\n",
        "total_steps=total_steps*4 # for grad accumulation\n",
        "gamma = np.exp(np.log(max_lr/min_lr)/total_steps)\n",
        "lr_list=np.ones(total_steps)*min_lr*gamma**np.arange(total_steps)\n",
        "train_lst, test_lst=[],[]\n",
        "\n",
        "\n",
        "print(\"lr: \", optimizer.param_groups[0][\"lr\"])\n",
        "for i in range(epochs):\n",
        "    train_ls = strain(test_loader, model, loss_fn, optimizer, scheduler)\n",
        "    # train_ls = strain(train_loader, model, loss_fn, optimizer, scheduler)\n",
        "    train_lst.extend(train_ls)\n",
        "print(optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "# https://stackoverflow.com/a/53472966/13359815\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "train_lstsm = gaussian_filter1d(train_lst, sigma=30)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lr_list, train_lst)\n",
        "plt.plot(lr_list, train_lstsm)\n",
        "plt.xscale('log')\n",
        "# plt.plot(train_lst)\n",
        "# plt.plot(np.linspace(0,len(train_lst),len(test_lst)), test_lst)\n",
        "plt.show()\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wkBp7WjC8LLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2d353c-4923-46d0-fada-cf75bc531d99",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# @title wwwwwwwww\n",
        "acc_lst, train_lst, test_lst=[],[],[]\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "base_lr, max_lr = 3e-7, 3e-6 # resnet\n",
        "# base_lr, max_lr = 1e-3, 1e-2 # resnet lamb\n",
        "# base_lr, max_lr = 1e-6, 1e-5 # vit\n",
        "# base_lr, max_lr = 3e-6, 3e-5 # inception\n",
        "# end_lr, start_lr = 1e-5, 1e-3 # 0.0001,0.1\n",
        "tp=0\n",
        "epochs = 5 #5 20\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr = start_lr, momentum=0.9)\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "import bitsandbytes as bnb # 8bit optimizer\n",
        "optimizer = bnb.optim.AdamW(model.parameters(), lr=base_lr, betas=(0.9, 0.999), optim_bits=8)\n",
        "# optimizer = bnb.optim.AdamW(model.parameters(), lr=3e-6, betas=(0.9, 0.999), optim_bits=8)\n",
        "# optimizer = Lamb(model.parameters(), lr=base_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "# optimizer = Lamb(model.parameters(), lr=1e-2, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "# 152 1e-5\n",
        "# cnn 3e-4\n",
        "\n",
        "div_factor = max_lr/base_lr\n",
        "num_batches=len(train_loader)\n",
        "# total_steps=int(num_batches*epochs)+1 # +1 to excluse uptick at the end of onecycle\n",
        "total_steps=int(np.ceil(num_batches/4)*epochs +1) # /4 for when using grad accumulation\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, total_steps=total_steps, pct_start=0.45, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=div_factor, final_div_factor=100.0, three_phase=True,)\n",
        "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, epochs=epochs, steps_per_epoch=num_batches, pct_start=0.45, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=div_factor, final_div_factor=10000.0, three_phase=True,)\n",
        "# gamma = np.exp(np.log(end_lr/start_lr)/(num_batches*epochs)) # for scheduler step every optimizer step\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # 0.75(20)-0.9(100)\n",
        "\n",
        "# pth='/content/res15270kg.pth'\n",
        "# pth='/content/res15270kg05aug.pth' # sps\n",
        "# pth='/content/drive/MyDrive/frame/res15236.pth' # B\n",
        "# pth='/content/drive/MyDrive/frame/res152373605aug.pth' # B\n",
        "# pth='/content/drive/MyDrive/frame/res152lamb12.pth' # sps\n",
        "# pth='/content/res152lamb12.pth' # sps\n",
        "# pth='/content/res15236.pth' # B\n",
        "pth='/content/drive/MyDrive/frame/res15237361aug.pth' # ty\n",
        "\n",
        "\n",
        "# pth='/content/vit.pth'\n",
        "# pth='/content/drive/MyDrive/frame/vit.pth'\n",
        "# pth='/content/drive/MyDrive/frame/vit3736.pth'\n",
        "# pth='/content/drive/MyDrive/frame/vit161505aug.pth' # A\n",
        "\n",
        "# pth='/content/drive/MyDrive/frame/inception1.pth'\n",
        "# pth='/content/drive/MyDrive/frame/inception363505aug.pth' # ty\n",
        "\n",
        "\n",
        "# # to continue training\n",
        "tp, modelsd, optimsd, schedsd = torch.load(pth).values()\n",
        "# tp, modelsd, optimsd = torch.load(pth).values()\n",
        "model.load_state_dict(modelsd)\n",
        "# optimizer.load_state_dict(optimsd)\n",
        "# scheduler.load_state_dict(schedsd)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REiP7-nvhc4s",
        "outputId": "9e46580e-90b5-4fd6-8d96-c7fdf8b2981a",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# @title save\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# # pth='/content/drive/MyDrive/frame/vit.pth'\n",
        "# pth='/content/drive/MyDrive/frame/res55.pth'\n",
        "# pth='/content/drive/MyDrive/frame/resnet152.pth'\n",
        "# pth='/content/drive/MyDrive/frame/res152373605aug.pth'\n",
        "# pth='/content/res152373605aug.pth' # B\n",
        "# pth='/content/drive/MyDrive/frame/res152lamb12.pth' # ty\n",
        "\n",
        "# pth='/content/drive/MyDrive/frame/inception.pth'\n",
        "# pth='/content/inception2.pth'\n",
        "\n",
        "# pth='/content/res15270kg.pth'\n",
        "\n",
        "# pth='/content/drive/MyDrive/frame/vit3736.pth'\n",
        "\n",
        "\n",
        "# tp, modelsd, optimsd, schedsd = torch.load(pth).values()\n",
        "# model.load_state_dict(modelsd)\n",
        "# # optimizer.load_state_dict(optimsd)\n",
        "# # scheduler.load_state_dict(schedsd)\n",
        "\n",
        "\n",
        "checkpoint = { # https://discuss.pytorch.org/t/saving-model-and-optimiser-and-scheduler/52030\n",
        "'epoch': t+1,\n",
        "'model': model.state_dict(),\n",
        "'optimizer': optimizer.state_dict(),\n",
        "'lr_sched': scheduler.state_dict()\n",
        "}\n",
        "torch.save(checkpoint, pth)\n",
        "\n",
        "\n",
        "\n",
        "# torch.save(model.state_dict(), pth)\n",
        "# model.load_state_dict(torch.load(pth))\n",
        "# # model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# !gdown 1---4fdFbOUBTrS-VP5Va6pKowfgoU2UN -O inception2.pth\n",
        "# !gdown 1visTNvWmnuV7jAm2TBiAIIrNjbOAi1Fv -O resnet152.pth # B weighted 56.0% unweighted 56.84\n",
        "# !gdown 1vszqD7O9hju9-iWm4WkDPZ_adHY1j2rw -O res152373605augA.pth # A\n",
        "# !gdown 1IDQLTn6yisr47-ronpJGfEmi2-lhAcve -O res152373605aug.pth # S nan\n",
        "# !gdown 1-3oA1cKxgw4cfrqx079h_MKtMqRT1UFq -O res152lamb12.pth # S 53.6%\n",
        "# !gdown 1MdC4t07TFGI1sFVQsD9ofKATizGfzIPO -O res15236.pth # B 10epoch 57.6%\n",
        "\n",
        "# # t, modelsd, optimsd, scheduler = torch.load('/content/drive/MyDrive/frame/resnet152.pth').values()\n",
        "# t, modelsd, optimsd, scheduler = torch.load('/content/resnet152.pth').values()\n",
        "# model.load_state_dict(modelsd)\n",
        "# # optimizer.load_state_dict(optimsd)\n",
        "\n",
        "# !gdown 1MQ0xLfHbio458uEVbn2VyMpD3bij2A4J -O res152.pth # M weighted % unweighted  # low\n",
        "# model.load_state_dict(torch.load(\"res152.pth\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDBEk-l-Oxjn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "# scheduler = PolynomialLR(optimizer, total_iters=4, power=1.0)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=10**(-1/2))\n",
        "# for epoch in range(5):\n",
        "#     scheduler.step()\n",
        "for t in range(tp,epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    lr=optimizer.param_groups[0][\"lr\"]\n",
        "    print(lr)\n",
        "    train_ls = strain(train_loader, model, loss_fn, optimizer, scheduler)\n",
        "    # train_ls = strain(train_loader, model, loss_fn, optimizer)\n",
        "    correct, test_loss = test(test_loader, model, loss_fn)\n",
        "    train_lst.extend(train_ls)\n",
        "    test_lst.append(test_loss)\n",
        "    acc_lst.append(correct)\n",
        "\n",
        "    checkpoint = { # https://discuss.pytorch.org/t/saving-model-and-optimiser-and-scheduler/52030\n",
        "    'epoch': t+1,\n",
        "    'model': model.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "    'lr_sched': scheduler.state_dict()}\n",
        "    torch.save(checkpoint, pth)\n",
        "    # torch.save(model.state_dict(), pth)\n",
        "\n",
        "# print(\"Done!\")\n",
        "\n",
        "# end = time.time()\n",
        "# print(\"time: \",end - start)\n",
        "\n",
        "# print(len(train_lst), len(test_lst))\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(train_lst)\n",
        "# plt.plot(np.linspace(0,len(train_lst),len(test_lst)), test_lst)\n",
        "# plt.show()\n",
        "# plt.plot(acc_lst)\n",
        "# plt.show()\n",
        "# plt.close()\n",
        "\n",
        "\n",
        "# torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "# resnet 18, 60/61 38.4%, 528s\n",
        "# resnet 18, 58/61 39.8%, 523s\n",
        "# resnet 18 compile , 58/61 40.4%, 555s\n",
        "# resnet 18 compile augment , 58/61 36.4%, 1941 # augment on cpu, takes longer\n",
        "# resnet 18 augment lr3e-4:3e-3, 58/61 37.7%, 1863s\n",
        "# resnet 18 augment 10epoch lr1e-5:3e-4, 58/61 33.5%, 3387s\n",
        "# resnet 18 compile lr1e-5:3e-4, 58/61 35.0%, 493s\n",
        "# resnet 18 compile scratch lr1e-5:1e-3, 58/61 26.8%, 475s\n",
        "# resnet 18 compile lr1e-5:1e-3, 55/61 47.3%, 480s\n",
        "# resnet 18 compile lr1e-5:1e-3, 52/61 51.7% 503s\n",
        "# resnet 18 compile lr1e-5:1e-3, unfreeze 51.0%, 550s\n",
        "# resnet 18 compile lr1e-5:1e-4, unfreeze 52.7%, 518s\n",
        "# resnet 34 compile lr1e-5:1e-4, unfreeze bitsadamW batch16*4\n",
        "# resnet 152 compileoverhead lr3e-7:3e-6, bitsadamW batch16*4 ckpt 53.8%, 2066s\n",
        "# resnet 152 from53.8% augment+cutout lr3e-7:3e-6, 53.8%, 2088s\n",
        "# resnet 152 comile augment+cutout lr1e-5 /4 1epoch 48.3%, 454s\n",
        "# resnet 152 comile augment+cutout lr1e-5 1epoch 48.4%, 446s\n",
        "# resnet 152 comilemaxautotue augment+cutout lr1e-5 1epoch 47.7%, 448\n",
        "# resnet 152 clipclean comilemax augment+cutout lr1e-5 10epoch 45.1%, 1585 *2\n",
        "# resnet 152 clipclean comilemax augmax lr1e-6:3e-5 20epoch\n",
        "# resnet 152 clipclean compilemax lr3e-7:1e-5,\n",
        "# resnet 152 70k augment compilemax lr3e-7:3e-6 5epoch, 65.4% 11585s*5/3=19300s = 5h20m\n",
        "\n",
        "# resnet 152 70k augment0.8 compile lr3e-7:3e-6 5epoch, not learning? slow?\n",
        "# resnet 152 70k augment1 compile lr3e-7:3e-6 5epoch,\n",
        "# normafter\n",
        "\n",
        "# resnet 152 70k augment compile adamw const lr3e-6, 59.8%\n",
        "# resnet 152 70k augment compile adamw const3e-6 stepdown\n",
        "\n",
        "\n",
        "\n",
        "# resnet 152 70k augment compile lamb lr1e-2 not learning\n",
        "# resnet 152 70k augment compile lamb lr3e-3 not learning\n",
        "# resnet 152 70k augment compile lamb lr1e-3:1e-2 5epoch,\n",
        "# 2/5epochwarmup 55.0%\n",
        "# resnet 152 70k augment1 compile lamb lr1e-3:1e-2 5epoch nan train\n",
        "# resnet 152 70k augment1 compile lamb lr3e-4:3e-3 5epoch nan train\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# vit b16 lr1e-5 5epochs 41.3%, 466s # 4.4ram, 5.5vram\n",
        "# vit l16 lr1e-5 5epochs # 32.0%, 1242s 4.5ram, 8.0vram\n",
        "# vit l16 lr3e-7;1e-5 5epochs # 45.4%, 1315s 4.5ram, 8.0vram\n",
        "# vit l32 lr1e-5 5epochs # .ram, .vram\n",
        "# vit_large_patch16_384\n",
        "# vit_base_patch16_224 maxcompile nockpt lr3e-7;1e-5 5epochs # 45.2%, 2272s 5.3ram, 11.0vram\n",
        "# vit_base_patch16_224 maxcompile nockpt gradacc batch16 1e-5, 1e-2 explode\n",
        "# vit_base_patch16_224 maxcompile nockpt gradacc batch16 1e-6, 1e-5 low acc, test nan\n",
        "# vit_base_patch16_224 maxcompile nockpt gradacc batch16 3e-7, 3e-6 4/5 epoch50%\n",
        "# vit_base_patch16_224 maxcompile nockpt gradacc batch16 1e-6, 1e-5 0.5aug\n",
        "\n",
        "\n",
        "\n",
        "# inception\n",
        "# inception og 10kclean 1e-7, 3e-5 batch64 nockpt 5epochs 0.020348  51.4%, 0.024312 20m; 1st 40.5% max 52.1\n",
        "# inception hid 10kclean 1e-7, 3e-5 batch64 nockpt 1/5epochs 0.019635 53.6%, 0.024120 1st 32.8%, max 53.6%\n",
        "# inception og 10kclean 1e-7, 1e-4 batch64 nockpt 2/10epochs 0.020348  0.020923 39.9%, 0.026105\n",
        "# inception og 70kg 1e-7 nope\n",
        "# inception og 70kg 3e-6 3e-5 17%\n",
        "# inception og 70kg 1e-6, 1e-5\n",
        "# inception og 70kg 3e-6 3e-5 0.5aug\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())\n",
        "\n"
      ],
      "metadata": {
        "id": "QpIy7G_bpTlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86I4ghMp-dgP",
        "outputId": "6e0370b7-d4bd-4010-e57f-76f296b4b3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0009999999999999992\n"
          ]
        }
      ],
      "source": [
        "scheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer, total_iters=4, power=1.0)\n",
        "for epoch in range(100):\n",
        "    print(optimizer.param_groups[0][\"lr\"])\n",
        "    scheduler.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "PFsnIRVz7Xp5",
        "outputId": "0924b061-bbf5-4f54-e921-d0d1c918b1b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BackendCompilerFailed",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\u001b[0m in \u001b[0;36mcall_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m                 \u001b[0mcompiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_example_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m             \u001b[0m_step_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"done compiler function {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/debug_utils.py\u001b[0m in \u001b[0;36mdebug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0mcompiled_gm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model_, inputs_)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompile_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_patches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36mcompile_fx\u001b[0;34m(model_, example_inputs_, inner_compile, config_patches)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# once torchdynamo is merged into pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         return aot_autograd(\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mfw_compiler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfw_compiler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\u001b[0m in \u001b[0;36mcompiler_fn\u001b[0;34m(gm, example_inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0menable_aot_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maot_module_simplified\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mcounters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"aot_autograd\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ok\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36maot_module_simplified\u001b[0;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, hasher_type, static_argnums, keep_inference_input_mutations)\u001b[0m\n\u001b[1;32m   2821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2822\u001b[0;31m     compiled_fn = create_aot_dispatcher_function(\n\u001b[0m\u001b[1;32m   2823\u001b[0m         \u001b[0mfunctional_call\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36mtime_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mtime_spent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36mcreate_aot_dispatcher_function\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2515\u001b[0;31m         \u001b[0mcompiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_flat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maot_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36maot_wrapper_dedupe\u001b[0;34m(flat_fn, flat_args, aot_config, compiler_fn)\u001b[0m\n\u001b[1;32m   1714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompiler_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_flat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maot_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36maot_dispatch_base\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_graph_compiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maot_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m         \u001b[0mcompiled_fw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maot_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfw_compiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfw_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args_with_views_handled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36mtime_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mtime_spent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36mfw_compiler\u001b[0;34m(model, example_inputs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_outplace_to_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         return inner_compile(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/debug_utils.py\u001b[0m in \u001b[0;36mdebug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0mcompiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mDebugContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36mcompile_fx_inner\u001b[0;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mcompiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_to_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\u001b[0m in \u001b[0;36mcompile_to_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_to_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_to_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36mtime_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mtime_spent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\u001b[0m in \u001b[0;36mcompile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyCodeCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, source_code)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m                 \u001b[0;31m# another thread might set this first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torchinductor_root/p6/cp6pn3pwqjlfg2joqeoyvyisoaiffy3ttvlaqrwn6bravs6fih72.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m triton__0 = async_compile.triton('''\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtriton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\u001b[0m in \u001b[0;36mtriton\u001b[0;34m(self, source_code)\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmajor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             future = self.process_pool().submit(\n\u001b[0m\u001b[1;32m    684\u001b[0m                 \u001b[0m_worker_compile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/process.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broken\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mBrokenProcessPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_thread\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenProcessPool\u001b[0m: A child process terminated abruptly, the process pool is not usable anymore",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mBackendCompilerFailed\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fdc6ff3cf838>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# # https://discuss.pytorch.org/t/model-predictions-changing-with-no-grad-and-eval/126543/2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# self.drop_layer = nn.Dropout(p = .5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b0e3b2cce3b3>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn, verbose)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamo_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mdynamic_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36mcatch_errors\u001b[0;34m(frame, cache_size)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcompile_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mcatch_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torchdynamo_orig_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m_convert_frame\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcounters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"frames\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"total\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0mcounters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"frames\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ok\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_from_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfx_forward_from_src_skip_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_grad_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m_convert_frame_assert\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0minitial_grad_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         return _compile(\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36mtime_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mcompilation_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mtime_spent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 \u001b[0mout_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_code_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0morig_code_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_code\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\u001b[0m in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mpropagate_line_nums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0mtransformations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclean_and_assemble_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmutated_closure_cell_contents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         )\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mtracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1724\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m         \u001b[0m_step_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"torchdynamo start tracing {self.f_code.co_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatch_nested_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_pointer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             ):\n\u001b[1;32m    578\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0munimplemented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"missing: {inst.opname}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"RETURN_VALUE\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36mRETURN_VALUE\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   1790\u001b[0m         )\n\u001b[1;32m   1791\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RETURN_VALUE triggered compile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m         self.output.compile_subgraph(\n\u001b[0m\u001b[1;32m   1793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGraphCompileReason\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"return_value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\u001b[0m in \u001b[0;36mcompile_subgraph\u001b[0;34m(self, tx, partial_convert, reason)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;31m# optimization to generate better code in a common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             self.add_output_instructions(\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_and_call_fx_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcreate_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UNPACK_SEQUENCE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\u001b[0m in \u001b[0;36mcompile_and_call_fx_graph\u001b[0;34m(self, tx, rv, root)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0massert_no_fake_params_or_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mcompiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_user_compiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mcompiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiled_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36mtime_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mcompilation_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mtime_spent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\u001b[0m in \u001b[0;36mcall_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mcompiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBackendCompilerFailed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBackendCompilerFailed\u001b[0m: debug_wrapper raised BrokenProcessPool: A child process terminated abruptly, the process pool is not usable anymore\n\nSet torch._dynamo.config.verbose=True for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    torch._dynamo.config.suppress_errors = True\n"
          ]
        }
      ],
      "source": [
        "correct, test_loss = test(test_loader, model, loss_fn)\n",
        "print(correct, test_loss)\n",
        "\n",
        "# # https://discuss.pytorch.org/t/model-predictions-changing-with-no-grad-and-eval/126543/2\n",
        "# self.drop_layer = nn.Dropout(p = .5)\n",
        "# out = F.dropout(x, training=self.training)\n",
        "# # https://discuss.pytorch.org/t/trained-resnet-doesnt-work-in-eval-mode-behaves-strangely/121242/8\n",
        "# self.bn = torch.nn.BatchNorm2d(input_features,track_running_stats=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyVU_i594fMh",
        "outputId": "34e9f18d-c411-4b90-bd36-521188a7de3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6794\n",
            "425\n"
          ]
        }
      ],
      "source": [
        "print(len(test_loader.dataset))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWt4B_YoCxKB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def confusion(dataloader, model, loss_fn, verbose=True):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    y_true, y_pred = torch.empty(0, device=device), torch.empty(0, device=device)\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            # print(pred[0])\n",
        "            # loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            # test_loss += loss_fn(pred, y).item()\n",
        "            print((pred.argmax(1)==y).sum().item(), pred.argmax(1).tolist(), y.tolist())\n",
        "            # y_true(pred.argmax(1)), y_pred(y)\n",
        "            y_pred = torch.cat((y_pred, pred.argmax(1)), 0)\n",
        "            y_true = torch.cat((y_true, y), 0)\n",
        "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    # test_loss /= num_batches\n",
        "    # correct /= size\n",
        "    # should not use weighted rand sampler for test?\n",
        "    # if verbose: print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
        "    # return correct, test_loss\n",
        "    return y_true, y_pred\n",
        "    # y_true, y_pred = y_true(), y_pred.cpu()\n",
        "    # cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
        "    # cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    # fig, ax = plt.subplots(figsize=(5,5))\n",
        "    # sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=['1','2','3','4','5','6',], yticklabels=['1','2','3','4','5','6',])\n",
        "    # plt.ylabel('Actual')\n",
        "    # plt.xlabel('Predicted')\n",
        "    # plt.show()\n",
        "\n",
        "# y_true, y_pred = confusion(test_loader, model, loss_fn)\n",
        "\n",
        "y_true, y_pred = y_true.cpu(), y_pred.cpu()\n",
        "cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
        "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=['1','2','3','4','5','6',], yticklabels=['1','2','3','4','5','6',])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayRePbr_rq9F"
      },
      "outputs": [],
      "source": [
        "# pytorch release gpu ram after training\n",
        "# https://discuss.pytorch.org/t/free-all-gpu-memory-used-in-between-runs/168202/2\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# correct, test_loss = test(test_loader, model, loss_fn)\n",
        "# train_lst.extend(train_ls)\n",
        "# test_lst.append(test_loss)\n",
        "# acc_lst.append(correct)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A57FKq_YGadX"
      },
      "outputs": [],
      "source": [
        "# @title trash\n",
        "# dir='/content/google_street_view'\n",
        "\n",
        "# # data = datasets.ImageFolder(dir, transform=transform)\n",
        "# data = datasets.ImageFolder(dir, transform=None)\n",
        "# torch.manual_seed(0)\n",
        "# train_data, test_data = torch.utils.data.random_split(data, [.85,.15])\n",
        "\n",
        "# # train_data = DatasetWrap(train_data, TrainTransform()) # apply data augmentation to train dataset only\n",
        "# train_data = DatasetWrap(train_data, transform)\n",
        "# test_data = DatasetWrap(test_data, transform)\n",
        "\n",
        "\n",
        "# batch_size = 16 # 64\n",
        "# num_batches=int(np.ceil(len(train_data)/batch_size))\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "# # data, train_data, test_data = None, None, None\n",
        "\n",
        "\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = next(dataiter)\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# dataiter=None\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# dataiter = iter(train_data)\n",
        "\n",
        "\n",
        "# img,label = next(iter(sample_ds))\n",
        "i=5\n",
        "# print(len(test_data))\n",
        "# img,label=test_data[i]\n",
        "img,label=sample_ds[i]\n",
        "print(img.shape)\n",
        "# print(type(img))\n",
        "model.eval()\n",
        "pred=model(img.unsqueeze(0).to(device))\n",
        "pred_probab = nn.Softmax(dim=1)(pred)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(pred_probab)\n",
        "print(\"pred: \",y_pred.item())\n",
        "# print(img)\n",
        "# image=images[0]\n",
        "\n",
        "print(\"actual: \",label)\n",
        "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q_3Cttn1qHcc"
      },
      "outputs": [],
      "source": [
        "# @title trash\n",
        "\n",
        "model.eval()\n",
        "count=0\n",
        "i=138\n",
        "rong_lst=[]\n",
        "\n",
        "while count<20:\n",
        "    img,label=test_data[i]\n",
        "    pred=model(img.unsqueeze(0).to(device))\n",
        "    pred_probab = nn.Softmax(dim=1)(pred)\n",
        "    y_pred = pred_probab.argmax(1)\n",
        "    if y_pred.item() != label:\n",
        "        print(\"pred: \",y_pred.item(),\", actual: \",label)\n",
        "        # plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "        # plt.show()\n",
        "        imshow(img)\n",
        "        rong_lst.append(img)\n",
        "        count+=1\n",
        "    i+=1\n",
        "\n",
        "\n",
        "# 20/137 wrong\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJs2bVL0rXnG"
      },
      "outputs": [],
      "source": [
        "print(i)\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=4))\n",
        "# print(torch.stack(rong_lst).shape)\n",
        "# print(len(rong_lst))\n",
        "# print(rong_lst[0].shape)\n",
        "imshow(torchvision.utils.make_grid(torch.stack(rong_lst),nrow=4))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}