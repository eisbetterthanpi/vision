{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+RJJ0bKVAdRQ03o53uAQ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/Meta_Pseudo_Labels_down.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9XrV9ZACgjm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Meta Pseudo Labels mar 2021 https://arxiv.org/pdf/2003.10580v4.pdf\n",
        "# https://github.com/kekmodel/MPL-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title torch augment\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        # self.transform = transforms.RandomApply([transforms.Compose([\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomResizedCrop((400,640), scale=(0.7, 1.0), ratio=(0.8, 1.25), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                transforms.RandomResizedCrop((32,32), scale=(0.7, 1.0), ratio=(0.8, 1.25), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(p=0.5), # 0.5\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,), # brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8\n",
        "                transforms.RandomGrayscale(p=0.2), # 0.2\n",
        "                # # transforms.RandomChoice(transforms.ColorJitter , transforms.RandomGrayscale(p=1.)\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # # transforms.RandomSolarize(threshold=130, p=0.5)\n",
        "                transforms.RandomErasing(p=1., scale=(0.1, 0.11), ratio=(1,1), value=(0.485, 0.456, 0.406)),\n",
        "                # transforms.ToTensor(), # ToTensored at dataset level, no need to ToTensor again\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalised at dataset level. default 0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225\n",
        "                ])\n",
        "            # ], p=1.)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        dims = len(sample.shape)\n",
        "        if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "        # x1 = self.transform(sample)\n",
        "        return x1\n",
        "\n",
        "trs=TrainTransform()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6iYyVffJcYB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title utils\n",
        "# https://github.com/kekmodel/MPL-pytorch/blob/main/utils.py\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "# def reduce_tensor(tensor, n):\n",
        "#     rt = tensor.clone()\n",
        "#     dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n",
        "#     rt /= n\n",
        "#     return rt\n",
        "\n",
        "\n",
        "def create_loss_fn():\n",
        "    label_smoothing = 0 # default 0 / mainargs 0.15\n",
        "\n",
        "    # if label_smoothing > 0:\n",
        "    #     criterion = SmoothCrossEntropyV2(alpha=label_smoothing)\n",
        "    # else:\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    return criterion.to(device)\n",
        "\n",
        "\n",
        "def module_load_state_dict(model, state_dict):\n",
        "    try:\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            name = k[7:]  # remove `module.`\n",
        "            new_state_dict[name] = v\n",
        "        model.load_state_dict(new_state_dict)\n",
        "    except:\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            name = f'module.{k}'  # add `module.`\n",
        "            new_state_dict[name] = v\n",
        "        model.load_state_dict(new_state_dict)\n",
        "\n",
        "def model_load_state_dict(model, state_dict):\n",
        "    try: model.load_state_dict(state_dict)\n",
        "    except: module_load_state_dict(model, state_dict)\n",
        "\n",
        "\n",
        "import shutil\n",
        "# './checkpoint/model_best.pth.tar\n",
        "# def save_checkpoint(state, is_best, finetune=False):\n",
        "def save_checkpoint(name,save_path , state, is_best, finetune=False):\n",
        "    save_path = './checkpoint'\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    if finetune:\n",
        "        name = f'{name}_finetune'\n",
        "    # else:\n",
        "    #     name = name\n",
        "    filename = f'{save_path}/{name}_last.pth.tar'\n",
        "    torch.save(state, filename, _use_new_zipfile_serialization=False)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, f'{save_path}/{name}_best.pth.tar')\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    output = output.to(torch.device('cpu'))\n",
        "    target = target.to(torch.device('cpu'))\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.shape[0]\n",
        "    _, idx = output.sort(dim=1, descending=True)\n",
        "    pred = idx.narrow(1, 0, maxk).t()\n",
        "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(dim=0, keepdim=True)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "class SmoothCrossEntropy(nn.Module):\n",
        "    def __init__(self, alpha=0.1):\n",
        "        super(SmoothCrossEntropy, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        if self.alpha == 0:\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "        else:\n",
        "            num_classes = logits.shape[-1]\n",
        "            alpha_div_k = self.alpha / num_classes\n",
        "            target_probs = F.one_hot(labels, num_classes=num_classes).float() * (1. - self.alpha) + alpha_div_k\n",
        "            loss = (-(target_probs * torch.log_softmax(logits, dim=-1)).sum(dim=-1)).mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class SmoothCrossEntropyV2(nn.Module):\n",
        "    \"\"\"NLL loss with label smoothing.\"\"\"\n",
        "    def __init__(self, label_smoothing=0.1):\n",
        "        super().__init__()\n",
        "        assert label_smoothing < 1.0\n",
        "        self.smoothing = label_smoothing\n",
        "        self.confidence = 1. - label_smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        if self.smoothing == 0:\n",
        "            loss = F.cross_entropy(x, target)\n",
        "        else:\n",
        "            logprobs = F.log_softmax(x, dim=-1)\n",
        "            nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "            nll_loss = nll_loss.squeeze(1)\n",
        "            smooth_loss = -logprobs.mean(dim=-1)\n",
        "            loss = (self.confidence * nll_loss + self.smoothing * smooth_loss).mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\n",
        "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "metadata": {
        "id": "q_bJYwwSDNNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ModelEMA\n",
        "# expopnential moving average, smoothen model parameters\n",
        "# https://github.com/kekmodel/MPL-pytorch/blob/main/models.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from copy import deepcopy\n",
        "\n",
        "class ModelEMA(nn.Module):\n",
        "    def __init__(self, model, decay=0.9999, device=None):\n",
        "        super().__init__()\n",
        "        self.module = deepcopy(model)\n",
        "        self.module.eval()\n",
        "        self.decay = decay\n",
        "        self.device = device\n",
        "        if self.device is not None:\n",
        "            self.module.to(device=device)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.module(input)\n",
        "\n",
        "    def _update(self, model, update_fn):\n",
        "        with torch.no_grad():\n",
        "            for ema_v, model_v in zip(self.module.parameters(), model.parameters()):\n",
        "                if self.device is not None:\n",
        "                    model_v = model_v.to(device=self.device)\n",
        "                ema_v.copy_(update_fn(ema_v, model_v))\n",
        "            for ema_v, model_v in zip(self.module.buffers(), model.buffers()):\n",
        "                if self.device is not None:\n",
        "                    model_v = model_v.to(device=self.device)\n",
        "                ema_v.copy_(model_v)\n",
        "\n",
        "    def update_parameters(self, model):\n",
        "        self._update(model, update_fn=lambda e, m: self.decay * e + (1. - self.decay) * m)\n",
        "\n",
        "    def state_dict(self):\n",
        "        return self.module.state_dict()\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.module.load_state_dict(state_dict)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4J3GeedWa6QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title main\n",
        "# https://github.com/kekmodel/MPL-pytorch/blob/main/main.py\n",
        "\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.cuda import amp\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# temperature = 1 # default 1 / mainargs 0.7\n",
        "ema = 0.995 # default 0 / mainargs 0.995\n",
        "# local_rank = -1\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def set_seed():\n",
        "    random.seed(0)\n",
        "    np.random.seed(0)\n",
        "    torch.manual_seed(0)\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, num_wait_steps=0, num_cycles=0.5, last_epoch=-1):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_wait_steps:\n",
        "            return 0.0\n",
        "        if current_step < num_warmup_steps + num_wait_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps + num_wait_steps))\n",
        "        progress = float(current_step - num_warmup_steps - num_wait_steps) / \\\n",
        "            float(max(1, num_training_steps - num_warmup_steps - num_wait_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
        "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    return optimizer.param_groups[0]['lr']\n",
        "\n",
        "\n",
        "def train_loop(labeled_loader, unlabeled_loader, test_loader, finetune_dataset,\n",
        "               teacher_model, student_model, avg_student_model, criterion,\n",
        "               t_optimizer, s_optimizer, t_scheduler, s_scheduler, t_scaler, s_scaler):\n",
        "    save_path = './checkpoint'\n",
        "    name = 'model'\n",
        "\n",
        "    labeled_iter = iter(labeled_loader)\n",
        "    unlabeled_iter = iter(unlabeled_loader)\n",
        "\n",
        "    # for author's code formula\n",
        "    # moving_dot_product = torch.empty(1).to(device)\n",
        "    # limit = 3.0**(0.5)  # 3 = 6 / (f_in + f_out)\n",
        "    # nn.init.uniform_(moving_dot_product, -limit, limit)\n",
        "\n",
        "    eval_step = 1000\n",
        "    start_step=0\n",
        "    for step in range(start_step, total_steps):\n",
        "        if step % eval_step == 0:\n",
        "            batch_time = AverageMeter()\n",
        "            data_time = AverageMeter()\n",
        "            s_losses = AverageMeter()\n",
        "            t_losses = AverageMeter()\n",
        "            t_losses_l = AverageMeter()\n",
        "            t_losses_u = AverageMeter()\n",
        "            t_losses_mpl = AverageMeter()\n",
        "            mean_mask = AverageMeter()\n",
        "\n",
        "        teacher_model.train()\n",
        "        student_model.train()\n",
        "        end = time.time()\n",
        "\n",
        "        try:\n",
        "            images_l, targets = next(labeled_iter)\n",
        "        except:\n",
        "            labeled_iter = iter(labeled_loader)\n",
        "            images_l, targets = next(labeled_iter)\n",
        "\n",
        "        try:\n",
        "            # (images_uw, images_us), _ = next(unlabeled_iter)\n",
        "            images_uw, _ = next(unlabeled_iter)\n",
        "            images_us = trs(images_uw)\n",
        "        except:\n",
        "            unlabeled_iter = iter(unlabeled_loader)\n",
        "            # (images_uw, images_us), _ = next(unlabeled_iter)\n",
        "            images_uw, _ = next(unlabeled_iter)\n",
        "            images_us = trs(images_uw)\n",
        "\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        images_l = images_l.to(device)\n",
        "        images_uw = images_uw.to(device)\n",
        "        images_us = images_us.to(device)\n",
        "        targets = targets.to(device)\n",
        "        with amp.autocast():\n",
        "            batch_size = images_l.shape[0]\n",
        "            # print(images_l.shape, images_uw.shape, images_us.shape) # [64, 3, 32, 32]. [448, 3, 32, 32], [448, 3, 32, 32]\n",
        "            t_images = torch.cat((images_l, images_uw, images_us))\n",
        "            t_logits = teacher_model(t_images)\n",
        "            t_logits_l = t_logits[:batch_size]\n",
        "            t_logits_uw, t_logits_us = t_logits[batch_size:].chunk(2)\n",
        "            del t_logits\n",
        "\n",
        "            t_loss_l = criterion(t_logits_l, targets)\n",
        "\n",
        "            temperature = 1 # default 1 / mainargs 0.7\n",
        "            soft_pseudo_label = torch.softmax(t_logits_uw.detach() / temperature, dim=-1)\n",
        "            max_probs, hard_pseudo_label = torch.max(soft_pseudo_label, dim=-1)\n",
        "\n",
        "            threshold = 0.95 # default 0.95 / mainargs 0.6\n",
        "            mask = max_probs.ge(threshold).float()\n",
        "            t_loss_u = torch.mean(-(soft_pseudo_label * torch.log_softmax(t_logits_us, dim=-1)).sum(dim=-1) * mask)\n",
        "            lambda_u = 8 # default 1 / mainargs 8 coefficient of unlabeled loss\n",
        "            uda_steps = 10 # default 1 / mainargs 5000 warmup steps of lambda-u\n",
        "            weight_u = lambda_u * min(1., (step + 1) / uda_steps)\n",
        "            t_loss_uda = t_loss_l + weight_u * t_loss_u\n",
        "\n",
        "            s_images = torch.cat((images_l, images_us))\n",
        "            s_logits = student_model(s_images)\n",
        "            s_logits_l = s_logits[:batch_size]\n",
        "            s_logits_us = s_logits[batch_size:]\n",
        "            del s_logits\n",
        "\n",
        "            s_loss_l_old = F.cross_entropy(s_logits_l.detach(), targets)\n",
        "\n",
        "            # print(\"s_logits_us, hard_pseudo_label: \", s_logits_us.shape, hard_pseudo_label.shape) # [448, 10] [224]\n",
        "            s_loss = criterion(s_logits_us, hard_pseudo_label)\n",
        "\n",
        "        s_scaler.scale(s_loss).backward()\n",
        "\n",
        "        # if grad_clip > 0:\n",
        "        s_scaler.unscale_(s_optimizer)\n",
        "        nn.utils.clip_grad_norm_(student_model.parameters(), 1e9)\n",
        "\n",
        "        s_scaler.step(s_optimizer)\n",
        "        s_scaler.update()\n",
        "        s_scheduler.step()\n",
        "\n",
        "        if ema > 0: avg_student_model.update_parameters(student_model)\n",
        "\n",
        "        with amp.autocast():\n",
        "            with torch.no_grad():\n",
        "                s_logits_l = student_model(images_l)\n",
        "            s_loss_l_new = F.cross_entropy(s_logits_l.detach(), targets)\n",
        "\n",
        "            dot_product = s_loss_l_old - s_loss_l_new # theoretically correct formula (https://github.com/kekmodel/MPL-pytorch/issues/6)\n",
        "            # dot_product = s_loss_l_new - s_loss_l_old # author's code formula\n",
        "            # # moving_dot_product = moving_dot_product * 0.99 + dot_product * 0.01\n",
        "            # # dot_product = dot_product - moving_dot_product\n",
        "\n",
        "            _, hard_pseudo_label = torch.max(t_logits_us.detach(), dim=-1)\n",
        "            t_loss_mpl = dot_product * F.cross_entropy(t_logits_us, hard_pseudo_label)\n",
        "            # test\n",
        "            # t_loss_mpl = torch.tensor(0.).to(device)\n",
        "            t_loss = t_loss_uda + t_loss_mpl\n",
        "\n",
        "        t_scaler.scale(t_loss).backward()\n",
        "\n",
        "        # if grad_clip > 0:\n",
        "        t_scaler.unscale_(t_optimizer)\n",
        "        nn.utils.clip_grad_norm_(teacher_model.parameters(), 1e9)\n",
        "\n",
        "        t_scaler.step(t_optimizer)\n",
        "        t_scaler.update()\n",
        "        t_scheduler.step()\n",
        "\n",
        "        teacher_model.zero_grad()\n",
        "        student_model.zero_grad()\n",
        "\n",
        "        s_losses.update(s_loss.item())\n",
        "        t_losses.update(t_loss.item())\n",
        "        t_losses_l.update(t_loss_l.item())\n",
        "        t_losses_u.update(t_loss_u.item())\n",
        "        t_losses_mpl.update(t_loss_mpl.item())\n",
        "        mean_mask.update(mask.mean().item())\n",
        "\n",
        "        batch_time.update(time.time() - end)\n",
        "        # pbar.set_description(\n",
        "        #     f\"Train Iter: {step+1:3}/{total_steps:3}. \"\n",
        "        #     f\"LR: {get_lr(s_optimizer):.4f}. Data: {data_time.avg:.2f}s. \"\n",
        "        #     f\"Batch: {batch_time.avg:.2f}s. S_Loss: {s_losses.avg:.4f}. \"\n",
        "        #     f\"T_Loss: {t_losses.avg:.4f}. Mask: {mean_mask.avg:.4f}. \")\n",
        "        # pbar.update()\n",
        "\n",
        "        # args.num_eval = step // eval_step\n",
        "        if (step + 1) % eval_step == 0:\n",
        "            # print(s_losses.avg, t_losses.avg, t_losses_l.avg, t_losses_u.avg, t_losses_mpl.avg, mean_mask.avg)\n",
        "\n",
        "            test_model = avg_student_model if avg_student_model is not None else student_model\n",
        "            test_loss, top1, top5 = evaluate(test_loader, test_model, criterion)\n",
        "\n",
        "\n",
        "            is_best = top1 > best_top1\n",
        "            if is_best:\n",
        "                best_top1 = top1\n",
        "                best_top5 = top5\n",
        "\n",
        "            # './checkpoint/model_best.pth.tar\n",
        "            save_checkpoint(name,save_path,{\n",
        "                'step': step + 1,\n",
        "                'teacher_state_dict': teacher_model.state_dict(),\n",
        "                'student_state_dict': student_model.state_dict(),\n",
        "                'avg_state_dict': avg_student_model.state_dict() if avg_student_model is not None else None,\n",
        "                'best_top1': best_top1,\n",
        "                'best_top5': best_top5,\n",
        "                'teacher_optimizer': t_optimizer.state_dict(),\n",
        "                'student_optimizer': s_optimizer.state_dict(),\n",
        "                'teacher_scheduler': t_scheduler.state_dict(),\n",
        "                'student_scheduler': s_scheduler.state_dict(),\n",
        "                'teacher_scaler': t_scaler.state_dict(),\n",
        "                'student_scaler': s_scaler.state_dict(),\n",
        "            }, is_best)\n",
        "\n",
        "    # finetune\n",
        "    ckpt_name = f'{save_path}/{name}_best.pth.tar'\n",
        "    gpu=0\n",
        "    loc = f'cuda:{gpu}'\n",
        "    checkpoint = torch.load(ckpt_name, map_location=loc)\n",
        "    if checkpoint['avg_state_dict'] is not None:\n",
        "        model_load_state_dict(student_model, checkpoint['avg_state_dict'])\n",
        "    else:\n",
        "        model_load_state_dict(student_model, checkpoint['student_state_dict'])\n",
        "    finetune(finetune_dataset, test_loader, student_model, criterion)\n",
        "    return\n",
        "\n",
        "\n",
        "def evaluate(test_loader, model, criterion):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    model.eval()\n",
        "    test_iter = tqdm(test_loader, disable=False)\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for step, (images, targets) in enumerate(test_iter):\n",
        "            data_time.update(time.time() - end)\n",
        "            batch_size = images.shape[0]\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            with amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            acc1, acc5 = accuracy(outputs, targets, (1, 5))\n",
        "            losses.update(loss.item(), batch_size)\n",
        "            top1.update(acc1[0], batch_size)\n",
        "            top5.update(acc5[0], batch_size)\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "        test_iter.close()\n",
        "        return losses.avg, top1.avg, top5.avg\n",
        "\n",
        "\n",
        "def finetune(finetune_dataset, test_loader, model, criterion):\n",
        "    model.drop = nn.Identity()\n",
        "    train_sampler = RandomSampler\n",
        "    labeled_loader = DataLoader(finetune_dataset, batch_size=512, num_workers=4, pin_memory=True)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=3e-5, momentum=0.9, weight_decay=0, nesterov=True)\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    for epoch in range(1): #625\n",
        "\n",
        "        batch_time = AverageMeter()\n",
        "        data_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        model.train()\n",
        "        end = time.time()\n",
        "        labeled_iter = tqdm(labeled_loader, disable=False)\n",
        "        for step, (images, targets) in enumerate(labeled_iter):\n",
        "            data_time.update(time.time() - end)\n",
        "            batch_size = images.shape[0]\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            with amp.autocast():\n",
        "                model.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            losses.update(loss.item(), batch_size)\n",
        "            batch_time.update(time.time() - end)\n",
        "            labeled_iter.set_description(\n",
        "                f\"Finetune Epoch: {epoch+1:2}/{625:2}. Data: {data_time.avg:.2f}s. \"\n",
        "                f\"Batch: {batch_time.avg:.2f}s. Loss: {losses.avg:.4f}. \")\n",
        "        labeled_iter.close()\n",
        "\n",
        "        # print(losses.avg)\n",
        "        test_loss, top1, top5 = evaluate(test_loader, model, criterion)\n",
        "\n",
        "        is_best = top1 > best_top1\n",
        "        if is_best:\n",
        "            best_top1 = top1\n",
        "            best_top5 = top5\n",
        "\n",
        "        save_checkpoint({\n",
        "            'step': step + 1,\n",
        "            'best_top1': best_top1,\n",
        "            'best_top5': best_top5,\n",
        "            'student_state_dict': model.state_dict(),\n",
        "            'avg_state_dict': None,\n",
        "            'student_optimizer': optimizer.state_dict(),\n",
        "        }, is_best, finetune=True)\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "# labeled_dataset, unlabeled_dataset, test_dataset, finetune_dataset = DATASET_GETTERS[dataset](args)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=transform)\n",
        "# test_data = datasets.CIFAR10(root=\"data\", train=False, download=True,transform=transform)\n",
        "labeled_dataset, unlabeled_dataset = torch.utils.data.random_split(train_data, [.1,.9])\n",
        "test_dataset = datasets.CIFAR10(root=\"data\", train=False, download=True,transform=transform)\n",
        "finetune_dataset = labeled_dataset\n",
        "\n",
        "\n",
        "batch_size = 64 # default 64/ mainargs128\n",
        "train_sampler = RandomSampler\n",
        "labeled_loader = DataLoader(labeled_dataset, sampler=train_sampler(labeled_dataset), batch_size=batch_size, num_workers=4, drop_last=True)\n",
        "unlabeled_loader = DataLoader(unlabeled_dataset, sampler=train_sampler(unlabeled_dataset), batch_size=batch_size * 7, num_workers=4, drop_last=True) # mu=7 ,coefficient of unlabeled batch size\n",
        "test_loader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size, num_workers=4)\n",
        "\n",
        "num_classes = 10\n",
        "# if dataset == \"cifar10\": depth, widen_factor = 28, 2\n",
        "# elif dataset == 'cifar100': depth, widen_factor = 28, 8\n",
        "# teacher_model = WideResNet(num_classes=num_classes, depth=depth, widen_factor=widen_factor, dropout=0, dense_dropout=0.2)\n",
        "# student_model = WideResNet(num_classes=num_classes, depth=depth, widen_factor=widen_factor, dropout=0, dense_dropout=0.2)\n",
        "\n",
        "\n",
        "from torchvision import models\n",
        "def get_resnet():\n",
        "    model = models.resnet152(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential( # og (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "        nn.Linear(num_ftrs, num_classes, bias=False),\n",
        "        nn.Softmax(dim=1),\n",
        "        )\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # model = model.to(device)\n",
        "    model = torch.compile(model.to(device))\n",
        "    return model\n",
        "\n",
        "teacher_model = get_resnet()\n",
        "student_model = get_resnet()\n",
        "\n",
        "\n",
        "# teacher_model.to(device)\n",
        "# student_model.to(device)\n",
        "avg_student_model = None\n",
        "if ema > 0: avg_student_model = ModelEMA(student_model, ema)\n",
        "\n",
        "\n",
        "criterion = create_loss_fn()\n",
        "\n",
        "no_decay = ['bn']\n",
        "weight_decay = 5e-4 # default 0 / mainargs 5e-4\n",
        "teacher_parameters = [{'params': [p for n, p in teacher_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in teacher_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "student_parameters = [{'params': [p for n, p in student_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in student_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "# lr default 0.01/ mainargs 0.05\n",
        "t_optimizer = optim.SGD(teacher_parameters, lr=0.05, momentum=0.9, nesterov=True)\n",
        "s_optimizer = optim.SGD(student_parameters, lr=0.05, momentum=0.9, nesterov=True)\n",
        "\n",
        "total_steps=30 # 300000\n",
        "warmup_steps = 100 # default 0 / mainargs 5000\n",
        "t_scheduler = get_cosine_schedule_with_warmup(t_optimizer, warmup_steps, total_steps)\n",
        "\n",
        "student_wait_steps = 100 # default 0 / mainargs 3000\n",
        "s_scheduler = get_cosine_schedule_with_warmup(s_optimizer, warmup_steps, total_steps, student_wait_steps)\n",
        "\n",
        "t_scaler = amp.GradScaler()\n",
        "s_scaler = amp.GradScaler()\n",
        "\n",
        "# # optionally resume from a checkpoint\n",
        "# if resume:\n",
        "#     if os.path.isfile(resume):\n",
        "#         logger.info(f\"=> loading checkpoint '{resume}'\")\n",
        "#         loc = f'cuda:{gpu}'\n",
        "#         checkpoint = torch.load(resume, map_location=loc)\n",
        "#         best_top1 = checkpoint['best_top1'].to(torch.device('cpu'))\n",
        "#         best_top5 = checkpoint['best_top5'].to(torch.device('cpu'))\n",
        "#         if not (evaluate or finetune):\n",
        "#             start_step = checkpoint['step']\n",
        "#             t_optimizer.load_state_dict(checkpoint['teacher_optimizer'])\n",
        "#             s_optimizer.load_state_dict(checkpoint['student_optimizer'])\n",
        "#             t_scheduler.load_state_dict(checkpoint['teacher_scheduler'])\n",
        "#             s_scheduler.load_state_dict(checkpoint['student_scheduler'])\n",
        "#             t_scaler.load_state_dict(checkpoint['teacher_scaler'])\n",
        "#             s_scaler.load_state_dict(checkpoint['student_scaler'])\n",
        "#             model_load_state_dict(teacher_model, checkpoint['teacher_state_dict'])\n",
        "#             if avg_student_model is not None:\n",
        "#                 model_load_state_dict(avg_student_model, checkpoint['avg_state_dict'])\n",
        "#         else:\n",
        "#             if checkpoint['avg_state_dict'] is not None:\n",
        "#                 model_load_state_dict(student_model, checkpoint['avg_state_dict'])\n",
        "#             else:\n",
        "#                 model_load_state_dict(student_model, checkpoint['student_state_dict'])\n",
        "\n",
        "    #     logger.info(f\"=> loaded checkpoint '{resume}' (step {checkpoint['step']})\")\n",
        "    # else:\n",
        "    #     logger.info(f\"=> no checkpoint found at '{resume}'\")\n",
        "\n",
        "\n",
        "# finetune(finetune_dataset, test_loader, student_model, criterion)\n",
        "# evaluate(test_loader, student_model, criterion)\n",
        "\n",
        "teacher_model.zero_grad()\n",
        "student_model.zero_grad()\n",
        "train_loop(labeled_loader, unlabeled_loader, test_loader, finetune_dataset,\n",
        "            teacher_model, student_model, avg_student_model, criterion,\n",
        "            t_optimizer, s_optimizer, t_scheduler, s_scheduler, t_scaler, s_scaler)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LZVx1qyfCwGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5ad1831-3a06-44ac-9acd-b6c772a505a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter: 300/300. LR: 0.0000. Data: 1.48s. Batch: 3.07s. S_Loss: 2.2101. T_Loss: 2.0056. Mask: 0.0000. :  30%|███       | 300/1000 [41:06<1:35:55,  8.22s/it]\n",
            "Train Iter:   1/ 30. LR: 0.0000. Data: 2.43s. Batch: 236.32s. S_Loss: 2.3026. T_Loss: 2.3013. Mask: 0.0000. :   0%|          | 1/1000 [03:56<65:35:21, 236.36s/it]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:   2/ 30. LR: 0.0000. Data: 1.87s. Batch: 119.26s. S_Loss: 2.3031. T_Loss: 2.3113. Mask: 0.0000. :   0%|          | 2/1000 [03:58<27:20:34, 98.63s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:   3/ 30. LR: 0.0000. Data: 1.89s. Batch: 80.49s. S_Loss: 2.3026. T_Loss: 2.3008. Mask: 0.0000. :   0%|          | 3/1000 [04:01<15:12:59, 54.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:   4/ 30. LR: 0.0000. Data: 1.76s. Batch: 60.93s. S_Loss: 2.3027. T_Loss: 2.3057. Mask: 0.0000. :   0%|          | 4/1000 [04:03<9:26:45, 34.14s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:   5/ 30. LR: 0.0000. Data: 1.67s. Batch: 49.18s. S_Loss: 2.3024. T_Loss: 2.3064. Mask: 0.0000. :   0%|          | 5/1000 [04:05<6:15:13, 22.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:   6/ 30. LR: 0.0000. Data: 1.61s. Batch: 41.35s. S_Loss: 2.3025. T_Loss: 2.3082. Mask: 0.0000. :   1%|          | 6/1000 [04:08<4:19:49, 15.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:   7/ 30. LR: 0.0000. Data: 1.56s. Batch: 35.76s. S_Loss: 2.3028. T_Loss: 2.3069. Mask: 0.0000. :   1%|          | 7/1000 [04:10<3:06:34, 11.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:   8/ 30. LR: 0.0000. Data: 1.53s. Batch: 31.57s. S_Loss: 2.3026. T_Loss: 2.3057. Mask: 0.0000. :   1%|          | 8/1000 [04:12<2:18:52,  8.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:   9/ 30. LR: 0.0000. Data: 1.58s. Batch: 28.39s. S_Loss: 2.3027. T_Loss: 2.2997. Mask: 0.0000. :   1%|          | 9/1000 [04:15<1:50:46,  6.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  10/ 30. LR: 0.0000. Data: 1.56s. Batch: 25.77s. S_Loss: 2.3025. T_Loss: 2.3019. Mask: 0.0000. :   1%|          | 10/1000 [04:17<1:27:51,  5.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  11/ 30. LR: 0.0000. Data: 1.53s. Batch: 23.63s. S_Loss: 2.3024. T_Loss: 2.3018. Mask: 0.0000. :   1%|          | 11/1000 [04:20<1:12:06,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  12/ 30. LR: 0.0000. Data: 1.51s. Batch: 21.84s. S_Loss: 2.3027. T_Loss: 2.3012. Mask: 0.0000. :   1%|          | 12/1000 [04:22<1:00:57,  3.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  13/ 30. LR: 0.0000. Data: 1.49s. Batch: 20.33s. S_Loss: 2.3027. T_Loss: 2.3008. Mask: 0.0000. :   1%|▏         | 13/1000 [04:24<53:14,  3.24s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  14/ 30. LR: 0.0000. Data: 1.50s. Batch: 19.05s. S_Loss: 2.3030. T_Loss: 2.3021. Mask: 0.0000. :   1%|▏         | 14/1000 [04:26<49:27,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  15/ 30. LR: 0.0000. Data: 1.52s. Batch: 17.97s. S_Loss: 2.3030. T_Loss: 2.3014. Mask: 0.0000. :   2%|▏         | 15/1000 [04:29<48:28,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  16/ 30. LR: 0.0000. Data: 1.51s. Batch: 16.98s. S_Loss: 2.3029. T_Loss: 2.3015. Mask: 0.0000. :   2%|▏         | 16/1000 [04:31<44:43,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  17/ 30. LR: 0.0000. Data: 1.49s. Batch: 16.11s. S_Loss: 2.3030. T_Loss: 2.3031. Mask: 0.0000. :   2%|▏         | 17/1000 [04:34<42:06,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  18/ 30. LR: 0.0000. Data: 1.48s. Batch: 15.34s. S_Loss: 2.3031. T_Loss: 2.3046. Mask: 0.0000. :   2%|▏         | 18/1000 [04:36<40:05,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  19/ 30. LR: 0.0000. Data: 1.47s. Batch: 14.64s. S_Loss: 2.3031. T_Loss: 2.3029. Mask: 0.0000. :   2%|▏         | 19/1000 [04:38<38:47,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  20/ 30. LR: 0.0000. Data: 1.49s. Batch: 14.06s. S_Loss: 2.3030. T_Loss: 2.3028. Mask: 0.0000. :   2%|▏         | 20/1000 [04:41<41:28,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  21/ 30. LR: 0.0000. Data: 1.49s. Batch: 13.50s. S_Loss: 2.3029. T_Loss: 2.3011. Mask: 0.0000. :   2%|▏         | 21/1000 [04:43<40:29,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  22/ 30. LR: 0.0000. Data: 1.48s. Batch: 12.98s. S_Loss: 2.3029. T_Loss: 2.2993. Mask: 0.0000. :   2%|▏         | 22/1000 [04:45<38:52,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  23/ 30. LR: 0.0000. Data: 1.47s. Batch: 12.52s. S_Loss: 2.3029. T_Loss: 2.2987. Mask: 0.0000. :   2%|▏         | 23/1000 [04:48<37:58,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  24/ 30. LR: 0.0000. Data: 1.47s. Batch: 12.09s. S_Loss: 2.3028. T_Loss: 2.2988. Mask: 0.0000. :   2%|▏         | 24/1000 [04:50<37:17,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  25/ 30. LR: 0.0000. Data: 1.46s. Batch: 11.69s. S_Loss: 2.3028. T_Loss: 2.2985. Mask: 0.0000. :   2%|▎         | 25/1000 [04:52<37:03,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  26/ 30. LR: 0.0000. Data: 1.48s. Batch: 11.35s. S_Loss: 2.3027. T_Loss: 2.2991. Mask: 0.0000. :   3%|▎         | 26/1000 [04:55<40:16,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  27/ 30. LR: 0.0000. Data: 1.47s. Batch: 11.01s. S_Loss: 2.3028. T_Loss: 2.2993. Mask: 0.0000. :   3%|▎         | 27/1000 [04:57<38:48,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  28/ 30. LR: 0.0000. Data: 1.46s. Batch: 10.70s. S_Loss: 2.3027. T_Loss: 2.2985. Mask: 0.0000. :   3%|▎         | 28/1000 [04:59<37:48,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  29/ 30. LR: 0.0000. Data: 1.46s. Batch: 10.41s. S_Loss: 2.3028. T_Loss: 2.2973. Mask: 0.0000. :   3%|▎         | 29/1000 [05:02<36:59,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([448, 3, 32, 32]) torch.Size([448, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Iter:  30/ 30. LR: 0.0000. Data: 1.45s. Batch: 10.13s. S_Loss: 2.3029. T_Loss: 2.2960. Mask: 0.0000. :   3%|▎         | 30/1000 [05:04<36:30,  2.26s/it]"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2f892f67718e>\u001b[0m in \u001b[0;36m<cell line: 446>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0mteacher_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m train_loop(labeled_loader, unlabeled_loader, test_loader, finetune_dataset,\n\u001b[0m\u001b[1;32m    447\u001b[0m             \u001b[0mteacher_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_student_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             t_optimizer, s_optimizer, t_scheduler, s_scheduler, t_scaler, s_scaler)\n",
            "\u001b[0;32m<ipython-input-7-2f892f67718e>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(labeled_loader, unlabeled_loader, test_loader, finetune_dataset, teacher_model, student_model, avg_student_model, criterion, t_optimizer, s_optimizer, t_scheduler, s_scheduler, t_scaler, s_scaler)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'cuda:{gpu}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mmodel_load_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoint/model_best.pth.tar'"
          ]
        }
      ]
    }
  ]
}