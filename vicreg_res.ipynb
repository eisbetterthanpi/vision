{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/vicreg_res.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TZ4wM1O48nGS"
      },
      "outputs": [],
      "source": [
        "# https://arxiv.org/pdf/2105.04906.pdf\n",
        "# https://github.com/facebookresearch/vicreg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title augmentations\n",
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "\n",
        "from PIL import ImageOps, ImageFilter\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            sigma = np.random.rand() * 1.9 + 0.1\n",
        "            # return img.filter(ImageFilter.GaussianBlur(sigma))\n",
        "            return transforms.GaussianBlur(kernel_size=5, sigma=sigma)(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "class Solarization(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            return ImageOps.solarize(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                # transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                GaussianBlur(p=1.0),\n",
        "                Solarization(p=0.0),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                # transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                GaussianBlur(p=0.1),\n",
        "                Solarization(p=0.2),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        # print(\"sample.shape\",sample.shape)\n",
        "        # sample=torch.squeeze(sample)\n",
        "        # sample=transforms.ToPILImage()(sample)\n",
        "        # sample = torch.vmap(transforms.ToPILImage(),sample)\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        # x2 = transforms.ToTensor()(sample)\n",
        "        return x1, x2\n"
      ],
      "metadata": {
        "id": "hEUffQ24mkRY",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rG3xjMTtLmYN",
        "cellView": "form",
        "outputId": "e1ebab9a-383d-48d5-e97f-930ca91d1581",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# @title data\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor #, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "\n",
        "# train_data = datasets.FashionMNIST(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "# test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True,transform=ToTensor(),)\n",
        "\n",
        "# need rgb imgs?\n",
        "# train_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=transforms.Compose([TrainTransform(), ToTensor()]),)\n",
        "train_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=TrainTransform(),)\n",
        "# test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transforms.Compose([transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC), ToTensor()]),)\n",
        "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True,transform=ToTensor(),)\n",
        "\n",
        "\n",
        "batch_size = 64 #64\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "ctrain_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "ctrain_loader = DataLoader(ctrain_data, batch_size=batch_size)\n",
        "\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "x, labels = dataiter.next() # images, labels\n",
        "# print(labels)\n",
        "# print(y.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "import torchvision\n",
        "# imshow(torchvision.utils.make_grid(x))\n",
        "# imshow(torchvision.utils.make_grid(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title simplifi\n",
        "# https://github.com/JayPatwardhan/ResNet-PyTorch/blob/master/ResNet/ResNet.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Block(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False),\n",
        "            nn.BatchNorm2d(out_channels), nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "        self.i_downsample = i_downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        x = self.conv(x)\n",
        "        if self.i_downsample is not None:\n",
        "            identity = self.i_downsample(identity)\n",
        "        x += identity\n",
        "        x = nn.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(out_channels), nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
        "            nn.BatchNorm2d(out_channels), nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(out_channels*self.expansion),\n",
        "        )\n",
        "        self.i_downsample = i_downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        x = self.conv(x)\n",
        "        if self.i_downsample is not None: #downsample if needed\n",
        "            identity = self.i_downsample(identity)\n",
        "        x += identity #add identity\n",
        "        x = nn.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
        "        super(ResNet, self).__init__()\n",
        "        # https://github.com/akamaster/pytorch_resnet_cifar10/blob/master/resnet.py\n",
        "        # num_blocks=[3,3,3] aka layer_list\n",
        "        # plane_list=[64,128,256,512]\n",
        "        plane_list=[64,128,256]\n",
        "        # plane_list=[16,32,64]\n",
        "        self.in_channels = plane_list[0]\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, plane_list[0], kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(plane_list[0]), nn.ReLU(),\n",
        "            self._make_layer(ResBlock, layer_list[0], plane_list[0], stride=1),\n",
        "            self._make_layer(ResBlock, layer_list[1], plane_list[1], stride=2),\n",
        "            self._make_layer(ResBlock, layer_list[2], plane_list[2], stride=2),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "        )\n",
        "        # self.fc = nn.Linear(plane_list[2]*ResBlock.expansion, num_classes)\n",
        "        # self.cc = nn.Conv2d(plane_list[2]*ResBlock.expansion, num_classes, kernel_size=1, stride=1, padding=0)\n",
        "        self.cc = nn.Conv2d(plane_list[2]*ResBlock.expansion, 64, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        # print(\"forward x\",x.shape)\n",
        "        # x = x.reshape(x.shape[0], -1)\n",
        "        # x = self.fc(x)\n",
        "        x = self.cc(x)\n",
        "        x = torch.squeeze(x)\n",
        "        return x\n",
        "        \n",
        "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
        "        ii_downsample = None\n",
        "        layers = []\n",
        "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
        "            ii_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
        "            )\n",
        "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
        "        self.in_channels = planes*ResBlock.expansion\n",
        "        for i in range(blocks-1):\n",
        "            layers.append(ResBlock(self.in_channels, planes))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = ResNet(Bottleneck, [3,4,6,3], num_classes=10, num_channels=3).to(device)\n",
        "model = ResNet(Bottleneck, [3,3,3], num_classes=10, num_channels=3).to(device)\n",
        "# print(model)\n",
        "\n",
        "loss_list=[]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title vicreg\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def off_diagonal(x):\n",
        "    # print(\"off_diagonal\",x.shape)\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        dim_class=10\n",
        "        dim_exp=128\n",
        "        self.conv = ResNet(Bottleneck, [3,3,3], num_classes=10, num_channels=3)#.to(device)\n",
        "\n",
        "        f=[80,100,128]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(64, f[0]), nn.BatchNorm1d(f[0]), nn.ReLU(),\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[-1])\n",
        "            )\n",
        "        self.classifier = nn.Linear(64, dim_class)\n",
        "\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y)\n",
        "        \n",
        "        # x = torch.cat(FullGatherLayer.apply(x), dim=0)\n",
        "        # y = torch.cat(FullGatherLayer.apply(y), dim=0)\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        # print(x.var(dim=0),y.var(dim=0))\n",
        "        # print(std_x , std_y)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "        # std_loss=0.02\n",
        "        # print(torch.mean(F.relu(1 - std_x)) , torch.mean(F.relu(1 - std_y)))\n",
        "\n",
        "        # # covariance loss\n",
        "        # cov_x = (x.T @ x) / (self.args.batch_size - 1)\n",
        "        # cov_y = (y.T @ y) / (self.args.batch_size - 1)\n",
        "        # cov_loss = off_diagonal(cov_x).pow_(2).sum().div(self.num_features)\\\n",
        "        #  + off_diagonal(cov_y).pow_(2).sum().div(self.num_features)\n",
        "        # loss = (self.args.sim_coeff * repr_loss + self.args.std_coeff * std_loss + self.args.cov_coeff * cov_loss)\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=25.0 # λ / µ?\n",
        "        std_coeff=25.0\n",
        "        cov_coeff=1.0 # ν?\n",
        "\n",
        "        # print(\"x.dim()\",x.dim())\n",
        "        if x.dim() == 1:\n",
        "            x = x.view(-1, 1)\n",
        "        if y.dim() == 1:\n",
        "            y = y.view(-1, 1)\n",
        "        x=x.T\n",
        "        y=y.T\n",
        "        # print(\"x\",x.shape)\n",
        "        cov_x = (x.T @ x) / (batch_size - 1)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        # print(\"cov_x\",cov_x.shape)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features)\n",
        "        # print(\"in vicreg\",repr_loss , std_loss , cov_loss)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        return loss\n",
        "        \n",
        "    def loss(self, sx,sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "    def forward(self, x):\n",
        "        # # print(\"forward x\",x.shape)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "    def classify(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "# softmax = nn.Softmax(dim=1)\n",
        "# pred_probab = softmax(logits)\n",
        "model = NeuralNetwork().to(device) # create an instance and move it to device (cache?)\n",
        "# print(model)\n",
        "\n",
        "# LARGE BATCH TRAINING OF CONVOLUTIONAL NETWORKS\n",
        "# https://arxiv.org/pdf/1708.03888.pdf\n",
        "\n",
        "# Barlow Twins: Self-Supervised Learning via Redundancy Reduction\n",
        "# https://arxiv.org/pdf/2103.03230.pdf\n",
        "# https://github.com/facebookresearch/barlowtwins/blob/main/main.py\n",
        "\n",
        "# https://arxiv.org/search/?query=vicreg&searchtype=all\n",
        "\n",
        "loss_list=[]\n"
      ],
      "metadata": {
        "id": "RGYE1gWOMeuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f6bdcf-2e2e-4010-f5ba-64b512a0bd01"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = torch.rand(64, 3, 32, 32, device=device)\n",
        "logits = model(X)\n",
        "print(logits.shape)\n",
        "print(logits[0])\n",
        "# print(logits[0].argmax(1))\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "e6f8dWWjhNA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40803ab-78f7-4083-a1ca-6434a90d97e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 64])\n",
            "tensor([-2.3102, -2.1533, -4.1982, -1.1519, -0.0093,  1.3454, -0.0628, -1.6033,\n",
            "        -1.1835, -1.2622,  0.8428,  1.7901, -1.8901, -3.3317, -0.6312,  0.1207,\n",
            "         0.2479, -1.1840, -0.2588, -0.5976,  2.3028, -0.6578, -0.8441, -0.1051,\n",
            "        -0.3345, -0.6293,  0.7064, -2.7856,  2.2069, -2.4666, -1.2325,  1.2239,\n",
            "         2.3592, -0.0394,  1.3142,  0.4946,  1.6137,  1.7712,  0.3829,  1.0650,\n",
            "         4.0918,  1.2396, -1.6281, -1.6897,  0.6121, -1.5420,  0.7783,  2.8416,\n",
            "         5.3968,  1.6604,  0.7216,  1.0223,  3.7958,  0.4908,  0.7251,  1.1277,\n",
            "         0.5243,  1.0676, -2.4278, -2.8877, -0.1657,  1.1479, -0.7816,  0.3914],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "Predicted class: tensor([48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
            "        48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
            "        48, 48, 52, 48, 48, 48, 48, 52, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
            "        48, 48, 48, 48, 48, 48, 48, 48, 48, 48], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train test function\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# def strain(dataloader, model, loss_fn, optimizer):\n",
        "def strain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, ((x,y), labels) in enumerate(dataloader):\n",
        "    # for batch, (x, y) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        with torch.cuda.amp.autocast():\n",
        "            # pred = model(sx)\n",
        "            # loss = loss_fn(pred, sy)\n",
        "            loss = model.loss(sx,sy)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        if (batch) % (size//(10* len(x))) == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    # return lr_list, loss_list\n",
        "\n",
        "# def train(dataloader, model, loss_fn, optimizer):\n",
        "def train(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    # for batch, (x, y) in enumerate(dataloader):\n",
        "    for batch, ((x,y), labels) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        # print(\"sx sy\",sx.shape,sy.shape)\n",
        "        # pred = model(sx)\n",
        "        # loss = loss_fn(pred, sy)\n",
        "        loss = model.loss(sx,sy)\n",
        "        optimizer.zero_grad() # reset gradients of model parameters, to prevent double-counting\n",
        "        loss.backward() # Backpropagate gradients\n",
        "        optimizer.step() # adjust the parameters by the gradients\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        if (batch) % (size//(10* len(x))) == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            # loss_list.append(loss)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train_classifier(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "    # for batch, ((x,y), labels) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        sx = model(sx)\n",
        "        pred = model.classify(sx)\n",
        "        loss = loss_fn(pred, sy)\n",
        "        optimizer.zero_grad() # reset gradients of model parameters, to prevent double-counting\n",
        "        loss.backward() # Backpropagate gradients\n",
        "        optimizer.step() # adjust the parameters by the gradients\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            x, y = X.to(device), y.to(device)\n",
        "            sx = model(x)\n",
        "            pred = model.classify(sx)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ],
      "metadata": {
        "id": "fsealXK3OPQa",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = torch.optim.SGD(model.parameters(), lr = 1e-1, momentum=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8) # 0.75(20)-0.9(100)\n",
        "# # gamma^step\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-6)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 30)\n",
        "\n",
        "lr_list=[]\n",
        "for x in range(100):\n",
        "    scheduler.step()\n",
        "    lr=optimizer.param_groups[0][\"lr\"]\n",
        "    # print(lr)\n",
        "    lr_list.append(lr)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lr_list)\n",
        "plt.yscale('log')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I8tEMTjMxVu1",
        "outputId": "2c117ff6-c301-4a95-919a-61f51b007c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title wwwwwwwww\n",
        "import time\n",
        "start = time.time()\n",
        "lr_list=[]\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "batch_size = 512 # 4\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "ctrain_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "ctrain_loader = DataLoader(ctrain_data, batch_size=batch_size)\n",
        "\n",
        "base_lr ,max_lr = 1e-4, 1e-3\n",
        "epochs = 10 #5 40\n",
        "num_batches=int(np.ceil(len(train_data)/batch_size))\n",
        "epochs = 10 #5 20\n",
        "# (1e-5/1e-1)=gamma**(num_batches*epochs)\n",
        "# gamma = np.exp(np.log(1e-3/1e-1)/epochs) # for scheduler step every epoch\n",
        "gamma = np.exp(np.log(base_lr/max_lr)/(num_batches*epochs)) # for scheduler step every optimizer step\n",
        "# print(gamma)\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-6)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr = 1e-1, momentum=0.9)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
        "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, total_steps=num_iter, pct_start=0.45, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=25.0, final_div_factor=10000.0, three_phase=True,)\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, epochs=epochs, steps_per_epoch=num_batches, pct_start=0.45, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=25.0, final_div_factor=10000.0, three_phase=True,)\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # 0.75(20)-0.9(100)\n",
        "\n",
        "# coptimizer = torch.optim.SGD(model.classifier.parameters(), lr=1e-3)\n",
        "coptimizer = torch.optim.AdamW(model.classifier.parameters(), lr=1e-3)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    lr=optimizer.param_groups[0][\"lr\"]\n",
        "    lr_list.append(lr)\n",
        "    print(lr)\n",
        "    # train(train_loader, model, loss_fn, optimizer)\n",
        "    strain(train_loader, model, loss_fn, optimizer, scheduler)\n",
        "    # strain(train_loader, model, loss_fn, optimizer)\n",
        "    train_classifier(ctrain_loader, model, loss_fn, coptimizer)\n",
        "    test(test_loader, model, loss_fn)\n",
        "    # scheduler.step()\n",
        "print(\"Done!\")\n",
        "\n",
        "end = time.time()\n",
        "print(\"time: \",end - start)\n",
        "\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "# model = NeuralNetwork().to(device)\n",
        "# model.load_state_dict(torch.load(\"model.pth\"))\n"
      ],
      "metadata": {
        "id": "kDBEk-l-Oxjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c6944e-e0f8-48f3-fa63-baec098a722c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "3.9999999999999996e-05\n",
            "loss: 15.873966  [    0/50000]\n",
            "loss: 15.494720  [ 4608/50000]\n",
            "loss: 15.780310  [ 9216/50000]\n",
            "loss: 15.541817  [13824/50000]\n",
            "loss: 15.510596  [18432/50000]\n",
            "loss: 15.513143  [23040/50000]\n",
            "loss: 15.343438  [27648/50000]\n",
            "loss: 15.292038  [32256/50000]\n",
            "loss: 15.190303  [36864/50000]\n",
            "loss: 15.277014  [41472/50000]\n",
            "loss: 15.214978  [46080/50000]\n",
            "loss: 1.818323  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.9%, Avg loss: 1.770094 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "0.0001527886758400849\n",
            "loss: 15.120742  [    0/50000]\n",
            "loss: 15.357693  [ 4608/50000]\n",
            "loss: 15.043781  [ 9216/50000]\n",
            "loss: 15.265494  [13824/50000]\n",
            "loss: 15.054854  [18432/50000]\n",
            "loss: 15.109354  [23040/50000]\n",
            "loss: 14.908815  [27648/50000]\n",
            "loss: 14.874107  [32256/50000]\n",
            "loss: 14.989883  [36864/50000]\n",
            "loss: 14.702206  [41472/50000]\n",
            "loss: 14.960526  [46080/50000]\n",
            "loss: 1.799736  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.5%, Avg loss: 1.760407 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "0.0004381493475363405\n",
            "loss: 14.837034  [    0/50000]\n",
            "loss: 14.700195  [ 4608/50000]\n",
            "loss: 14.423498  [ 9216/50000]\n",
            "loss: 14.606773  [13824/50000]\n",
            "loss: 14.534367  [18432/50000]\n",
            "loss: 14.407127  [23040/50000]\n",
            "loss: 14.141977  [27648/50000]\n",
            "loss: 14.285234  [32256/50000]\n",
            "loss: 14.111931  [36864/50000]\n",
            "loss: 14.103118  [41472/50000]\n",
            "loss: 14.022552  [46080/50000]\n",
            "loss: 1.849934  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.9%, Avg loss: 1.720348 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "0.0007619759638493593\n",
            "loss: 13.992768  [    0/50000]\n",
            "loss: 13.968580  [ 4608/50000]\n",
            "loss: 13.963274  [ 9216/50000]\n",
            "loss: 13.682789  [13824/50000]\n",
            "loss: 13.621634  [18432/50000]\n",
            "loss: 13.531125  [23040/50000]\n",
            "loss: 13.721446  [27648/50000]\n",
            "loss: 13.415560  [32256/50000]\n",
            "loss: 13.242922  [36864/50000]\n",
            "loss: 13.387341  [41472/50000]\n",
            "loss: 13.367112  [46080/50000]\n",
            "loss: 1.721362  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.0%, Avg loss: 1.679199 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "0.0009720852945469718\n",
            "loss: 13.114017  [    0/50000]\n",
            "loss: 13.199735  [ 4608/50000]\n",
            "loss: 13.056944  [ 9216/50000]\n",
            "loss: 12.836432  [13824/50000]\n",
            "loss: 12.842365  [18432/50000]\n",
            "loss: 12.858410  [23040/50000]\n",
            "loss: 12.924796  [27648/50000]\n",
            "loss: 12.812799  [32256/50000]\n",
            "loss: 12.663516  [36864/50000]\n",
            "loss: 12.658867  [41472/50000]\n",
            "loss: 12.682877  [46080/50000]\n",
            "loss: 1.691980  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.654960 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "0.0009697358679998857\n",
            "loss: 12.598555  [    0/50000]\n",
            "loss: 12.541176  [ 4608/50000]\n",
            "loss: 12.323526  [ 9216/50000]\n",
            "loss: 12.279714  [13824/50000]\n",
            "loss: 12.283276  [18432/50000]\n",
            "loss: 12.315989  [23040/50000]\n",
            "loss: 12.393062  [27648/50000]\n",
            "loss: 12.126179  [32256/50000]\n",
            "loss: 12.062681  [36864/50000]\n",
            "loss: 12.173893  [41472/50000]\n",
            "loss: 12.012222  [46080/50000]\n",
            "loss: 1.763992  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 41.7%, Avg loss: 1.651447 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "0.0007560318038298899\n",
            "loss: 12.106073  [    0/50000]\n",
            "loss: 12.094757  [ 4608/50000]\n",
            "loss: 11.911121  [ 9216/50000]\n",
            "loss: 11.800700  [13824/50000]\n",
            "loss: 11.744749  [18432/50000]\n",
            "loss: 11.798503  [23040/50000]\n",
            "loss: 11.805490  [27648/50000]\n",
            "loss: 11.703100  [32256/50000]\n",
            "loss: 11.514086  [36864/50000]\n",
            "loss: 11.717239  [41472/50000]\n",
            "loss: 11.687139  [46080/50000]\n",
            "loss: 1.668998  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 41.6%, Avg loss: 1.648367 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "0.00043140392878439425\n",
            "loss: 11.674110  [    0/50000]\n",
            "loss: 11.691595  [ 4608/50000]\n",
            "loss: 11.559427  [ 9216/50000]\n",
            "loss: 11.528882  [13824/50000]\n",
            "loss: 11.430702  [18432/50000]\n",
            "loss: 11.566080  [23040/50000]\n",
            "loss: 11.401108  [27648/50000]\n",
            "loss: 11.381451  [32256/50000]\n",
            "loss: 11.252793  [36864/50000]\n",
            "loss: 11.385269  [41472/50000]\n",
            "loss: 11.252134  [46080/50000]\n",
            "loss: 1.661031  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 41.8%, Avg loss: 1.645106 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "0.0001484120268932404\n",
            "loss: 11.384333  [    0/50000]\n",
            "loss: 11.380683  [ 4608/50000]\n",
            "loss: 11.259239  [ 9216/50000]\n",
            "loss: 11.124963  [13824/50000]\n",
            "loss: 11.219765  [18432/50000]\n",
            "loss: 11.282702  [23040/50000]\n",
            "loss: 11.166729  [27648/50000]\n",
            "loss: 11.082772  [32256/50000]\n",
            "loss: 11.196918  [36864/50000]\n",
            "loss: 11.134240  [41472/50000]\n",
            "loss: 11.254255  [46080/50000]\n",
            "loss: 1.636659  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 42.1%, Avg loss: 1.640390 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "3.9959737556084744e-05\n",
            "loss: 11.021376  [    0/50000]\n",
            "loss: 11.400662  [ 4608/50000]\n",
            "loss: 11.081457  [ 9216/50000]\n",
            "loss: 11.012707  [13824/50000]\n",
            "loss: 11.067131  [18432/50000]\n",
            "loss: 11.138951  [23040/50000]\n",
            "loss: 11.045483  [27648/50000]\n",
            "loss: 11.061896  [32256/50000]\n",
            "loss: 11.006573  [36864/50000]\n",
            "loss: 10.982092  [41472/50000]\n",
            "loss: 11.138834  [46080/50000]\n",
            "loss: 1.634221  [    0/50000]\n",
            "Test Error: \n",
            " Accuracy: 42.1%, Avg loss: 1.638944 \n",
            "\n",
            "Done!\n",
            "time:  3245.776997089386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_list)\n",
        "# plt.yscale('log')\n",
        "plt.show()\n",
        "\n",
        "# plt.plot(lr_list)\n",
        "plt.show()\n",
        "\n",
        "# nooo"
      ],
      "metadata": {
        "id": "P2wbvqI8v2Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title save\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "PATH=\"/content/gdrive/MyDrive/torch_save/\" # for saving to google drive\n",
        "name='vicreg_res.pth'\n",
        "# PATH=\"/content/\" # for saving on colab only\n",
        "# name='model.pth'\n",
        "\n",
        "# torch.save(model.state_dict(), PATH+name)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(PATH+name))\n"
      ],
      "metadata": {
        "id": "wH6LkL0QnPTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dadf320-c7ff-454f-8dcc-73fd27bae6f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        n_class_correct = [0 for i in range(10)]\n",
        "        n_class_samples = [0 for i in range(10)]\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # outputs = model(images)\n",
        "            sx = model(images)\n",
        "            outputs = model.classify(sx)\n",
        "            # max returns (value ,index)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (predicted == labels).sum().item()\n",
        "            for i in range(batch_size):\n",
        "                print(len(labels))\n",
        "                label = labels[i]\n",
        "                pred = predicted[i]\n",
        "                if (label == pred):\n",
        "                    n_class_correct[label] += 1\n",
        "                n_class_samples[label] += 1\n",
        "        acc = 100.0 * n_correct / n_samples\n",
        "        print(f'Accuracy of the network: {acc} %')\n",
        "        for i in range(10):\n",
        "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "            print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "7S6mWmf_xom6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\",]\n",
        "model.eval()\n",
        "import random\n",
        "n=random.randint(0,1000)\n",
        "print(n)\n",
        "x, y = test_data[n]\n",
        "# print(x)\n",
        "with torch.no_grad():\n",
        "    # pred = model(x.to(device))\n",
        "    # print(pred)\n",
        "    # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "\n",
        "    # x, y = x.to(device), y.to(device)\n",
        "    x = x.to(device)\n",
        "    sx = model(x)\n",
        "    pred = model.classify(sx)\n",
        "    pred = torch.argmax(pred, dim=1).item()\n",
        "    print(pred)\n",
        "    print(y)\n",
        "    # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    # print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "\n"
      ],
      "metadata": {
        "id": "PoDyJMwUO4gX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}