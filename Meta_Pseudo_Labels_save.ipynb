{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/Meta_Pseudo_Labels_save.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9XrV9ZACgjm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Meta Pseudo Labels mar 2021 https://arxiv.org/pdf/2003.10580v4.pdf\n",
        "# https://github.com/kekmodel/MPL-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "combi = torch.combinations(torch.arange(0,6), with_replacement=False)\n",
        "# print(combi)\n",
        "\n",
        "rongs=[[[str(i)+str(j)] for i in range(6)] for j in range(6)]\n",
        "print(rongs)\n",
        "\n",
        "for i, j in combi:\n",
        "    print(i,j)\n",
        "    print(rongs[i][j])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bblybPU7-0Sn",
        "outputId": "e29b0123-e905-4b98-c033-39519ded03f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['00'], ['10'], ['20'], ['30'], ['40'], ['50']], [['01'], ['11'], ['21'], ['31'], ['41'], ['51']], [['02'], ['12'], ['22'], ['32'], ['42'], ['52']], [['03'], ['13'], ['23'], ['33'], ['43'], ['53']], [['04'], ['14'], ['24'], ['34'], ['44'], ['54']], [['05'], ['15'], ['25'], ['35'], ['45'], ['55']]]\n",
            "tensor(0) tensor(1)\n",
            "['10']\n",
            "tensor(0) tensor(2)\n",
            "['20']\n",
            "tensor(0) tensor(3)\n",
            "['30']\n",
            "tensor(0) tensor(4)\n",
            "['40']\n",
            "tensor(0) tensor(5)\n",
            "['50']\n",
            "tensor(1) tensor(2)\n",
            "['21']\n",
            "tensor(1) tensor(3)\n",
            "['31']\n",
            "tensor(1) tensor(4)\n",
            "['41']\n",
            "tensor(1) tensor(5)\n",
            "['51']\n",
            "tensor(2) tensor(3)\n",
            "['32']\n",
            "tensor(2) tensor(4)\n",
            "['42']\n",
            "tensor(2) tensor(5)\n",
            "['52']\n",
            "tensor(3) tensor(4)\n",
            "['43']\n",
            "tensor(3) tensor(5)\n",
            "['53']\n",
            "tensor(4) tensor(5)\n",
            "['54']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title torch augment\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        # self.transform = transforms.RandomApply([transforms.Compose([\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomResizedCrop((400,640), scale=(0.7, 1.0), ratio=(0.8, 1.25), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                transforms.RandomResizedCrop((32,32), scale=(0.7, 1.0), ratio=(0.8, 1.25), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(p=0.5), # 0.5\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,), # brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8\n",
        "                transforms.RandomGrayscale(p=0.2), # 0.2\n",
        "                # # transforms.RandomChoice(transforms.ColorJitter , transforms.RandomGrayscale(p=1.)\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # # transforms.RandomSolarize(threshold=130, p=0.5)\n",
        "                transforms.RandomErasing(p=1., scale=(0.1, 0.11), ratio=(1,1), value=(0.485, 0.456, 0.406)),\n",
        "                # transforms.ToTensor(), # ToTensored at dataset level, no need to ToTensor again\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalised at dataset level. default 0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225\n",
        "                ])\n",
        "            # ], p=1.)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        dims = len(sample.shape)\n",
        "        if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "        # x1 = self.transform(sample)\n",
        "        return x1\n",
        "\n",
        "trs=TrainTransform()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6iYyVffJcYB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title utils\n",
        "# https://github.com/kekmodel/MPL-pytorch/blob/main/utils.py\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "# def reduce_tensor(tensor, n):\n",
        "#     rt = tensor.clone()\n",
        "#     dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n",
        "#     rt /= n\n",
        "#     return rt\n",
        "\n",
        "\n",
        "def create_loss_fn():\n",
        "    label_smoothing = 0 # default 0 / mainargs 0.15\n",
        "\n",
        "    # if label_smoothing > 0:\n",
        "    #     criterion = SmoothCrossEntropyV2(alpha=label_smoothing)\n",
        "    # else:\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    return criterion.to(device)\n",
        "\n",
        "\n",
        "def module_load_state_dict(model, state_dict):\n",
        "    try:\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            name = k[7:]  # remove `module.`\n",
        "            new_state_dict[name] = v\n",
        "        model.load_state_dict(new_state_dict)\n",
        "    except:\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            name = f'module.{k}'  # add `module.`\n",
        "            new_state_dict[name] = v\n",
        "        model.load_state_dict(new_state_dict)\n",
        "\n",
        "def model_load_state_dict(model, state_dict):\n",
        "    try: model.load_state_dict(state_dict)\n",
        "    except: module_load_state_dict(model, state_dict)\n",
        "\n",
        "\n",
        "import shutil\n",
        "# './checkpoint/model_best.pth.tar\n",
        "# def save_checkpoint(state, is_best, finetune=False):\n",
        "def save_checkpoint(name,save_path , state, is_best, finetune=False):\n",
        "    save_path = './checkpoint'\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    if finetune:\n",
        "        name = f'{name}_finetune'\n",
        "    # else:\n",
        "    #     name = name\n",
        "    filename = f'{save_path}/{name}_last.pth.tar'\n",
        "    torch.save(state, filename, _use_new_zipfile_serialization=False)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, f'{save_path}/{name}_best.pth.tar')\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    output = output.to(torch.device('cpu'))\n",
        "    target = target.to(torch.device('cpu'))\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.shape[0]\n",
        "    _, idx = output.sort(dim=1, descending=True)\n",
        "    pred = idx.narrow(1, 0, maxk).t()\n",
        "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(dim=0, keepdim=True)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "class SmoothCrossEntropy(nn.Module):\n",
        "    def __init__(self, alpha=0.1):\n",
        "        super(SmoothCrossEntropy, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        if self.alpha == 0:\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "        else:\n",
        "            num_classes = logits.shape[-1]\n",
        "            alpha_div_k = self.alpha / num_classes\n",
        "            target_probs = F.one_hot(labels, num_classes=num_classes).float() * (1. - self.alpha) + alpha_div_k\n",
        "            loss = (-(target_probs * torch.log_softmax(logits, dim=-1)).sum(dim=-1)).mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class SmoothCrossEntropyV2(nn.Module):\n",
        "    \"\"\"NLL loss with label smoothing.\"\"\"\n",
        "    def __init__(self, label_smoothing=0.1):\n",
        "        super().__init__()\n",
        "        assert label_smoothing < 1.0\n",
        "        self.smoothing = label_smoothing\n",
        "        self.confidence = 1. - label_smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        if self.smoothing == 0:\n",
        "            loss = F.cross_entropy(x, target)\n",
        "        else:\n",
        "            logprobs = F.log_softmax(x, dim=-1)\n",
        "            nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "            nll_loss = nll_loss.squeeze(1)\n",
        "            smooth_loss = -logprobs.mean(dim=-1)\n",
        "            loss = (self.confidence * nll_loss + self.smoothing * smooth_loss).mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\n",
        "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "metadata": {
        "id": "q_bJYwwSDNNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ModelEMA\n",
        "# expopnential moving average, smoothen model parameters\n",
        "# https://github.com/kekmodel/MPL-pytorch/blob/main/models.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from copy import deepcopy\n",
        "\n",
        "class ModelEMA(nn.Module):\n",
        "    def __init__(self, model, decay=0.9999, device=None):\n",
        "        super().__init__()\n",
        "        self.module = deepcopy(model)\n",
        "        self.module.eval()\n",
        "        self.decay = decay\n",
        "        self.device = device\n",
        "        if self.device is not None:\n",
        "            self.module.to(device=device)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.module(input)\n",
        "\n",
        "    def _update(self, model, update_fn):\n",
        "        with torch.no_grad():\n",
        "            for ema_v, model_v in zip(self.module.parameters(), model.parameters()):\n",
        "                if self.device is not None:\n",
        "                    model_v = model_v.to(device=self.device)\n",
        "                ema_v.copy_(update_fn(ema_v, model_v))\n",
        "            for ema_v, model_v in zip(self.module.buffers(), model.buffers()):\n",
        "                if self.device is not None:\n",
        "                    model_v = model_v.to(device=self.device)\n",
        "                ema_v.copy_(model_v)\n",
        "\n",
        "    def update_parameters(self, model):\n",
        "        self._update(model, update_fn=lambda e, m: self.decay * e + (1. - self.decay) * m)\n",
        "\n",
        "    def state_dict(self):\n",
        "        return self.module.state_dict()\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.module.load_state_dict(state_dict)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4J3GeedWa6QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title main\n",
        "# https://github.com/kekmodel/MPL-pytorch/blob/main/main.py\n",
        "\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.cuda import amp\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# temperature = 1 # default 1 / mainargs 0.7\n",
        "ema = 0.995 # default 0 / mainargs 0.995\n",
        "# local_rank = -1\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def set_seed():\n",
        "    random.seed(0)\n",
        "    np.random.seed(0)\n",
        "    torch.manual_seed(0)\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, num_wait_steps=0, num_cycles=0.5, last_epoch=-1):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_wait_steps:\n",
        "            return 0.0\n",
        "        if current_step < num_warmup_steps + num_wait_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps + num_wait_steps))\n",
        "        progress = float(current_step - num_warmup_steps - num_wait_steps) / \\\n",
        "            float(max(1, num_training_steps - num_warmup_steps - num_wait_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
        "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    return optimizer.param_groups[0]['lr']\n",
        "\n",
        "\n",
        "def train_loop(labeled_loader, unlabeled_loader, test_loader, finetune_dataset,\n",
        "               teacher_model, student_model, avg_student_model, criterion,\n",
        "               t_optimizer, s_optimizer, t_scheduler, s_scheduler, t_scaler, s_scaler):\n",
        "    save_path = './checkpoint'\n",
        "    name = 'model'\n",
        "    best_top1 = 0\n",
        "\n",
        "    labeled_iter = iter(labeled_loader)\n",
        "    unlabeled_iter = iter(unlabeled_loader)\n",
        "\n",
        "    # for author's code formula\n",
        "    # moving_dot_product = torch.empty(1).to(device)\n",
        "    # limit = 3.0**(0.5)  # 3 = 6 / (f_in + f_out)\n",
        "    # nn.init.uniform_(moving_dot_product, -limit, limit)\n",
        "\n",
        "    eval_step = 10#1000\n",
        "    start_step=0\n",
        "    for step in range(start_step, total_steps):\n",
        "        if step % eval_step == 0:\n",
        "            batch_time = AverageMeter()\n",
        "            data_time = AverageMeter()\n",
        "            s_losses = AverageMeter()\n",
        "            t_losses = AverageMeter()\n",
        "            t_losses_l = AverageMeter()\n",
        "            t_losses_u = AverageMeter()\n",
        "            t_losses_mpl = AverageMeter()\n",
        "            mean_mask = AverageMeter()\n",
        "\n",
        "        teacher_model.train()\n",
        "        student_model.train()\n",
        "        end = time.time()\n",
        "\n",
        "        try:\n",
        "            images_l, targets = next(labeled_iter)\n",
        "        except:\n",
        "            labeled_iter = iter(labeled_loader)\n",
        "            images_l, targets = next(labeled_iter)\n",
        "\n",
        "        try:\n",
        "            # (images_uw, images_us), _ = next(unlabeled_iter)\n",
        "            images_uw, _ = next(unlabeled_iter)\n",
        "            images_us = trs(images_uw)\n",
        "        except:\n",
        "            unlabeled_iter = iter(unlabeled_loader)\n",
        "            # (images_uw, images_us), _ = next(unlabeled_iter)\n",
        "            images_uw, _ = next(unlabeled_iter)\n",
        "            images_us = trs(images_uw)\n",
        "\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        images_l = images_l.to(device)\n",
        "        images_uw = images_uw.to(device)\n",
        "        images_us = images_us.to(device)\n",
        "        targets = targets.to(device)\n",
        "        with amp.autocast():\n",
        "            batch_size = images_l.shape[0]\n",
        "            # print(images_l.shape, images_uw.shape, images_us.shape) # [64, 3, 32, 32]. [448, 3, 32, 32], [448, 3, 32, 32]\n",
        "            t_images = torch.cat((images_l, images_uw, images_us))\n",
        "            t_logits = teacher_model(t_images)\n",
        "            t_logits_l = t_logits[:batch_size]\n",
        "            t_logits_uw, t_logits_us = t_logits[batch_size:].chunk(2)\n",
        "            del t_logits\n",
        "\n",
        "            t_loss_l = criterion(t_logits_l, targets)\n",
        "\n",
        "            temperature = 1 # default 1 / mainargs 0.7\n",
        "            soft_pseudo_label = torch.softmax(t_logits_uw.detach() / temperature, dim=-1)\n",
        "            max_probs, hard_pseudo_label = torch.max(soft_pseudo_label, dim=-1)\n",
        "\n",
        "            threshold = 0.95 # default 0.95 / mainargs 0.6\n",
        "            mask = max_probs.ge(threshold).float()\n",
        "            t_loss_u = torch.mean(-(soft_pseudo_label * torch.log_softmax(t_logits_us, dim=-1)).sum(dim=-1) * mask)\n",
        "            lambda_u = 8 # default 1 / mainargs 8 coefficient of unlabeled loss\n",
        "            uda_steps = 10 # default 1 / mainargs 5000 warmup steps of lambda-u\n",
        "            weight_u = lambda_u * min(1., (step + 1) / uda_steps)\n",
        "            t_loss_uda = t_loss_l + weight_u * t_loss_u\n",
        "\n",
        "            s_images = torch.cat((images_l, images_us))\n",
        "            s_logits = student_model(s_images)\n",
        "            s_logits_l = s_logits[:batch_size]\n",
        "            s_logits_us = s_logits[batch_size:]\n",
        "            del s_logits\n",
        "\n",
        "            s_loss_l_old = F.cross_entropy(s_logits_l.detach(), targets)\n",
        "\n",
        "            # print(\"s_logits_us, hard_pseudo_label: \", s_logits_us.shape, hard_pseudo_label.shape) # [448, 10] [224]\n",
        "            s_loss = criterion(s_logits_us, hard_pseudo_label)\n",
        "\n",
        "        s_scaler.scale(s_loss).backward()\n",
        "\n",
        "        # if grad_clip > 0:\n",
        "        s_scaler.unscale_(s_optimizer)\n",
        "        nn.utils.clip_grad_norm_(student_model.parameters(), 1e9)\n",
        "\n",
        "        s_scaler.step(s_optimizer)\n",
        "        s_scaler.update()\n",
        "        s_scheduler.step()\n",
        "\n",
        "        if ema > 0: avg_student_model.update_parameters(student_model)\n",
        "\n",
        "        with amp.autocast():\n",
        "            with torch.no_grad():\n",
        "                s_logits_l = student_model(images_l)\n",
        "            s_loss_l_new = F.cross_entropy(s_logits_l.detach(), targets)\n",
        "\n",
        "            dot_product = s_loss_l_old - s_loss_l_new # theoretically correct formula (https://github.com/kekmodel/MPL-pytorch/issues/6)\n",
        "            # dot_product = s_loss_l_new - s_loss_l_old # author's code formula\n",
        "            # # moving_dot_product = moving_dot_product * 0.99 + dot_product * 0.01\n",
        "            # # dot_product = dot_product - moving_dot_product\n",
        "\n",
        "            _, hard_pseudo_label = torch.max(t_logits_us.detach(), dim=-1)\n",
        "            t_loss_mpl = dot_product * F.cross_entropy(t_logits_us, hard_pseudo_label)\n",
        "            # test\n",
        "            # t_loss_mpl = torch.tensor(0.).to(device)\n",
        "            t_loss = t_loss_uda + t_loss_mpl\n",
        "\n",
        "        t_scaler.scale(t_loss).backward()\n",
        "\n",
        "        # if grad_clip > 0:\n",
        "        t_scaler.unscale_(t_optimizer)\n",
        "        nn.utils.clip_grad_norm_(teacher_model.parameters(), 1e9)\n",
        "\n",
        "        t_scaler.step(t_optimizer)\n",
        "        t_scaler.update()\n",
        "        t_scheduler.step()\n",
        "\n",
        "        teacher_model.zero_grad()\n",
        "        student_model.zero_grad()\n",
        "\n",
        "        s_losses.update(s_loss.item())\n",
        "        t_losses.update(t_loss.item())\n",
        "        t_losses_l.update(t_loss_l.item())\n",
        "        t_losses_u.update(t_loss_u.item())\n",
        "        t_losses_mpl.update(t_loss_mpl.item())\n",
        "        mean_mask.update(mask.mean().item())\n",
        "\n",
        "        batch_time.update(time.time() - end)\n",
        "        # pbar.set_description(\n",
        "        #     f\"Train Iter: {step+1:3}/{total_steps:3}. \"\n",
        "        #     f\"LR: {get_lr(s_optimizer):.4f}. Data: {data_time.avg:.2f}s. \"\n",
        "        #     f\"Batch: {batch_time.avg:.2f}s. S_Loss: {s_losses.avg:.4f}. \"\n",
        "        #     f\"T_Loss: {t_losses.avg:.4f}. Mask: {mean_mask.avg:.4f}. \")\n",
        "        # pbar.update()\n",
        "\n",
        "        # args.num_eval = step // eval_step\n",
        "        if (step + 1) % eval_step == 0:\n",
        "            # print(s_losses.avg, t_losses.avg, t_losses_l.avg, t_losses_u.avg, t_losses_mpl.avg, mean_mask.avg)\n",
        "\n",
        "            test_model = avg_student_model if avg_student_model is not None else student_model\n",
        "            test_loss, top1, top5 = evaluate(test_loader, test_model, criterion)\n",
        "\n",
        "\n",
        "            is_best = top1 > best_top1\n",
        "            if is_best:\n",
        "                best_top1 = top1\n",
        "                best_top5 = top5\n",
        "\n",
        "            # './checkpoint/model_best.pth.tar\n",
        "            save_checkpoint(name,save_path,{\n",
        "                'step': step + 1,\n",
        "                'teacher_state_dict': teacher_model.state_dict(),\n",
        "                'student_state_dict': student_model.state_dict(),\n",
        "                'avg_state_dict': avg_student_model.state_dict() if avg_student_model is not None else None,\n",
        "                'best_top1': best_top1,\n",
        "                'best_top5': best_top5,\n",
        "                'teacher_optimizer': t_optimizer.state_dict(),\n",
        "                'student_optimizer': s_optimizer.state_dict(),\n",
        "                'teacher_scheduler': t_scheduler.state_dict(),\n",
        "                'student_scheduler': s_scheduler.state_dict(),\n",
        "                'teacher_scaler': t_scaler.state_dict(),\n",
        "                'student_scaler': s_scaler.state_dict(),\n",
        "            }, is_best)\n",
        "\n",
        "    # finetune\n",
        "    ckpt_name = f'{save_path}/{name}_best.pth.tar'\n",
        "    gpu=0\n",
        "    loc = f'cuda:{gpu}'\n",
        "    checkpoint = torch.load(ckpt_name, map_location=loc)\n",
        "    if checkpoint['avg_state_dict'] is not None:\n",
        "        model_load_state_dict(student_model, checkpoint['avg_state_dict'])\n",
        "    else:\n",
        "        model_load_state_dict(student_model, checkpoint['student_state_dict'])\n",
        "    finetune(finetune_dataset, test_loader, student_model, criterion)\n",
        "    return\n",
        "\n",
        "\n",
        "def evaluate(test_loader, model, criterion):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    model.eval()\n",
        "    test_iter = tqdm(test_loader, disable=False)\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for step, (images, targets) in enumerate(test_iter):\n",
        "            data_time.update(time.time() - end)\n",
        "            batch_size = images.shape[0]\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            with amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            acc1, acc5 = accuracy(outputs, targets, (1, 5))\n",
        "            losses.update(loss.item(), batch_size)\n",
        "            top1.update(acc1[0], batch_size)\n",
        "            top5.update(acc5[0], batch_size)\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "        test_iter.close()\n",
        "        return losses.avg, top1.avg, top5.avg\n",
        "\n",
        "\n",
        "def finetune(finetune_dataset, test_loader, model, criterion):\n",
        "    model.drop = nn.Identity()\n",
        "    train_sampler = RandomSampler\n",
        "    labeled_loader = DataLoader(finetune_dataset, batch_size=512, num_workers=4, pin_memory=True)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=3e-5, momentum=0.9, weight_decay=0, nesterov=True)\n",
        "    scaler = amp.GradScaler()\n",
        "    save_path = './checkpoint'\n",
        "    name = 'model'\n",
        "    best_top1 = 0\n",
        "    for epoch in range(1): #625\n",
        "\n",
        "        batch_time = AverageMeter()\n",
        "        data_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        model.train()\n",
        "        end = time.time()\n",
        "        labeled_iter = tqdm(labeled_loader, disable=False)\n",
        "        for step, (images, targets) in enumerate(labeled_iter):\n",
        "            data_time.update(time.time() - end)\n",
        "            batch_size = images.shape[0]\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            with amp.autocast():\n",
        "                model.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            losses.update(loss.item(), batch_size)\n",
        "            batch_time.update(time.time() - end)\n",
        "            labeled_iter.set_description(\n",
        "                f\"Finetune Epoch: {epoch+1:2}/{625:2}. Data: {data_time.avg:.2f}s. \"\n",
        "                f\"Batch: {batch_time.avg:.2f}s. Loss: {losses.avg:.4f}. \")\n",
        "        labeled_iter.close()\n",
        "\n",
        "        # print(losses.avg)\n",
        "        test_loss, top1, top5 = evaluate(test_loader, model, criterion)\n",
        "\n",
        "        is_best = top1 > best_top1\n",
        "        if is_best:\n",
        "            best_top1 = top1\n",
        "            best_top5 = top5\n",
        "\n",
        "        save_checkpoint(name,save_path,{\n",
        "            'step': step + 1,\n",
        "            'best_top1': best_top1,\n",
        "            'best_top5': best_top5,\n",
        "            'student_state_dict': model.state_dict(),\n",
        "            'avg_state_dict': None,\n",
        "            'student_optimizer': optimizer.state_dict(),\n",
        "        }, is_best, finetune=True)\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "# labeled_dataset, unlabeled_dataset, test_dataset, finetune_dataset = DATASET_GETTERS[dataset](args)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=transform)\n",
        "# test_data = datasets.CIFAR10(root=\"data\", train=False, download=True,transform=transform)\n",
        "labeled_dataset, unlabeled_dataset = torch.utils.data.random_split(train_data, [.1,.9])\n",
        "test_dataset = datasets.CIFAR10(root=\"data\", train=False, download=True,transform=transform)\n",
        "finetune_dataset = labeled_dataset\n",
        "\n",
        "\n",
        "batch_size = 64 # default 64/ mainargs128\n",
        "train_sampler = RandomSampler\n",
        "labeled_loader = DataLoader(labeled_dataset, sampler=train_sampler(labeled_dataset), batch_size=batch_size, num_workers=4, drop_last=True)\n",
        "unlabeled_loader = DataLoader(unlabeled_dataset, sampler=train_sampler(unlabeled_dataset), batch_size=batch_size * 7, num_workers=4, drop_last=True) # mu=7 ,coefficient of unlabeled batch size\n",
        "test_loader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size, num_workers=4)\n",
        "\n",
        "num_classes = 10\n",
        "# if dataset == \"cifar10\": depth, widen_factor = 28, 2\n",
        "# elif dataset == 'cifar100': depth, widen_factor = 28, 8\n",
        "# teacher_model = WideResNet(num_classes=num_classes, depth=depth, widen_factor=widen_factor, dropout=0, dense_dropout=0.2)\n",
        "# student_model = WideResNet(num_classes=num_classes, depth=depth, widen_factor=widen_factor, dropout=0, dense_dropout=0.2)\n",
        "\n",
        "\n",
        "from torchvision import models\n",
        "def get_resnet():\n",
        "    model = models.resnet152(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential( # og (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "        nn.Linear(num_ftrs, num_classes, bias=False),\n",
        "        nn.Softmax(dim=1),\n",
        "        )\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # model = model.to(device)\n",
        "    model = torch.compile(model.to(device))\n",
        "    return model\n",
        "\n",
        "teacher_model = get_resnet()\n",
        "student_model = get_resnet()\n",
        "\n",
        "\n",
        "# teacher_model.to(device)\n",
        "# student_model.to(device)\n",
        "avg_student_model = None\n",
        "if ema > 0: avg_student_model = ModelEMA(student_model, ema)\n",
        "\n",
        "\n",
        "criterion = create_loss_fn()\n",
        "\n",
        "no_decay = ['bn']\n",
        "weight_decay = 5e-4 # default 0 / mainargs 5e-4\n",
        "teacher_parameters = [{'params': [p for n, p in teacher_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in teacher_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "student_parameters = [{'params': [p for n, p in student_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in student_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "# lr default 0.01/ mainargs 0.05\n",
        "t_optimizer = optim.SGD(teacher_parameters, lr=0.05, momentum=0.9, nesterov=True)\n",
        "s_optimizer = optim.SGD(student_parameters, lr=0.05, momentum=0.9, nesterov=True)\n",
        "\n",
        "total_steps=30 # 300000\n",
        "warmup_steps = 100 # default 0 / mainargs 5000\n",
        "t_scheduler = get_cosine_schedule_with_warmup(t_optimizer, warmup_steps, total_steps)\n",
        "\n",
        "student_wait_steps = 100 # default 0 / mainargs 3000\n",
        "s_scheduler = get_cosine_schedule_with_warmup(s_optimizer, warmup_steps, total_steps, student_wait_steps)\n",
        "\n",
        "t_scaler = amp.GradScaler()\n",
        "s_scaler = amp.GradScaler()\n",
        "\n",
        "# # optionally resume from a checkpoint\n",
        "# if resume:\n",
        "#     if os.path.isfile(resume):\n",
        "#         logger.info(f\"=> loading checkpoint '{resume}'\")\n",
        "#         loc = f'cuda:{gpu}'\n",
        "#         checkpoint = torch.load(resume, map_location=loc)\n",
        "#         best_top1 = checkpoint['best_top1'].to(torch.device('cpu'))\n",
        "#         best_top5 = checkpoint['best_top5'].to(torch.device('cpu'))\n",
        "#         if not (evaluate or finetune):\n",
        "#             start_step = checkpoint['step']\n",
        "#             t_optimizer.load_state_dict(checkpoint['teacher_optimizer'])\n",
        "#             s_optimizer.load_state_dict(checkpoint['student_optimizer'])\n",
        "#             t_scheduler.load_state_dict(checkpoint['teacher_scheduler'])\n",
        "#             s_scheduler.load_state_dict(checkpoint['student_scheduler'])\n",
        "#             t_scaler.load_state_dict(checkpoint['teacher_scaler'])\n",
        "#             s_scaler.load_state_dict(checkpoint['student_scaler'])\n",
        "#             model_load_state_dict(teacher_model, checkpoint['teacher_state_dict'])\n",
        "#             if avg_student_model is not None:\n",
        "#                 model_load_state_dict(avg_student_model, checkpoint['avg_state_dict'])\n",
        "#         else:\n",
        "#             if checkpoint['avg_state_dict'] is not None:\n",
        "#                 model_load_state_dict(student_model, checkpoint['avg_state_dict'])\n",
        "#             else:\n",
        "#                 model_load_state_dict(student_model, checkpoint['student_state_dict'])\n",
        "\n",
        "    #     logger.info(f\"=> loaded checkpoint '{resume}' (step {checkpoint['step']})\")\n",
        "    # else:\n",
        "    #     logger.info(f\"=> no checkpoint found at '{resume}'\")\n",
        "\n",
        "\n",
        "# finetune(finetune_dataset, test_loader, student_model, criterion)\n",
        "# evaluate(test_loader, student_model, criterion)\n",
        "\n",
        "# best_top1 = 0\n",
        "\n",
        "teacher_model.zero_grad()\n",
        "student_model.zero_grad()\n",
        "train_loop(labeled_loader, unlabeled_loader, test_loader, finetune_dataset,\n",
        "            teacher_model, student_model, avg_student_model, criterion,\n",
        "            t_optimizer, s_optimizer, t_scheduler, s_scheduler, t_scaler, s_scaler)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LZVx1qyfCwGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbcbaa78-d951-4d29-8784-5aec32cd9a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 157/157 [01:06<00:00,  2.37it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.10it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 16.63it/s]\n",
            "Finetune Epoch:  1/625. Data: 3.96s. Batch: 11.62s. Loss: 2.3034. : 100%|██████████| 10/10 [01:17<00:00,  7.78s/it]\n",
            "  0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 157/157 [01:06<00:00,  2.37it/s]\n"
          ]
        }
      ]
    }
  ]
}