{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b270e69464a432496192e4462524e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b61705b2f73f4adf830982e2cc0afce3",
              "IPY_MODEL_64afb99b01a64f4bb7183b049866f4c3",
              "IPY_MODEL_68c4dc77096143cea7b8e42afea733ad"
            ],
            "layout": "IPY_MODEL_85a649313bc64aaab46e41c54cbd0dfd"
          }
        },
        "b61705b2f73f4adf830982e2cc0afce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1e6cc308e224b1b9b0461f03c6856bb",
            "placeholder": "​",
            "style": "IPY_MODEL_2ac6e4f2e5a84a4cb974c421dd79a0f5",
            "value": "100%"
          }
        },
        "64afb99b01a64f4bb7183b049866f4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db1e89798a54364955298c6879ed04b",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67f9b18eb6ce47aeb8a0632167aae7ae",
            "value": 170498071
          }
        },
        "68c4dc77096143cea7b8e42afea733ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee7e062af2184200a9f2a7eabda252fb",
            "placeholder": "​",
            "style": "IPY_MODEL_7f0852c4f97a48bc806d831ba32e15c9",
            "value": " 170498071/170498071 [00:14&lt;00:00, 15917605.02it/s]"
          }
        },
        "85a649313bc64aaab46e41c54cbd0dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e6cc308e224b1b9b0461f03c6856bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac6e4f2e5a84a4cb974c421dd79a0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9db1e89798a54364955298c6879ed04b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f9b18eb6ce47aeb8a0632167aae7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee7e062af2184200a9f2a7eabda252fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f0852c4f97a48bc806d831ba32e15c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/vicreg_tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ4wM1O48nGS"
      },
      "outputs": [],
      "source": [
        "# https://arxiv.org/pdf/2105.04906.pdf\n",
        "# https://github.com/facebookresearch/vicreg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title augmentations\n",
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "\n",
        "from PIL import ImageOps, ImageFilter\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            sigma = np.random.rand() * 1.9 + 0.1\n",
        "            # return img.filter(ImageFilter.GaussianBlur(sigma))\n",
        "            return transforms.GaussianBlur(kernel_size=5, sigma=sigma)(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "class Solarization(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            return ImageOps.solarize(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                # transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                GaussianBlur(p=1.0),\n",
        "                Solarization(p=0.0),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                # transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                GaussianBlur(p=0.1),\n",
        "                Solarization(p=0.2),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        # print(\"sample.shape\",sample.shape)\n",
        "        # sample=torch.squeeze(sample)\n",
        "        # sample=transforms.ToPILImage()(sample)\n",
        "        # sample = torch.vmap(transforms.ToPILImage(),sample)\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        # x2 = transforms.ToTensor()(sample)\n",
        "        return x1, x2\n"
      ],
      "metadata": {
        "id": "hEUffQ24mkRY",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rG3xjMTtLmYN",
        "cellView": "form",
        "outputId": "ac8bc5c4-06f6-4df9-d1bc-0cb381342cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "4b270e69464a432496192e4462524e8b",
            "b61705b2f73f4adf830982e2cc0afce3",
            "64afb99b01a64f4bb7183b049866f4c3",
            "68c4dc77096143cea7b8e42afea733ad",
            "85a649313bc64aaab46e41c54cbd0dfd",
            "f1e6cc308e224b1b9b0461f03c6856bb",
            "2ac6e4f2e5a84a4cb974c421dd79a0f5",
            "9db1e89798a54364955298c6879ed04b",
            "67f9b18eb6ce47aeb8a0632167aae7ae",
            "ee7e062af2184200a9f2a7eabda252fb",
            "7f0852c4f97a48bc806d831ba32e15c9"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b270e69464a432496192e4462524e8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# @title data\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor #, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "\n",
        "# training_data = datasets.FashionMNIST(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "# test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True,transform=ToTensor(),)\n",
        "\n",
        "# need rgb imgs?\n",
        "# training_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=transforms.Compose([TrainTransform(), ToTensor()]),)\n",
        "training_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=TrainTransform(),)\n",
        "# test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transforms.Compose([transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC), ToTensor()]),)\n",
        "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True,transform=ToTensor(),)\n",
        "\n",
        "\n",
        "batch_size = 64 #64\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "ctraining_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "ctrain_dataloader = DataLoader(ctraining_data, batch_size=batch_size)\n",
        "\n",
        "\n",
        "dataiter = iter(test_dataloader)\n",
        "x, labels = dataiter.next() # images, labels\n",
        "# print(labels)\n",
        "# print(y.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "import torchvision\n",
        "# imshow(torchvision.utils.make_grid(x))\n",
        "# imshow(torchvision.utils.make_grid(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title vicreg\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def off_diagonal(x):\n",
        "    # print(\"off_diagonal\",x.shape)\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # dim_out=10\n",
        "        dim_class=10\n",
        "        dim_exp=128\n",
        "        self.conv = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            # nn.Conv2d(3, 8, 3, 1, 1), nn.BatchNorm2d(8), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(8, 16, 5, 1, 2), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(16, 16, 7, 1, 3), nn.BatchNorm2d(16), nn.ReLU(), #nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), #nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 5, 1, 2), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 7, 1, 3), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(256 * 8 * 8, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "        )\n",
        "\n",
        "        f=[80,100,128]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(64, f[0]), nn.BatchNorm1d(f[0]), nn.ReLU(),\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[-1])\n",
        "            )\n",
        "        self.classifier = nn.Linear(64, dim_class)\n",
        "\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y)\n",
        "        \n",
        "        # x = torch.cat(FullGatherLayer.apply(x), dim=0)\n",
        "        # y = torch.cat(FullGatherLayer.apply(y), dim=0)\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        # print(x.var(dim=0),y.var(dim=0))\n",
        "        # print(std_x , std_y)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "        # std_loss=0.02\n",
        "        # print(torch.mean(F.relu(1 - std_x)) , torch.mean(F.relu(1 - std_y)))\n",
        "\n",
        "        # # covariance loss\n",
        "        # cov_x = (x.T @ x) / (self.args.batch_size - 1)\n",
        "        # cov_y = (y.T @ y) / (self.args.batch_size - 1)\n",
        "        # cov_loss = off_diagonal(cov_x).pow_(2).sum().div(self.num_features)\\\n",
        "        #  + off_diagonal(cov_y).pow_(2).sum().div(self.num_features)\n",
        "        # loss = (self.args.sim_coeff * repr_loss + self.args.std_coeff * std_loss + self.args.cov_coeff * cov_loss)\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=25.0 # λ / µ?\n",
        "        std_coeff=25.0\n",
        "        cov_coeff=1.0 # ν?\n",
        "\n",
        "        # print(\"x.dim()\",x.dim())\n",
        "        if x.dim() == 1:\n",
        "            x = x.view(-1, 1)\n",
        "        if y.dim() == 1:\n",
        "            y = y.view(-1, 1)\n",
        "        x=x.T\n",
        "        y=y.T\n",
        "        # print(\"x\",x.shape)\n",
        "        cov_x = (x.T @ x) / (batch_size - 1)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        # print(\"cov_x\",cov_x.shape)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features)\n",
        "        # print(\"in vicreg\",repr_loss , std_loss , cov_loss)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        return loss\n",
        "        \n",
        "    def loss(self, sx,sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        # print(\"forward x\",x.shape)\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "    def classify(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "# softmax = nn.Softmax(dim=1)\n",
        "# pred_probab = softmax(logits)\n",
        "model = NeuralNetwork().to(device) # create an instance and move it to device (cache?)\n",
        "# print(model)\n",
        "\n",
        "# LARGE BATCH TRAINING OF CONVOLUTIONAL NETWORKS\n",
        "# https://arxiv.org/pdf/1708.03888.pdf\n",
        "\n",
        "# Barlow Twins: Self-Supervised Learning via Redundancy Reduction\n",
        "# https://arxiv.org/pdf/2103.03230.pdf\n",
        "# https://github.com/facebookresearch/barlowtwins/blob/main/main.py\n",
        "\n",
        "# https://arxiv.org/search/?query=vicreg&searchtype=all\n",
        "\n",
        "loss_list=[]\n"
      ],
      "metadata": {
        "id": "RGYE1gWOMeuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea71889-51e3-495c-9c76-211096320bbc",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = torch.rand(64, 3, 32, 32, device=device)\n",
        "logits = model(X)\n",
        "print(logits.shape)\n",
        "print(logits[0])\n",
        "# print(logits[0].argmax(1))\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "e6f8dWWjhNA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b191108-47cc-4715-8ddb-3c7d63387a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward x torch.Size([64, 256, 8, 8])\n",
            "torch.Size([64, 64])\n",
            "tensor([ 0.0572, -0.0649, -0.1722, -0.2338,  0.1145,  0.1187,  0.0763,  0.0216,\n",
            "        -0.0654,  0.1771, -0.0271, -0.2069, -0.1035,  0.2459,  0.2247, -0.0541,\n",
            "        -0.0312,  0.0158, -0.3151, -0.0317, -0.0440, -0.1179, -0.0012, -0.1164,\n",
            "        -0.0386, -0.0592, -0.1001,  0.0885,  0.1681, -0.0692, -0.3456,  0.0081,\n",
            "         0.1034,  0.1631, -0.1176,  0.0624,  0.0389, -0.0354, -0.0676,  0.1597,\n",
            "         0.0184,  0.2048, -0.1722,  0.0567,  0.0818,  0.0456, -0.2405, -0.2981,\n",
            "        -0.1709,  0.0708, -0.0306,  0.0887, -0.1182,  0.1387, -0.1528, -0.0787,\n",
            "         0.1444, -0.0729, -0.0276, -0.0507, -0.2167, -0.0387, -0.1427,  0.0666],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "Predicted class: tensor([13, 49, 14, 41, 14, 41, 53, 14, 49,  0, 14, 49, 41, 41, 14, 14, 14, 14,\n",
            "        41, 49, 49, 49, 41, 14, 33, 41, 41, 14, 13, 41, 41, 14, 28, 14, 41, 14,\n",
            "        13, 33, 33, 41, 33, 14, 33,  0,  0, 14, 49, 33, 14, 41, 41, 41, 14, 14,\n",
            "        27, 41, 14, 41,  0, 41, 14, 14, 41, 41], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train test function\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    # for batch, (x, y) in enumerate(dataloader):\n",
        "    for batch, ((x,y), labels) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        # print(\"sx sy\",sx.shape,sy.shape)\n",
        "        # pred = model(sx)\n",
        "        # loss = loss_fn(pred, sy)\n",
        "        loss = model.loss(sx,sy)\n",
        "        optimizer.zero_grad() # reset gradients of model parameters, to prevent double-counting\n",
        "        loss.backward() # Backpropagate gradients\n",
        "        optimizer.step() # adjust the parameters by the gradients\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def train_classifier(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "    # for batch, ((x,y), labels) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        sx = model(sx)\n",
        "        pred = model.classify(sx)\n",
        "        loss = loss_fn(pred, sy)\n",
        "        optimizer.zero_grad() # reset gradients of model parameters, to prevent double-counting\n",
        "        loss.backward() # Backpropagate gradients\n",
        "        optimizer.step() # adjust the parameters by the gradients\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            x, y = X.to(device), y.to(device)\n",
        "            sx = model(x)\n",
        "            pred = model.classify(sx)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ],
      "metadata": {
        "id": "fsealXK3OPQa",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = torch.optim.SGD(model.parameters(), lr = 1e-1, momentum=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8) # 0.75(20)-0.9(100)\n",
        "# # gamma^step\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-6)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 30)\n",
        "\n",
        "lr_list=[]\n",
        "for x in range(100):\n",
        "    scheduler.step()\n",
        "    lr=optimizer.param_groups[0][\"lr\"]\n",
        "    # print(lr)\n",
        "    lr_list.append(lr)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lr_list)\n",
        "plt.yscale('log')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I8tEMTjMxVu1",
        "outputId": "08894fa0-4809-4dd3-c602-b4adcc58748c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  0.1020,  0.0527,  0.0185,  0.0295, -0.0470, -0.0641,  0.0206, -0.1019\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7) # 0.75(20)-0.9(100)\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-6)\n",
        "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
        "\n",
        "coptimizer = torch.optim.SGD(model.classifier.parameters(), lr=1e-3)\n",
        "lr_list=[]\n",
        "\n",
        "epochs = 10 #5 40\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    lr=optimizer.param_groups[0][\"lr\"]\n",
        "    lr_list.append(lr)\n",
        "    # print(lr)\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    train_classifier(ctrain_dataloader, model, loss_fn, coptimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "    scheduler.step()\n",
        "print(\"Done!\")\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "# model = NeuralNetwork().to(device)\n",
        "# model.load_state_dict(torch.load(\"model.pth\"))\n"
      ],
      "metadata": {
        "id": "kDBEk-l-Oxjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de17b4df-deaa-47de-a12a-4abe18f48e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 13.043016  [    0/50000]\n",
            "loss: 12.302605  [ 6400/50000]\n",
            "loss: 15.480703  [12800/50000]\n",
            "loss: 14.747604  [19200/50000]\n",
            "loss: 15.016106  [25600/50000]\n",
            "loss: 14.490833  [32000/50000]\n",
            "loss: 13.559613  [38400/50000]\n",
            "loss: 13.266211  [44800/50000]\n",
            "loss: 2.229071  [    0/50000]\n",
            "loss: 2.217223  [ 6400/50000]\n",
            "loss: 2.188015  [12800/50000]\n",
            "loss: 2.260777  [19200/50000]\n",
            "loss: 2.246653  [25600/50000]\n",
            "loss: 2.241529  [32000/50000]\n",
            "loss: 2.228412  [38400/50000]\n",
            "loss: 2.202658  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 21.7%, Avg loss: 2.229793 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 15.018920  [    0/50000]\n",
            "loss: 15.993645  [ 6400/50000]\n",
            "loss: 14.504047  [12800/50000]\n",
            "loss: 13.416109  [19200/50000]\n",
            "loss: 14.144498  [25600/50000]\n",
            "loss: 15.445381  [32000/50000]\n",
            "loss: 16.451962  [38400/50000]\n",
            "loss: 12.380365  [44800/50000]\n",
            "loss: 2.224599  [    0/50000]\n",
            "loss: 2.222846  [ 6400/50000]\n",
            "loss: 2.187388  [12800/50000]\n",
            "loss: 2.262511  [19200/50000]\n",
            "loss: 2.230584  [25600/50000]\n",
            "loss: 2.233196  [32000/50000]\n",
            "loss: 2.219213  [38400/50000]\n",
            "loss: 2.197441  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 21.5%, Avg loss: 2.225257 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 13.804581  [    0/50000]\n",
            "loss: 14.580417  [ 6400/50000]\n",
            "loss: 13.785217  [12800/50000]\n",
            "loss: 12.941315  [19200/50000]\n",
            "loss: 14.738903  [25600/50000]\n",
            "loss: 14.114182  [32000/50000]\n",
            "loss: 13.714507  [38400/50000]\n",
            "loss: 11.539676  [44800/50000]\n",
            "loss: 2.238175  [    0/50000]\n",
            "loss: 2.210559  [ 6400/50000]\n",
            "loss: 2.162517  [12800/50000]\n",
            "loss: 2.240217  [19200/50000]\n",
            "loss: 2.226769  [25600/50000]\n",
            "loss: 2.218073  [32000/50000]\n",
            "loss: 2.205549  [38400/50000]\n",
            "loss: 2.193398  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 23.7%, Avg loss: 2.214183 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 14.888677  [    0/50000]\n",
            "loss: 13.580329  [ 6400/50000]\n",
            "loss: 14.049342  [12800/50000]\n",
            "loss: 13.030638  [19200/50000]\n",
            "loss: 14.798996  [25600/50000]\n",
            "loss: 13.775658  [32000/50000]\n",
            "loss: 13.729812  [38400/50000]\n",
            "loss: 13.841660  [44800/50000]\n",
            "loss: 2.246049  [    0/50000]\n",
            "loss: 2.220869  [ 6400/50000]\n",
            "loss: 2.178367  [12800/50000]\n",
            "loss: 2.243510  [19200/50000]\n",
            "loss: 2.236002  [25600/50000]\n",
            "loss: 2.227017  [32000/50000]\n",
            "loss: 2.207036  [38400/50000]\n",
            "loss: 2.206376  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 23.9%, Avg loss: 2.220673 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 13.442152  [    0/50000]\n",
            "loss: 13.235713  [ 6400/50000]\n",
            "loss: 13.644487  [12800/50000]\n",
            "loss: 16.266863  [19200/50000]\n",
            "loss: 13.723909  [25600/50000]\n",
            "loss: 13.319675  [32000/50000]\n",
            "loss: 12.740163  [38400/50000]\n",
            "loss: 12.299337  [44800/50000]\n",
            "loss: 2.243531  [    0/50000]\n",
            "loss: 2.216240  [ 6400/50000]\n",
            "loss: 2.175696  [12800/50000]\n",
            "loss: 2.242464  [19200/50000]\n",
            "loss: 2.231075  [25600/50000]\n",
            "loss: 2.224873  [32000/50000]\n",
            "loss: 2.213305  [38400/50000]\n",
            "loss: 2.197722  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.0%, Avg loss: 2.219379 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 13.863812  [    0/50000]\n",
            "loss: 11.643306  [ 6400/50000]\n",
            "loss: 13.632338  [12800/50000]\n",
            "loss: 13.192205  [19200/50000]\n",
            "loss: 14.412369  [25600/50000]\n",
            "loss: 13.166018  [32000/50000]\n",
            "loss: 16.878792  [38400/50000]\n",
            "loss: 11.560781  [44800/50000]\n",
            "loss: 2.241394  [    0/50000]\n",
            "loss: 2.217469  [ 6400/50000]\n",
            "loss: 2.170982  [12800/50000]\n",
            "loss: 2.242885  [19200/50000]\n",
            "loss: 2.230399  [25600/50000]\n",
            "loss: 2.226150  [32000/50000]\n",
            "loss: 2.209721  [38400/50000]\n",
            "loss: 2.202199  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 25.0%, Avg loss: 2.218254 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 12.078138  [    0/50000]\n",
            "loss: 12.630894  [ 6400/50000]\n",
            "loss: 15.638628  [12800/50000]\n",
            "loss: 13.503989  [19200/50000]\n",
            "loss: 13.846626  [25600/50000]\n",
            "loss: 12.947969  [32000/50000]\n",
            "loss: 12.757861  [38400/50000]\n",
            "loss: 11.548713  [44800/50000]\n",
            "loss: 2.242488  [    0/50000]\n",
            "loss: 2.216307  [ 6400/50000]\n",
            "loss: 2.173928  [12800/50000]\n",
            "loss: 2.240937  [19200/50000]\n",
            "loss: 2.233757  [25600/50000]\n",
            "loss: 2.226979  [32000/50000]\n",
            "loss: 2.206949  [38400/50000]\n",
            "loss: 2.199691  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.2%, Avg loss: 2.218799 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 13.157888  [    0/50000]\n",
            "loss: 12.201242  [ 6400/50000]\n",
            "loss: 13.970703  [12800/50000]\n",
            "loss: 12.281435  [19200/50000]\n",
            "loss: 14.290707  [25600/50000]\n",
            "loss: 12.394731  [32000/50000]\n",
            "loss: 13.360939  [38400/50000]\n",
            "loss: 12.275893  [44800/50000]\n",
            "loss: 2.241531  [    0/50000]\n",
            "loss: 2.214892  [ 6400/50000]\n",
            "loss: 2.170426  [12800/50000]\n",
            "loss: 2.240134  [19200/50000]\n",
            "loss: 2.231423  [25600/50000]\n",
            "loss: 2.223619  [32000/50000]\n",
            "loss: 2.205685  [38400/50000]\n",
            "loss: 2.196557  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.4%, Avg loss: 2.217489 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 13.128487  [    0/50000]\n",
            "loss: 11.112196  [ 6400/50000]\n",
            "loss: 13.280273  [12800/50000]\n",
            "loss: 13.589889  [19200/50000]\n",
            "loss: 15.801453  [25600/50000]\n",
            "loss: 13.675314  [32000/50000]\n",
            "loss: 12.972927  [38400/50000]\n",
            "loss: 14.974581  [44800/50000]\n",
            "loss: 2.242099  [    0/50000]\n",
            "loss: 2.216443  [ 6400/50000]\n",
            "loss: 2.173560  [12800/50000]\n",
            "loss: 2.242972  [19200/50000]\n",
            "loss: 2.232169  [25600/50000]\n",
            "loss: 2.225493  [32000/50000]\n",
            "loss: 2.206910  [38400/50000]\n",
            "loss: 2.196711  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.4%, Avg loss: 2.218222 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 13.646474  [    0/50000]\n",
            "loss: 13.497561  [ 6400/50000]\n",
            "loss: 12.532915  [12800/50000]\n",
            "loss: 15.203319  [19200/50000]\n",
            "loss: 14.953829  [25600/50000]\n",
            "loss: 12.728375  [32000/50000]\n",
            "loss: 15.400953  [38400/50000]\n",
            "loss: 12.647416  [44800/50000]\n",
            "loss: 2.241115  [    0/50000]\n",
            "loss: 2.213361  [ 6400/50000]\n",
            "loss: 2.172311  [12800/50000]\n",
            "loss: 2.239991  [19200/50000]\n",
            "loss: 2.229300  [25600/50000]\n",
            "loss: 2.222746  [32000/50000]\n",
            "loss: 2.203060  [38400/50000]\n",
            "loss: 2.193208  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 24.7%, Avg loss: 2.215686 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_list)\n",
        "# plt.yscale('log')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(lr_list)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P2wbvqI8v2Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title save\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "PATH=\"/content/gdrive/MyDrive/torch_save/\" # for saving to google drive\n",
        "name='vicreg_tut.pth'\n",
        "# PATH=\"/content/\" # for saving on colab only\n",
        "# name='model.pth'\n",
        "\n",
        "torch.save(model.state_dict(), PATH+name)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(PATH+name))\n"
      ],
      "metadata": {
        "id": "wH6LkL0QnPTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3a0b68-4b3e-4712-cb5c-81c55e643f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        n_class_correct = [0 for i in range(10)]\n",
        "        n_class_samples = [0 for i in range(10)]\n",
        "        for images, labels in test_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # outputs = model(images)\n",
        "            sx = model(images)\n",
        "            outputs = model.classify(sx)\n",
        "            # max returns (value ,index)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (predicted == labels).sum().item()\n",
        "            for i in range(batch_size):\n",
        "                print(len(labels))\n",
        "                label = labels[i]\n",
        "                pred = predicted[i]\n",
        "                if (label == pred):\n",
        "                    n_class_correct[label] += 1\n",
        "                n_class_samples[label] += 1\n",
        "        acc = 100.0 * n_correct / n_samples\n",
        "        print(f'Accuracy of the network: {acc} %')\n",
        "        for i in range(10):\n",
        "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "            print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "7S6mWmf_xom6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\",]\n",
        "model.eval()\n",
        "import random\n",
        "n=random.randint(0,1000)\n",
        "print(n)\n",
        "x, y = test_data[n]\n",
        "# print(x)\n",
        "with torch.no_grad():\n",
        "    # pred = model(x.to(device))\n",
        "    # print(pred)\n",
        "    # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "\n",
        "    # x, y = x.to(device), y.to(device)\n",
        "    x = x.to(device)\n",
        "    sx = model(x)\n",
        "    pred = model.classify(sx)\n",
        "    pred = torch.argmax(pred, dim=1).item()\n",
        "    print(pred)\n",
        "    print(y)\n",
        "    # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    # print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "\n"
      ],
      "metadata": {
        "id": "PoDyJMwUO4gX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}