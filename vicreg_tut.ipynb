{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIQVUY34xZ0+nrtIXKCZUH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eaa26fb826a746daa5d5671d3615f36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab65de3ad30848988734a4ba7292e88a",
              "IPY_MODEL_a98c521b69554774a4de2ec43443be90",
              "IPY_MODEL_7a96688d980745179971db6a40f0325a"
            ],
            "layout": "IPY_MODEL_33e3bfd51fe14264a25968c7938c1fa7"
          }
        },
        "ab65de3ad30848988734a4ba7292e88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56e9bbe71ba54a079bb113befecd396a",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e56d0857c84e429f1811219eb36259",
            "value": "100%"
          }
        },
        "a98c521b69554774a4de2ec43443be90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd19b3f8c4694546bf936b9679fcdec4",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5270a7e978d143c68bb71e4a887cf09d",
            "value": 170498071
          }
        },
        "7a96688d980745179971db6a40f0325a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea56192a0654b6abc9bae2c7b735762",
            "placeholder": "​",
            "style": "IPY_MODEL_16bb547ee1ea42c2b05ded6f65cb09a3",
            "value": " 170498071/170498071 [00:02&lt;00:00, 74300379.80it/s]"
          }
        },
        "33e3bfd51fe14264a25968c7938c1fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56e9bbe71ba54a079bb113befecd396a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e56d0857c84e429f1811219eb36259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd19b3f8c4694546bf936b9679fcdec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5270a7e978d143c68bb71e4a887cf09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ea56192a0654b6abc9bae2c7b735762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16bb547ee1ea42c2b05ded6f65cb09a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/vicreg_tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ4wM1O48nGS"
      },
      "outputs": [],
      "source": [
        "# https://arxiv.org/pdf/2105.04906.pdf\n",
        "# https://github.com/facebookresearch/vicreg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title augmentations\n",
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "\n",
        "from PIL import ImageOps, ImageFilter\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            sigma = np.random.rand() * 1.9 + 0.1\n",
        "            # return img.filter(ImageFilter.GaussianBlur(sigma))\n",
        "            return transforms.GaussianBlur(kernel_size=5, sigma=sigma)(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "class Solarization(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            return ImageOps.solarize(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                # transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                GaussianBlur(p=1.0),\n",
        "                Solarization(p=0.0),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                # transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                GaussianBlur(p=0.1),\n",
        "                Solarization(p=0.2),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        # print(\"sample.shape\",sample.shape)\n",
        "        # sample=torch.squeeze(sample)\n",
        "        # sample=transforms.ToPILImage()(sample)\n",
        "        # sample = torch.vmap(transforms.ToPILImage(),sample)\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        # x2 = transforms.ToTensor()(sample)\n",
        "        return x1, x2\n"
      ],
      "metadata": {
        "id": "hEUffQ24mkRY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG3xjMTtLmYN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "eaa26fb826a746daa5d5671d3615f36e",
            "ab65de3ad30848988734a4ba7292e88a",
            "a98c521b69554774a4de2ec43443be90",
            "7a96688d980745179971db6a40f0325a",
            "33e3bfd51fe14264a25968c7938c1fa7",
            "56e9bbe71ba54a079bb113befecd396a",
            "a2e56d0857c84e429f1811219eb36259",
            "cd19b3f8c4694546bf936b9679fcdec4",
            "5270a7e978d143c68bb71e4a887cf09d",
            "7ea56192a0654b6abc9bae2c7b735762",
            "16bb547ee1ea42c2b05ded6f65cb09a3"
          ]
        },
        "outputId": "9b5dd6cd-d9b3-4320-9465-b35f3aa9419e",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eaa26fb826a746daa5d5671d3615f36e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# @title data\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor #, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "\n",
        "# training_data = datasets.FashionMNIST(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "# test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True,transform=ToTensor(),)\n",
        "\n",
        "# need rgb imgs?\n",
        "# training_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=transforms.Compose([TrainTransform(), ToTensor()]),)\n",
        "training_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=TrainTransform(),)\n",
        "# test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transforms.Compose([transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC), ToTensor()]),)\n",
        "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True,transform=ToTensor(),)\n",
        "\n",
        "\n",
        "batch_size = 256 #64\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "ctraining_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "ctrain_dataloader = DataLoader(ctraining_data, batch_size=batch_size)\n",
        "\n",
        "\n",
        "dataiter = iter(test_dataloader)\n",
        "x, labels = dataiter.next() # images, labels\n",
        "# print(labels)\n",
        "# print(y.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "import torchvision\n",
        "# imshow(torchvision.utils.make_grid(x))\n",
        "# imshow(torchvision.utils.make_grid(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title vicreg\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def off_diagonal(x):\n",
        "    # print(\"off_diagonal\",x.shape)\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # dim_out=10\n",
        "        dim_class=10\n",
        "        dim_exp=128\n",
        "        self.conv = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            # nn.Conv2d(3, 8, 3, 1, 1), nn.BatchNorm2d(8), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(8, 16, 5, 1, 2), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(16, 16, 7, 1, 3), nn.BatchNorm2d(16), nn.ReLU(), #nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), #nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 5, 1, 2), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 7, 1, 3), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(256 * 8 * 8, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "        )\n",
        "\n",
        "        f=[80,100,128]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(64, f[0]), nn.BatchNorm1d(f[0]), nn.ReLU(),\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[-1])\n",
        "            )\n",
        "        self.classifier = nn.Linear(64, dim_class)\n",
        "\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y)\n",
        "        \n",
        "        # x = torch.cat(FullGatherLayer.apply(x), dim=0)\n",
        "        # y = torch.cat(FullGatherLayer.apply(y), dim=0)\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        # print(x.var(dim=0),y.var(dim=0))\n",
        "        # print(std_x , std_y)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "        # std_loss=0.02\n",
        "        # print(torch.mean(F.relu(1 - std_x)) , torch.mean(F.relu(1 - std_y)))\n",
        "\n",
        "        # # covariance loss\n",
        "        # cov_x = (x.T @ x) / (self.args.batch_size - 1)\n",
        "        # cov_y = (y.T @ y) / (self.args.batch_size - 1)\n",
        "        # cov_loss = off_diagonal(cov_x).pow_(2).sum().div(self.num_features)\\\n",
        "        #  + off_diagonal(cov_y).pow_(2).sum().div(self.num_features)\n",
        "        # loss = (self.args.sim_coeff * repr_loss + self.args.std_coeff * std_loss + self.args.cov_coeff * cov_loss)\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=25.0 # λ / µ?\n",
        "        std_coeff=25.0\n",
        "        cov_coeff=1.0 # ν?\n",
        "\n",
        "        # print(\"x.dim()\",x.dim())\n",
        "        if x.dim() == 1:\n",
        "            x = x.view(-1, 1)\n",
        "        if y.dim() == 1:\n",
        "            y = y.view(-1, 1)\n",
        "        x=x.T\n",
        "        y=y.T\n",
        "        # print(\"x\",x.shape)\n",
        "        cov_x = (x.T @ x) / (batch_size - 1)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        # print(\"cov_x\",cov_x.shape)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features)\n",
        "        # print(\"in vicreg\",repr_loss , std_loss , cov_loss)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        return loss\n",
        "        \n",
        "    def loss(self, sx,sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        print(\"forward x\",x.shape)\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "    def classify(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "# softmax = nn.Softmax(dim=1)\n",
        "# pred_probab = softmax(logits)\n",
        "model = NeuralNetwork().to(device) # create an instance and move it to device (cache?)\n",
        "# print(model)\n",
        "\n",
        "# LARGE BATCH TRAINING OF CONVOLUTIONAL NETWORKS\n",
        "# https://arxiv.org/pdf/1708.03888.pdf\n",
        "\n",
        "# Barlow Twins: Self-Supervised Learning via Redundancy Reduction\n",
        "# https://arxiv.org/pdf/2103.03230.pdf\n",
        "# https://github.com/facebookresearch/barlowtwins/blob/main/main.py\n",
        "\n",
        "# https://arxiv.org/search/?query=vicreg&searchtype=all\n",
        "\n",
        "loss_list=[]\n"
      ],
      "metadata": {
        "id": "RGYE1gWOMeuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124d5001-e4f1-43a7-ae9e-00e681a331e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = torch.rand(64, 3, 32, 32, device=device)\n",
        "logits = model(X)\n",
        "print(logits.shape)\n",
        "print(logits[0])\n",
        "# print(logits[0].argmax(1))\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "e6f8dWWjhNA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc6250a-1ef7-4f54-ff44-694620f1db0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 64])\n",
            "tensor([-0.0201, -0.0382, -0.0675,  0.1091, -0.0487,  0.0453, -0.1886, -0.0453,\n",
            "         0.0323,  0.0332, -0.0521,  0.0440, -0.2036,  0.0750,  0.0423, -0.1726,\n",
            "        -0.0830, -0.0882, -0.0339,  0.0331,  0.0603, -0.0387, -0.0016,  0.0384,\n",
            "         0.0779,  0.1252, -0.0599, -0.0389, -0.1590, -0.0758, -0.0950, -0.0584,\n",
            "         0.1444,  0.1246, -0.0169,  0.1266,  0.0854,  0.1543,  0.0422, -0.1040,\n",
            "        -0.1424, -0.1049,  0.0436, -0.0555,  0.1059, -0.0304,  0.0418,  0.0867,\n",
            "        -0.0631,  0.1979,  0.0900, -0.0729,  0.0221, -0.0437,  0.0831, -0.0456,\n",
            "        -0.0426,  0.0516,  0.0558,  0.0276,  0.1113,  0.0067, -0.0216, -0.0497],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "Predicted class: tensor([49, 37, 25, 49, 49, 49, 25, 49, 25, 37, 49, 49, 49, 49, 49, 49, 49, 49,\n",
            "        25, 49, 49, 49, 37, 25, 49, 49, 49, 49, 25, 49, 25, 49, 25, 25, 49, 37,\n",
            "        25, 49, 25, 25, 49, 49, 49, 49, 25, 49, 49, 49, 49, 49, 25, 49, 37, 49,\n",
            "        49, 49, 49, 49, 49, 49, 49, 49, 49, 49], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train test function\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    # for batch, (x, y) in enumerate(dataloader):\n",
        "    for batch, ((x,y), labels) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        # print(\"sx sy\",sx.shape,sy.shape)\n",
        "        # pred = model(sx)\n",
        "        # loss = loss_fn(pred, sy)\n",
        "        loss = model.loss(sx,sy)\n",
        "        optimizer.zero_grad() # reset gradients of model parameters, to prevent double-counting\n",
        "        loss.backward() # Backpropagate gradients\n",
        "        optimizer.step() # adjust the parameters by the gradients\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def train_classifier(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "    # for batch, ((x,y), labels) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        sx = model(sx)\n",
        "        pred = model.classify(sx)\n",
        "        loss = loss_fn(pred, sy)\n",
        "        optimizer.zero_grad() # reset gradients of model parameters, to prevent double-counting\n",
        "        loss.backward() # Backpropagate gradients\n",
        "        optimizer.step() # adjust the parameters by the gradients\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            x, y = X.to(device), y.to(device)\n",
        "            sx = model(x)\n",
        "            pred = model.classify(sx)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ],
      "metadata": {
        "id": "fsealXK3OPQa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  0.1020,  0.0527,  0.0185,  0.0295, -0.0470, -0.0641,  0.0206, -0.1019\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.75) # 0.75(20)-0.9(100)\n",
        "coptimizer = torch.optim.SGD(model.classifier.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 20 #5 40\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    train_classifier(ctrain_dataloader, model, loss_fn, coptimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "# model = NeuralNetwork().to(device)\n",
        "# model.load_state_dict(torch.load(\"model.pth\"))\n"
      ],
      "metadata": {
        "id": "kDBEk-l-Oxjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711009af-c2ca-480a-f02f-0a7e9aa8f0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 16.165081  [    0/50000]\n",
            "loss: 14.027742  [ 6400/50000]\n",
            "loss: 12.221647  [12800/50000]\n",
            "loss: 13.033344  [19200/50000]\n",
            "loss: 11.234983  [25600/50000]\n",
            "loss: 22.357422  [32000/50000]\n",
            "loss: 12.353687  [38400/50000]\n",
            "loss: 11.101418  [44800/50000]\n",
            "loss: 2.276471  [    0/50000]\n",
            "loss: 2.283908  [ 6400/50000]\n",
            "loss: 2.256492  [12800/50000]\n",
            "loss: 2.259213  [19200/50000]\n",
            "loss: 2.272664  [25600/50000]\n",
            "loss: 2.279192  [32000/50000]\n",
            "loss: 2.263354  [38400/50000]\n",
            "loss: 2.261480  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 19.8%, Avg loss: 2.270920 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 13.439245  [    0/50000]\n",
            "loss: 11.759005  [ 6400/50000]\n",
            "loss: 11.017653  [12800/50000]\n",
            "loss: 11.406212  [19200/50000]\n",
            "loss: 12.451108  [25600/50000]\n",
            "loss: 13.736214  [32000/50000]\n",
            "loss: 11.844095  [38400/50000]\n",
            "loss: 11.813704  [44800/50000]\n",
            "loss: 2.276145  [    0/50000]\n",
            "loss: 2.282019  [ 6400/50000]\n",
            "loss: 2.258030  [12800/50000]\n",
            "loss: 2.256246  [19200/50000]\n",
            "loss: 2.275491  [25600/50000]\n",
            "loss: 2.282504  [32000/50000]\n",
            "loss: 2.263050  [38400/50000]\n",
            "loss: 2.260303  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 19.2%, Avg loss: 2.270244 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 15.255651  [    0/50000]\n",
            "loss: 14.381767  [ 6400/50000]\n",
            "loss: 13.946625  [12800/50000]\n",
            "loss: 11.932487  [19200/50000]\n",
            "loss: 11.315060  [25600/50000]\n",
            "loss: 14.719621  [32000/50000]\n",
            "loss: 12.989660  [38400/50000]\n",
            "loss: 11.449282  [44800/50000]\n",
            "loss: 2.275770  [    0/50000]\n",
            "loss: 2.281790  [ 6400/50000]\n",
            "loss: 2.255756  [12800/50000]\n",
            "loss: 2.261409  [19200/50000]\n",
            "loss: 2.272449  [25600/50000]\n",
            "loss: 2.282048  [32000/50000]\n",
            "loss: 2.265799  [38400/50000]\n",
            "loss: 2.257959  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 18.4%, Avg loss: 2.269133 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 13.798726  [    0/50000]\n",
            "loss: 15.096266  [ 6400/50000]\n",
            "loss: 16.677017  [12800/50000]\n",
            "loss: 10.979282  [19200/50000]\n",
            "loss: 13.038212  [25600/50000]\n",
            "loss: 12.615457  [32000/50000]\n",
            "loss: 15.953161  [38400/50000]\n",
            "loss: 12.060745  [44800/50000]\n",
            "loss: 2.274090  [    0/50000]\n",
            "loss: 2.279207  [ 6400/50000]\n",
            "loss: 2.253195  [12800/50000]\n",
            "loss: 2.255607  [19200/50000]\n",
            "loss: 2.272139  [25600/50000]\n",
            "loss: 2.280439  [32000/50000]\n",
            "loss: 2.260032  [38400/50000]\n",
            "loss: 2.259854  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 19.3%, Avg loss: 2.268547 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 14.061153  [    0/50000]\n",
            "loss: 16.956417  [ 6400/50000]\n",
            "loss: 13.429476  [12800/50000]\n",
            "loss: 11.695223  [19200/50000]\n",
            "loss: 14.961201  [25600/50000]\n",
            "loss: 11.069397  [32000/50000]\n",
            "loss: 14.041814  [38400/50000]\n",
            "loss: 10.810779  [44800/50000]\n",
            "loss: 2.273676  [    0/50000]\n",
            "loss: 2.278170  [ 6400/50000]\n",
            "loss: 2.247758  [12800/50000]\n",
            "loss: 2.258801  [19200/50000]\n",
            "loss: 2.268895  [25600/50000]\n",
            "loss: 2.281149  [32000/50000]\n",
            "loss: 2.260380  [38400/50000]\n",
            "loss: 2.256670  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 21.1%, Avg loss: 2.267152 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 12.718948  [    0/50000]\n",
            "loss: 12.797434  [ 6400/50000]\n",
            "loss: 12.870855  [12800/50000]\n",
            "loss: 11.629819  [19200/50000]\n",
            "loss: 17.989489  [25600/50000]\n",
            "loss: 10.489534  [32000/50000]\n",
            "loss: 12.812790  [38400/50000]\n",
            "loss: 11.934108  [44800/50000]\n",
            "loss: 2.271871  [    0/50000]\n",
            "loss: 2.277082  [ 6400/50000]\n",
            "loss: 2.246053  [12800/50000]\n",
            "loss: 2.251116  [19200/50000]\n",
            "loss: 2.263532  [25600/50000]\n",
            "loss: 2.279051  [32000/50000]\n",
            "loss: 2.253487  [38400/50000]\n",
            "loss: 2.254686  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 20.2%, Avg loss: 2.263542 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 12.376872  [    0/50000]\n",
            "loss: 14.213732  [ 6400/50000]\n",
            "loss: 13.175367  [12800/50000]\n",
            "loss: 10.732015  [19200/50000]\n",
            "loss: 15.358505  [25600/50000]\n",
            "loss: 12.531282  [32000/50000]\n",
            "loss: 11.053000  [38400/50000]\n",
            "loss: 10.348462  [44800/50000]\n",
            "loss: 2.270835  [    0/50000]\n",
            "loss: 2.277172  [ 6400/50000]\n",
            "loss: 2.246272  [12800/50000]\n",
            "loss: 2.249799  [19200/50000]\n",
            "loss: 2.265251  [25600/50000]\n",
            "loss: 2.275788  [32000/50000]\n",
            "loss: 2.253536  [38400/50000]\n",
            "loss: 2.248991  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 20.5%, Avg loss: 2.263042 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 13.390694  [    0/50000]\n",
            "loss: 11.694630  [ 6400/50000]\n",
            "loss: 13.364590  [12800/50000]\n",
            "loss: 12.999866  [19200/50000]\n",
            "loss: 11.464697  [25600/50000]\n",
            "loss: 12.119070  [32000/50000]\n",
            "loss: 17.681498  [38400/50000]\n",
            "loss: 11.062218  [44800/50000]\n",
            "loss: 2.268284  [    0/50000]\n",
            "loss: 2.274284  [ 6400/50000]\n",
            "loss: 2.241458  [12800/50000]\n",
            "loss: 2.243525  [19200/50000]\n",
            "loss: 2.266409  [25600/50000]\n",
            "loss: 2.273368  [32000/50000]\n",
            "loss: 2.251480  [38400/50000]\n",
            "loss: 2.250676  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 19.3%, Avg loss: 2.261471 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 13.715926  [    0/50000]\n",
            "loss: 12.523387  [ 6400/50000]\n",
            "loss: 10.861649  [12800/50000]\n",
            "loss: 12.047592  [19200/50000]\n",
            "loss: 13.237284  [25600/50000]\n",
            "loss: 15.370421  [32000/50000]\n",
            "loss: 12.668120  [38400/50000]\n",
            "loss: 10.138883  [44800/50000]\n",
            "loss: 2.264393  [    0/50000]\n",
            "loss: 2.273168  [ 6400/50000]\n",
            "loss: 2.249968  [12800/50000]\n",
            "loss: 2.248099  [19200/50000]\n",
            "loss: 2.267097  [25600/50000]\n",
            "loss: 2.276909  [32000/50000]\n",
            "loss: 2.256738  [38400/50000]\n",
            "loss: 2.255601  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 20.1%, Avg loss: 2.262710 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title save\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "PATH=\"/content/gdrive/MyDrive/torch_save/\" # for saving to google drive\n",
        "name='vicreg_tut.pth'\n",
        "# PATH=\"/content/\" # for saving on colab only\n",
        "# name='model.pth'\n",
        "\n",
        "torch.save(model.state_dict(), PATH+name)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(PATH+name))\n"
      ],
      "metadata": {
        "id": "wH6LkL0QnPTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4915156e-9771-405b-e5db-717b2ac05c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        n_class_correct = [0 for i in range(10)]\n",
        "        n_class_samples = [0 for i in range(10)]\n",
        "        for images, labels in test_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # outputs = model(images)\n",
        "            sx = model(images)\n",
        "            outputs = model.classify(sx)\n",
        "            # max returns (value ,index)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (predicted == labels).sum().item()\n",
        "            for i in range(batch_size):\n",
        "                print(len(labels))\n",
        "                label = labels[i]\n",
        "                pred = predicted[i]\n",
        "                if (label == pred):\n",
        "                    n_class_correct[label] += 1\n",
        "                n_class_samples[label] += 1\n",
        "        acc = 100.0 * n_correct / n_samples\n",
        "        print(f'Accuracy of the network: {acc} %')\n",
        "        for i in range(10):\n",
        "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "            print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "7S6mWmf_xom6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\",]\n",
        "model.eval()\n",
        "import random\n",
        "n=random.randint(0,1000)\n",
        "print(n)\n",
        "x, y = test_data[n]\n",
        "# print(x)\n",
        "with torch.no_grad():\n",
        "    # pred = model(x.to(device))\n",
        "    # print(pred)\n",
        "    # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "\n",
        "    # x, y = x.to(device), y.to(device)\n",
        "    x = x.to(device)\n",
        "    sx = model(x)\n",
        "    pred = model.classify(sx)\n",
        "    pred = torch.argmax(pred, dim=1).item()\n",
        "    print(pred)\n",
        "    print(y)\n",
        "    # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    # print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "\n"
      ],
      "metadata": {
        "id": "PoDyJMwUO4gX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}