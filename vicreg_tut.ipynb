{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ac6485d5bc9401b8839770c803cf1d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5658bfa7c6514ed19aff3557e350e9bf",
              "IPY_MODEL_e19dafec3cb64c3d8875f45860788b1a",
              "IPY_MODEL_8a972c01846f440ab73a5b018107ab0e"
            ],
            "layout": "IPY_MODEL_489b1a2e230e41498dd8f28f9f5b7792"
          }
        },
        "5658bfa7c6514ed19aff3557e350e9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7003254488d84225973a21a031f20f02",
            "placeholder": "​",
            "style": "IPY_MODEL_6ca30fa06942421398227e565c53b03b",
            "value": "100%"
          }
        },
        "e19dafec3cb64c3d8875f45860788b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a48fc78ffc274f15b5492f9ea7dd343c",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61354ee2de00483d910063bea238f050",
            "value": 170498071
          }
        },
        "8a972c01846f440ab73a5b018107ab0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fcdf43b1aee4c24845373812b2a34c3",
            "placeholder": "​",
            "style": "IPY_MODEL_1067edeef6c64b9995092637c292b958",
            "value": " 170498071/170498071 [00:14&lt;00:00, 13345897.86it/s]"
          }
        },
        "489b1a2e230e41498dd8f28f9f5b7792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7003254488d84225973a21a031f20f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ca30fa06942421398227e565c53b03b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a48fc78ffc274f15b5492f9ea7dd343c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61354ee2de00483d910063bea238f050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fcdf43b1aee4c24845373812b2a34c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1067edeef6c64b9995092637c292b958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/vicreg_tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ4wM1O48nGS"
      },
      "outputs": [],
      "source": [
        "# https://arxiv.org/pdf/2105.04906.pdf\n",
        "# https://github.com/facebookresearch/vicreg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title augmentations\n",
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "\n",
        "from PIL import ImageOps, ImageFilter\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            sigma = np.random.rand() * 1.9 + 0.1\n",
        "            # return img.filter(ImageFilter.GaussianBlur(sigma))\n",
        "            return transforms.GaussianBlur(kernel_size=5, sigma=sigma)(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "class Solarization(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            return ImageOps.solarize(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                # transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                GaussianBlur(p=1.0),\n",
        "                Solarization(p=0.0),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                # transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                GaussianBlur(p=0.1),\n",
        "                Solarization(p=0.2),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        # print(\"sample.shape\",sample.shape)\n",
        "        # sample=torch.squeeze(sample)\n",
        "        # sample=transforms.ToPILImage()(sample)\n",
        "        # sample = torch.vmap(transforms.ToPILImage(),sample)\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        # x2 = transforms.ToTensor()(sample)\n",
        "        return x1, x2\n"
      ],
      "metadata": {
        "id": "hEUffQ24mkRY",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rG3xjMTtLmYN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "9ac6485d5bc9401b8839770c803cf1d8",
            "5658bfa7c6514ed19aff3557e350e9bf",
            "e19dafec3cb64c3d8875f45860788b1a",
            "8a972c01846f440ab73a5b018107ab0e",
            "489b1a2e230e41498dd8f28f9f5b7792",
            "7003254488d84225973a21a031f20f02",
            "6ca30fa06942421398227e565c53b03b",
            "a48fc78ffc274f15b5492f9ea7dd343c",
            "61354ee2de00483d910063bea238f050",
            "1fcdf43b1aee4c24845373812b2a34c3",
            "1067edeef6c64b9995092637c292b958"
          ]
        },
        "outputId": "1e4dd7ad-160f-4438-b4da-ed4773d773e7",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ac6485d5bc9401b8839770c803cf1d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# @title data\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor #, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "\n",
        "# training_data = datasets.FashionMNIST(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "# test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True,transform=ToTensor(),)\n",
        "\n",
        "# need rgb imgs?\n",
        "# training_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=transforms.Compose([TrainTransform(), ToTensor()]),)\n",
        "training_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=TrainTransform(),)\n",
        "# test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transforms.Compose([transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC), ToTensor()]),)\n",
        "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True,transform=ToTensor(),)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "ctraining_data = datasets.CIFAR10(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "ctrain_dataloader = DataLoader(ctraining_data, batch_size=batch_size)\n",
        "\n",
        "\n",
        "dataiter = iter(test_dataloader)\n",
        "x, labels = dataiter.next() # images, labels\n",
        "# print(labels)\n",
        "# print(y.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "import torchvision\n",
        "# imshow(torchvision.utils.make_grid(x))\n",
        "# imshow(torchvision.utils.make_grid(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title vicreg\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def off_diagonal(x):\n",
        "    # print(\"off_diagonal\",x.shape)\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # dim_out=10\n",
        "        dim_class=10\n",
        "        dim_exp=128\n",
        "        self.conv = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            # nn.Conv2d(3, 8, 3, 1, 1), nn.BatchNorm2d(8), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(8, 16, 5, 1, 2), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(16, 16, 7, 1, 3), nn.BatchNorm2d(16), nn.ReLU(), #nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), #nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 5, 1, 2), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 7, 1, 3), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(256 * 8 * 8, 4096), nn.ReLU(),\n",
        "            nn.Linear(4096, 512), nn.ReLU(),\n",
        "            nn.Linear(512, 64),\n",
        "        )\n",
        "\n",
        "        f=[80,100,128]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(64, f[0]), nn.BatchNorm1d(f[0]), nn.ReLU(),\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[-1])\n",
        "            )\n",
        "        self.classifier = nn.Linear(64, dim_class)\n",
        "\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y)\n",
        "        \n",
        "        # x = torch.cat(FullGatherLayer.apply(x), dim=0)\n",
        "        # y = torch.cat(FullGatherLayer.apply(y), dim=0)\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        # print(x.var(dim=0),y.var(dim=0))\n",
        "        # print(std_x , std_y)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "        # std_loss=0.02\n",
        "        # print(torch.mean(F.relu(1 - std_x)) , torch.mean(F.relu(1 - std_y)))\n",
        "\n",
        "        # # covariance loss\n",
        "        # cov_x = (x.T @ x) / (self.args.batch_size - 1)\n",
        "        # cov_y = (y.T @ y) / (self.args.batch_size - 1)\n",
        "        # cov_loss = off_diagonal(cov_x).pow_(2).sum().div(self.num_features)\\\n",
        "        #  + off_diagonal(cov_y).pow_(2).sum().div(self.num_features)\n",
        "        # loss = (self.args.sim_coeff * repr_loss + self.args.std_coeff * std_loss + self.args.cov_coeff * cov_loss)\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=25.0 # λ / µ?\n",
        "        std_coeff=25.0\n",
        "        cov_coeff=1.0 # ν?\n",
        "\n",
        "        # print(\"x.dim()\",x.dim())\n",
        "        if x.dim() == 1:\n",
        "            x = x.view(-1, 1)\n",
        "        if y.dim() == 1:\n",
        "            y = y.view(-1, 1)\n",
        "        x=x.T\n",
        "        y=y.T\n",
        "        # print(\"x\",x.shape)\n",
        "        cov_x = (x.T @ x) / (batch_size - 1)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        # print(\"cov_x\",cov_x.shape)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features)\n",
        "        # print(\"in vicreg\",repr_loss , std_loss , cov_loss)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        return loss\n",
        "        \n",
        "    def loss(self, sx,sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        # print(\"forward x\",x.shape)\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "    def classify(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "# softmax = nn.Softmax(dim=1)\n",
        "# pred_probab = softmax(logits)\n",
        "model = NeuralNetwork().to(device) # create an instance and move it to device (cache?)\n",
        "# print(model)\n",
        "\n",
        "# LARGE BATCH TRAINING OF CONVOLUTIONAL NETWORKS\n",
        "# https://arxiv.org/pdf/1708.03888.pdf\n",
        "\n",
        "# Barlow Twins: Self-Supervised Learning via Redundancy Reduction\n",
        "# https://arxiv.org/pdf/2103.03230.pdf\n",
        "# https://github.com/facebookresearch/barlowtwins/blob/main/main.py\n",
        "\n",
        "# https://arxiv.org/search/?query=vicreg&searchtype=all\n"
      ],
      "metadata": {
        "id": "RGYE1gWOMeuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a57b97-547f-4ceb-89f7-46b1ed19b96b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = torch.rand(64, 3, 32, 32, device=device)\n",
        "logits = model(X)\n",
        "print(logits.shape)\n",
        "print(logits[0])\n",
        "# print(logits[0].argmax(1))\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "e6f8dWWjhNA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c0d968-b756-4bc8-8fab-b05760031653"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 64])\n",
            "tensor([-0.1402, -0.0820, -0.0451,  0.0304,  0.0086,  0.0953,  0.0503, -0.1340,\n",
            "         0.0013, -0.0722,  0.1491,  0.1574,  0.0774, -0.0917, -0.0467, -0.1056,\n",
            "        -0.0304, -0.0396,  0.0885,  0.0470, -0.0372,  0.0181,  0.0521, -0.0003,\n",
            "         0.0947, -0.1287, -0.1436,  0.0934,  0.1214, -0.0337,  0.1340,  0.0584,\n",
            "         0.0443, -0.0786, -0.2327,  0.1081, -0.0696,  0.1807,  0.0284,  0.0042,\n",
            "        -0.0128, -0.0948, -0.1110, -0.1459, -0.0806,  0.0351,  0.0168,  0.0287,\n",
            "         0.0673,  0.0133, -0.0546, -0.0468, -0.1250, -0.0520, -0.0145, -0.0196,\n",
            "        -0.0129,  0.0471, -0.0644, -0.0025, -0.0216,  0.0376, -0.0811,  0.0220],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "Predicted class: tensor([37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37, 37, 37, 37, 37, 37, 11, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train test function\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    # for batch, (x, y) in enumerate(dataloader):\n",
        "    for batch, ((x,y), labels) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        # print(\"sx sy\",sx.shape,sy.shape)\n",
        "        # pred = model(sx)\n",
        "        # loss = loss_fn(pred, sy)\n",
        "        loss = model.loss(sx,sy)\n",
        "        optimizer.zero_grad() # reset gradients of model parameters, to prevent double-counting\n",
        "        loss.backward() # Backpropagate gradients\n",
        "        optimizer.step() # adjust the parameters by the gradients\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def train_classifier(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "    # for batch, ((x,y), labels) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        sx = model(sx)\n",
        "        pred = model.classify(sx)\n",
        "        loss = loss_fn(pred, sy)\n",
        "        optimizer.zero_grad() # reset gradients of model parameters, to prevent double-counting\n",
        "        loss.backward() # Backpropagate gradients\n",
        "        optimizer.step() # adjust the parameters by the gradients\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            x, y = X.to(device), y.to(device)\n",
        "            sx = model(x)\n",
        "            pred = model.classify(sx)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ],
      "metadata": {
        "id": "fsealXK3OPQa",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  0.1020,  0.0527,  0.0185,  0.0295, -0.0470, -0.0641,  0.0206, -0.1019\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "coptimizer = torch.optim.SGD(model.classifier.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 5 #5 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    train_classifier(ctrain_dataloader, model, loss_fn, coptimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "# model = NeuralNetwork().to(device)\n",
        "# model.load_state_dict(torch.load(\"model.pth\"))\n"
      ],
      "metadata": {
        "id": "kDBEk-l-Oxjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8e1ab0-0273-4e4f-d9fd-65c23fb48c81"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 15.119040  [    0/50000]\n",
            "loss: 14.850348  [ 6400/50000]\n",
            "loss: 13.976443  [12800/50000]\n",
            "loss: 15.651359  [19200/50000]\n",
            "loss: 14.788509  [25600/50000]\n",
            "loss: 14.581607  [32000/50000]\n",
            "loss: 15.632578  [38400/50000]\n",
            "loss: 14.567408  [44800/50000]\n",
            "loss: 2.269583  [    0/50000]\n",
            "loss: 2.296555  [ 6400/50000]\n",
            "loss: 2.238818  [12800/50000]\n",
            "loss: 2.267452  [19200/50000]\n",
            "loss: 2.258715  [25600/50000]\n",
            "loss: 2.259788  [32000/50000]\n",
            "loss: 2.282304  [38400/50000]\n",
            "loss: 2.229334  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 17.2%, Avg loss: 2.266839 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 14.898645  [    0/50000]\n",
            "loss: 14.611539  [ 6400/50000]\n",
            "loss: 14.496476  [12800/50000]\n",
            "loss: 14.202031  [19200/50000]\n",
            "loss: 14.261537  [25600/50000]\n",
            "loss: 15.205136  [32000/50000]\n",
            "loss: 16.486755  [38400/50000]\n",
            "loss: 14.219546  [44800/50000]\n",
            "loss: 2.266939  [    0/50000]\n",
            "loss: 2.288191  [ 6400/50000]\n",
            "loss: 2.225401  [12800/50000]\n",
            "loss: 2.258638  [19200/50000]\n",
            "loss: 2.249273  [25600/50000]\n",
            "loss: 2.261369  [32000/50000]\n",
            "loss: 2.278543  [38400/50000]\n",
            "loss: 2.229512  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 17.1%, Avg loss: 2.261761 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 13.750263  [    0/50000]\n",
            "loss: 13.836218  [ 6400/50000]\n",
            "loss: 14.109581  [12800/50000]\n",
            "loss: 14.557015  [19200/50000]\n",
            "loss: 14.590084  [25600/50000]\n",
            "loss: 13.741268  [32000/50000]\n",
            "loss: 14.537727  [38400/50000]\n",
            "loss: 14.759212  [44800/50000]\n",
            "loss: 2.270786  [    0/50000]\n",
            "loss: 2.282043  [ 6400/50000]\n",
            "loss: 2.230622  [12800/50000]\n",
            "loss: 2.246794  [19200/50000]\n",
            "loss: 2.256538  [25600/50000]\n",
            "loss: 2.257423  [32000/50000]\n",
            "loss: 2.270683  [38400/50000]\n",
            "loss: 2.224659  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 15.5%, Avg loss: 2.262239 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 16.981817  [    0/50000]\n",
            "loss: 14.698626  [ 6400/50000]\n",
            "loss: 13.991705  [12800/50000]\n",
            "loss: 14.810284  [19200/50000]\n",
            "loss: 13.816441  [25600/50000]\n",
            "loss: 16.831631  [32000/50000]\n",
            "loss: 14.694748  [38400/50000]\n",
            "loss: 14.201366  [44800/50000]\n",
            "loss: 2.262789  [    0/50000]\n",
            "loss: 2.284255  [ 6400/50000]\n",
            "loss: 2.213207  [12800/50000]\n",
            "loss: 2.239901  [19200/50000]\n",
            "loss: 2.255633  [25600/50000]\n",
            "loss: 2.263405  [32000/50000]\n",
            "loss: 2.264135  [38400/50000]\n",
            "loss: 2.213589  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 16.9%, Avg loss: 2.256468 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 15.266307  [    0/50000]\n",
            "loss: 14.029319  [ 6400/50000]\n",
            "loss: 15.183985  [12800/50000]\n",
            "loss: 13.974869  [19200/50000]\n",
            "loss: 14.983536  [25600/50000]\n",
            "loss: 12.573797  [32000/50000]\n",
            "loss: 13.783421  [38400/50000]\n",
            "loss: 13.602890  [44800/50000]\n",
            "loss: 2.277334  [    0/50000]\n",
            "loss: 2.282108  [ 6400/50000]\n",
            "loss: 2.224281  [12800/50000]\n",
            "loss: 2.254715  [19200/50000]\n",
            "loss: 2.258280  [25600/50000]\n",
            "loss: 2.264359  [32000/50000]\n",
            "loss: 2.270178  [38400/50000]\n",
            "loss: 2.225436  [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 16.4%, Avg loss: 2.264107 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title save\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "PATH=\"/content/gdrive/MyDrive/torch_save/\" # for saving to google drive\n",
        "name='vicreg_tut.pth'\n",
        "# PATH=\"/content/\" # for saving on colab only\n",
        "# name='model.pth'\n",
        "\n",
        "torch.save(model.state_dict(), PATH+name)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(PATH+name))\n"
      ],
      "metadata": {
        "id": "wH6LkL0QnPTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4915156e-9771-405b-e5db-717b2ac05c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        n_class_correct = [0 for i in range(10)]\n",
        "        n_class_samples = [0 for i in range(10)]\n",
        "        for images, labels in test_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # outputs = model(images)\n",
        "            sx = model(images)\n",
        "            outputs = model.classify(sx)\n",
        "            # max returns (value ,index)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (predicted == labels).sum().item()\n",
        "            for i in range(batch_size):\n",
        "                print(len(labels))\n",
        "                label = labels[i]\n",
        "                pred = predicted[i]\n",
        "                if (label == pred):\n",
        "                    n_class_correct[label] += 1\n",
        "                n_class_samples[label] += 1\n",
        "        acc = 100.0 * n_correct / n_samples\n",
        "        print(f'Accuracy of the network: {acc} %')\n",
        "        for i in range(10):\n",
        "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "            print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "7S6mWmf_xom6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\",]\n",
        "model.eval()\n",
        "import random\n",
        "n=random.randint(0,1000)\n",
        "print(n)\n",
        "x, y = test_data[n]\n",
        "# print(x)\n",
        "with torch.no_grad():\n",
        "    # pred = model(x.to(device))\n",
        "    # print(pred)\n",
        "    # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "\n",
        "    # x, y = x.to(device), y.to(device)\n",
        "    x = x.to(device)\n",
        "    sx = model(x)\n",
        "    pred = model.classify(sx)\n",
        "    pred = torch.argmax(pred, dim=1).item()\n",
        "    print(pred)\n",
        "    print(y)\n",
        "    # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    # print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "\n"
      ],
      "metadata": {
        "id": "PoDyJMwUO4gX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}