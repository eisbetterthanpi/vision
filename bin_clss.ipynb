{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/bin_clss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kQGpnynh2oQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title download\n",
        "# # https://drive.google.com/file/d/1NkCNecLpFG3i7bo3Vl9RQSwzBpSRQ29q/view?usp=sharing\n",
        "# !gdown 1NkCNecLpFG3i7bo3Vl9RQSwzBpSRQ29q -O gsv.zip\n",
        "# !unzip /content/gsv.zip -d /content\n",
        "# import shutil\n",
        "# shutil.rmtree('/content/google_street_view/meta_data', ignore_errors=True) # delete the meta_data folder\n",
        "\n",
        "# # clip cleaned\n",
        "# # https://drive.google.com/file/d/1-xcHyVAMeTkY7SUdUyQRVAn_FFXPSDGB/view?usp=share_link\n",
        "!gdown 1-xcHyVAMeTkY7SUdUyQRVAn_FFXPSDGB -O gsv.zip\n",
        "!unzip /content/gsv.zip -d /\n",
        "!rm -R /content/gsv/.ipynb_checkpoints\n",
        "!rm -R /content/gsv/01/.ipynb_checkpoints\n",
        "!rm -R /content/gsv/02/.ipynb_checkpoints\n",
        "!rm -R /content/gsv/03/.ipynb_checkpoints\n",
        "!rm -R /content/gsv/04/.ipynb_checkpoints\n",
        "!rm -R /content/gsv/05/.ipynb_checkpoints\n",
        "!rm -R /content/gsv/06/.ipynb_checkpoints\n",
        "\n",
        "# # gsv 70k\n",
        "# # https://drive.google.com/file/d/1-7ZC29k4VxXQkpnOuLfj7Ag_SFTM4LV8/view?usp=share_link\n",
        "# !gdown 1-7ZC29k4VxXQkpnOuLfj7Ag_SFTM4LV8 -O gsv.zip\n",
        "# !unzip /content/gsv.zip -d /\n",
        "\n",
        "# # # !ls\n",
        "# !ls -a /content/gsv70k\n",
        "# !rm -R /content/gsv70k/.ipynb_checkpoints\n",
        "# # # !rm -R /content/gsv/06/.ipynb_checkpoints\n",
        "\n",
        "# # https://bestasoff.medium.com/how-to-fine-tune-very-large-model-if-it-doesnt-fit-on-your-gpu-3561e50859af\n",
        "!pip install bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "\n",
        "from PIL import ImageOps, ImageFilter\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            sigma = np.random.rand() * 1.9 + 0.1\n",
        "            # return img.filter(ImageFilter.GaussianBlur(sigma))\n",
        "            return transforms.GaussianBlur(kernel_size=5, sigma=sigma)(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "class Solarization(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            return ImageOps.solarize(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "class Cutout(object):\n",
        "    def __init__(self, p=0.5, mask_size=140, mask_color=(0, 0, 0)):\n",
        "        self.p = p\n",
        "        self.mask_size = mask_size\n",
        "        self.mask_color = mask_color\n",
        "        self.mask_size_half = self.mask_size // 2\n",
        "        # offset = 1 if mask_size % 2 == 0 else 0\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() > self.p:\n",
        "            return img\n",
        "        else:\n",
        "            img = np.asarray(img).copy()\n",
        "            h, w = img.shape[:2] # 480x600\n",
        "            cx = np.random.randint(0, w)\n",
        "            cy = np.random.randint(0, h)\n",
        "            xmin, xmax = cx - self.mask_size_half, cx + self.mask_size_half\n",
        "            ymin, ymax = cy - self.mask_size_half, cy + self.mask_size_half\n",
        "            xmin, xmax = max(0, xmin), min(w, xmax)\n",
        "            ymin, ymax = max(0, ymin), min(h, ymax)\n",
        "            img[ymin:ymax, xmin:xmax] = self.mask_color\n",
        "            return img\n",
        "\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomResizedCrop(224, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                # transforms.RandomResizedCrop((400,640), interpolation=InterpolationMode.BICUBIC),#224\n",
        "                # transforms.RandomResizedCrop((400,640), scale=(0.8, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=InterpolationMode.BICUBIC),\n",
        "                transforms.RandomResizedCrop((400,640), scale=(0.7, 1.0), ratio=(0.8, 1.25), interpolation=InterpolationMode.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(p=0.5), # 0.5\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,), # brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8\n",
        "                transforms.RandomGrayscale(p=0.2), # 0.2\n",
        "                GaussianBlur(p=1.0), # 1.0\n",
        "                # Solarization(p=0.0), # 0.0\n",
        "                Cutout(p=1.0),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # 0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225\n",
        "            ])\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        # x2 = transforms.ToTensor()(sample)\n",
        "        return x1\n",
        "# https://pytorch.org/vision/main/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
        "\n",
        "\n",
        "\n",
        "# https://github.com/hysts/pytorch_cutout/blob/master/dataloader.py\n",
        "# https://arxiv.org/pdf/1708.04552.pdf\n",
        "# size of the cutout region is a more important hyperparameter than the shape\n",
        "# randomly select a pixel coordinate within the image as a center point and then place the cutout mask around that location.\n",
        "# alternative randomly apply cutout constrained within the image region, but with 50% probability so that the network sometimes receives unmodified images\n",
        "def cutout(p=0.5, mask_size=16, mask_color=(0, 0, 0)):\n",
        "    mask_size_half = mask_size // 2\n",
        "    # offset = 1 if mask_size % 2 == 0 else 0\n",
        "    def _cutout(image):\n",
        "        image = np.asarray(image).copy()\n",
        "        if np.random.random() > p:\n",
        "            return image\n",
        "        h, w = image.shape[:2]\n",
        "        cx = np.random.randint(0, w)\n",
        "        cy = np.random.randint(0, h)\n",
        "        xmin, xmax = cx - mask_size_half, cx + mask_size_half\n",
        "        ymin, ymax = cy - mask_size_half, cy + mask_size_half\n",
        "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
        "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
        "        image[ymin:ymax, xmin:xmax] = mask_color\n",
        "        return image\n",
        "    return _cutout\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# dataset has PILImage images of range [0, 1], transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "# transform = transforms.Compose(transforms.ToTensor())\n",
        "\n",
        "# dir='/content/google_street_view'\n",
        "# dir='/content/gsv70k'\n",
        "dir='/content/gsv'\n",
        "\n",
        "# data = datasets.ImageFolder(dir, transform=transform)\n",
        "data = datasets.ImageFolder(dir, transform=None)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# train_data, test_data = torch.utils.data.random_split(data, [.85,.15])\n",
        "# https://www.scaler.com/topics/pytorch/how-to-split-a-torch-dataset/\n",
        "data_size = len(data)\n",
        "indices = np.arange(data_size)\n",
        "np.random.shuffle(indices)\n",
        "split_index = int(np.floor(0.9 * data_size))\n",
        "train_idx, test_idx = indices[:split_index], indices[split_index:]\n",
        "train_data = torch.utils.data.Subset(data, train_idx)\n",
        "test_data = torch.utils.data.Subset(data, test_idx)\n",
        "targets = np.array(data.targets)\n",
        "train_targets = targets[train_idx]\n",
        "test_targets = targets[test_idx]\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "class DatasetWrap(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super(DatasetWrap, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "        self.datasize = len(self.dataset)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.datasize\n",
        "        \n",
        "    # def __getitem__(self, index):\n",
        "    #     x, y = self.dataset[index]\n",
        "    #     x1, y1 = self.dataset[(index+1)%self.datasize]\n",
        "    #     if y>y1: yy=0.\n",
        "    #     elif y<y1: yy=1.\n",
        "    #     elif y==y1: yy=0.5\n",
        "    #     if self.transform:\n",
        "    #         x = self.transform(x)\n",
        "    #         x1 = self.transform(x1)\n",
        "    #     return (x,x1), yy\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "# train_data = DatasetWrap(train_data, TrainTransform()) # apply data augmentation to train dataset only\n",
        "train_data = DatasetWrap(train_data, transform)\n",
        "test_data = DatasetWrap(test_data, transform)\n",
        "\n",
        "batch_size = 16 # 64\n",
        "\n",
        "# https://stackoverflow.com/questions/62319228/number-of-instances-per-class-in-pytorch-dataset\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data.targets).values()))\n",
        "weights=1./class_count\n",
        "# weights=sum(class_count)/class_count\n",
        "# print(weights)\n",
        "# https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler\n",
        "\n",
        "train_weight = weights[train_targets]\n",
        "test_weight = weights[test_targets]\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(train_weight, len(train_weight))\n",
        "test_sampler = torch.utils.data.WeightedRandomSampler(test_weight, len(test_weight))\n",
        "train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "data, train_data, test_data = None, None, None\n",
        "\n",
        "num_batches=int(np.ceil(len(train_loader)/batch_size))\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = next(dataiter)\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=4))\n",
        "# dataiter=None\n",
        "# print(labels)\n",
        "\n",
        "# dataiter = iter(test_loader)\n",
        "# images, labels = next(dataiter)\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=4))\n",
        "# dataiter=None\n"
      ],
      "metadata": {
        "id": "Pqw5n--6WYEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279b9b32-f33c-4424-ece4-fe933678b517"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dir='/content/gsv'\n",
        "\n",
        "combi = torch.combinations(torch.arange(0,6), with_replacement=True)\n",
        "i, j = 1,2\n",
        "\n",
        "datai = datasets.ImageFolder(dir+'/'+str(i).zfill(2), transform=None)\n",
        "dataj = datasets.ImageFolder(dir+'/'+str(j).zfill(2), transform=None)\n",
        "train_bin_set = torch.utils.data.ConcatDataset([datai, dataj])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Fat1MI-8--ih",
        "outputId": "6d398c75-5def-4536-dd6b-c902ae9cd4dc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-4967d69d9250>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdatai\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdataj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_bin_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcatDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatai\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in /content/gsv/01."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7oYDr8kuA5Bl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, models, transforms\n",
        "# # https://pytorch.org/vision/0.12/models.html#id10\n",
        "# model = models.resnet18(pretrained=True) # 18 34 50 101 152\n",
        "model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Identity()\n",
        "bincls = nn.Sequential(nn.Linear(num_ftrs*2, num_ftrs), nn.ReLU(), # for bin classifier\n",
        "                nn.Linear(num_ftrs, 1), nn.Sigmoid(),)\n",
        "# bincls = nn.Linear(num_ftrs*2, 1) # for bin classifier\n",
        "\n",
        "\n",
        "# # model.mods = [module for k, module in model._modules.items()]\n",
        "# # modules = [module for k, module in model._modules.items()]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "bincls = bincls.to(device)\n",
        "# model = torch.compile(model.to(device))\n",
        "# model = torch.compile(model.to(device),mode='max-autotune')\n",
        "# bincls = torch.compile(bincls.to(device),mode='max-autotune')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEZCFg5YSS9J",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title try\n",
        "\n",
        "# # check model's input and output dimensions are correct\n",
        "x0 = torch.rand(16, 3, 400, 640, device=device)\n",
        "x1 = torch.rand(16, 3, 400, 640, device=device)\n",
        "model.eval()\n",
        "pred0 = model(x0)\n",
        "pred1 = model(x1)\n",
        "print(pred0.shape)\n",
        "print(torch.cat((pred0, pred1),).shape)\n",
        "\n",
        "pred = bincls(torch.cat((pred0, pred1),-1))\n",
        "\n",
        "# targets = torch.randint(0,6,(16,), device=device)\n",
        "targets = torch.randint(0,3,(16,), device=device)/2\n",
        "print(targets)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "# https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/resnet_new.py\n",
        "from torch.utils.checkpoint import checkpoint, checkpoint_sequential\n",
        "\n",
        "def triangle(bincls,pred,y,loss_fn):\n",
        "    combi = torch.combinations(torch.arange(0,y.shape[0]), with_replacement=True)\n",
        "    logits = bincls(torch.cat((pred[combi[:,0],:], pred[combi[:,1],:]),-1)).squeeze()\n",
        "    # yy = torch.where(y[combi[:,0]]>y[combi[:,1]], 0., torch.where(y[combi[:,0]]<y[combi[:,1]], 1., 0.5))\n",
        "    yy = torch.where(y[combi[:,0]]>y[combi[:,1]], 0., 1.)\n",
        "    loss = loss_fn(logits, yy)\n",
        "    return loss\n",
        "\n",
        "# train function with automatic mixed precision\n",
        "def strain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "    model,bincls=model\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        sx, sy = x.to(device), y.to(device)\n",
        "        # sy=sy.unsqueeze(-1)\n",
        "        with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "            pred = model(sx) # [16, 512]\n",
        "            # loss = loss_fn(pred, sy)\n",
        "            loss=triangle(bincls,pred,sy,loss_fn)\n",
        "            # modules = [module for k, module in model._modules.items()]\n",
        "            # pred = checkpoint_sequential(functions=modules, segments=1, input=sx) # gradient checkpointing for resnet and inception only\n",
        "            # # # pred = checkpoint_sequential(functions=model.mods, segments=1, input=sx)\n",
        "            # loss = loss_fn(pred, sy) # /4 to scale by gradient accumulation_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        # if ((batch + 1) % 4 == 0) or (batch + 1 == len(dataloader)): # gradient accumulation\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        if (batch) % (size//(10* len(x))) == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def test(dataloader, model, loss_fn, verbose=True):\n",
        "    model,bincls=model\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            sx, sy = x.to(device), y.to(device)\n",
        "            pred = model(sx)\n",
        "            # loss = loss_fn(pred, y)\n",
        "            # # # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "\n",
        "            # test_loss += loss_fn(pred, y).item()\n",
        "            test_loss += triangle(bincls,pred,y,loss_fn).item()\n",
        "            # correct += ((pred*2).round() == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    # correct /= size\n",
        "    if verbose: print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    # if verbose: print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
        "    # return correct, test_loss\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pth='/content/lr.pth'\n",
        "torch.save(model.state_dict(), pth) # save temporary model for lr finding\n"
      ],
      "metadata": {
        "id": "EDcsmMVZqGa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuumbm2SB_lX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title LR range test\n",
        "# 1cycle super convergencehttps://arxiv.org/pdf/1708.07120.pdf\n",
        "# # cyclic lr https://arxiv.org/pdf/1506.01186.pdf\n",
        "# Note the learning rate value when the accuracy starts to\n",
        "# increase and when the accuracy slows, becomes ragged, or starts to fall\n",
        "\n",
        "# one training run of the network for a few epochs\n",
        "\n",
        "epochs=5\n",
        "min_lr= 1e-7\n",
        "max_lr= 1e-3 # 1e-2\n",
        "# 152: 1e-7 - 1e-4      result 3e-7 - 3e-6\n",
        "\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = nn.BCEWithLogitsLoss() # loss with sigmoid, so model no need sigmoid\n",
        "\n",
        "model.load_state_dict(torch.load(\"lr.pth\"))\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=start_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=start_lr, momentum=0.9)\n",
        "import bitsandbytes as bnb\n",
        "# optimizer = bnb.optim.AdamW(model.parameters(), lr=min_lr, betas=(0.9, 0.999), optim_bits=8)\n",
        "optimizer = bnb.optim.AdamW(list(model.parameters())+ list(bincls.parameters()), lr=min_lr, betas=(0.9, 0.999), optim_bits=8)\n",
        "\n",
        "# num_batches=int(np.ceil(len(test_loader)/batch_size))\n",
        "num_batches=len(test_loader)\n",
        "\n",
        "# total_steps=int(np.ceil(num_batches/4)*epochs)\n",
        "total_steps=int(num_batches*epochs)\n",
        "\n",
        "# min_lr* gamma^total_steps = max_lr\n",
        "gamma = np.exp(np.log(max_lr/min_lr)/total_steps) # for scheduler step every optimizer step\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # 0.75(20)-0.9(100)\n",
        "train_lst, test_lst=[],[]\n",
        "lr_list=np.ones(total_steps)*min_lr*gamma**np.arange(total_steps)\n",
        "# gamma = np.exp(np.log(max_lr/min_lr)/(total_steps*4)) # total_steps*4 bec grad accumulation, loss step 4x per lr step\n",
        "# lr_list=np.ones(total_steps*4)*min_lr*gamma**np.arange(total_steps*4)\n",
        "\n",
        "\n",
        "for i in range(epochs):\n",
        "    train_ls = strain(test_loader, model, loss_fn, optimizer, scheduler)    \n",
        "    train_lst.extend(train_ls)\n",
        "\n",
        "\n",
        "# https://stackoverflow.com/a/53472966/13359815\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "train_lstsm = gaussian_filter1d(train_lst, sigma=3)\n",
        "end=200\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lr_list, train_lst)\n",
        "plt.plot(lr_list, train_lstsm)\n",
        "# plt.plot(lr_list[:end], train_lst[:end])\n",
        "# plt.plot(lr_list[:end], train_lstsm[:end])\n",
        "plt.xscale('log')\n",
        "# plt.plot(train_lst)\n",
        "# plt.plot(np.linspace(0,len(train_lst),len(test_lst)), test_lst)\n",
        "plt.show()\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lr_list))\n",
        "start, end = 20, 220\n",
        "plt.plot(lr_list[:end], train_lst[:end])\n",
        "plt.plot(lr_list[:end], train_lstsm[:end])\n",
        "plt.xscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hp241NCZoqkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "kDBEk-l-Oxjn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76b13886-49f7-447f-89d2-72652210af19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "1.0000000000000006e-06\n",
            "torch.Size([16, 512])\n",
            "loss: 0.204686 [    0/ 7421]\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-36 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 51, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 307, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-83a67c0a893d>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# train_ls = strain(train_loader, model, loss_fn, optimizer, scheduler)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# correct, test_loss = test(test_loader, model, loss_fn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtrain_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbincls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;31m# correct, test_loss = test(test_loader, (model,bincls), loss_fn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtrain_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-2e1ce353ced1>\u001b[0m in \u001b[0;36mstrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, scheduler, verbose)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# if ((batch + 1) % 4 == 0) or (batch + 1 == len(dataloader)): # gradient accumulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwww\n",
        "import time\n",
        "start = time.time()\n",
        "acc_lst, train_lst, test_lst=[],[],[]\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "# loss_fn = nn.BCELoss()\n",
        "# loss_fn = nn.BCEWithLogitsLoss() # loss with sigmoid, so model no need sigmoid\n",
        "loss_fn = nn.L1Loss()\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "\n",
        "base_lr, max_lr = 1e-6, 3e-5 # 1e-5, 1e-3 #0.5#\n",
        "# res152 3e-7, 3e-6\n",
        "# base_lr, max_lr = 3e-6, 3e-4\n",
        "end_lr, start_lr = 1e-5, 1e-3 # 0.0001,0.1\n",
        "\n",
        "epochs = 5 #5 20\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr = start_lr, momentum=0.9)\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "import bitsandbytes as bnb # 8bit optimizer\n",
        "# optimizer = bnb.optim.AdamW(model.parameters(), lr=base_lr, betas=(0.9, 0.999), optim_bits=8)\n",
        "optimizer = bnb.optim.AdamW(list(model.parameters())+ list(bincls.parameters()), lr=base_lr, betas=(0.9, 0.999), optim_bits=8)\n",
        "# optimizer = bnb.optim.AdamW(model.parameters(), lr=1e-5, betas=(0.9, 0.999), optim_bits=8)\n",
        "# 152 1e-5\n",
        "# cnn 3e-4\n",
        "\n",
        "div_factor = max_lr/base_lr\n",
        "num_batches=len(train_loader)\n",
        "total_steps=int(num_batches*epochs)+1\n",
        "# total_steps=int(np.ceil(num_batches/4)*epochs)+1 # +1 to excluse uptick at the end of onecycle\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, total_steps=total_steps, pct_start=0.45, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=div_factor, final_div_factor=100.0, three_phase=True,)\n",
        "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, epochs=epochs, steps_per_epoch=num_batches, pct_start=0.45, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=div_factor, final_div_factor=10000.0, three_phase=True,)\n",
        "# gamma = np.exp(np.log(end_lr/start_lr)/(num_batches*epochs)) # for scheduler step every optimizer step\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # 0.75(20)-0.9(100)\n",
        "\n",
        "\n",
        "# for x in range(int(num_batches)*1):\n",
        "#     scheduler.step()\n",
        "\n",
        "\n",
        "for t in range(0,epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    lr=optimizer.param_groups[0][\"lr\"]\n",
        "    print(lr)\n",
        "    # train_ls = strain(train_loader, model, loss_fn, optimizer, scheduler)\n",
        "    # correct, test_loss = test(test_loader, model, loss_fn)\n",
        "    train_ls = strain(train_loader, (model,bincls), loss_fn, optimizer, scheduler)\n",
        "    # correct, test_loss = test(test_loader, (model,bincls), loss_fn)\n",
        "    train_lst.extend(train_ls)\n",
        "    # test_lst.append(test_loss)\n",
        "    # acc_lst.append(correct)\n",
        "\n",
        "    # checkpoint = { # https://discuss.pytorch.org/t/saving-model-and-optimiser-and-scheduler/52030\n",
        "    # 'epoch': t,\n",
        "    # 'model': model.state_dict(),\n",
        "    # 'optimizer': optimizer.state_dict(),\n",
        "    # 'lr_sched': scheduler}\n",
        "    # # torch.save(checkpoint, 'checkpoint.pth')\n",
        "    # torch.save(checkpoint, '/content/drive/MyDrive/frame/resnet1522.pth')\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "print(\"Done!\")\n",
        "\n",
        "end = time.time()\n",
        "print(\"time: \",end - start)\n",
        "\n",
        "# print(len(train_lst), len(test_lst))\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_lst)\n",
        "# plt.plot(np.linspace(0,len(train_lst),len(test_lst)), test_lst.cpu().numpy())\n",
        "# plt.plot(np.linspace(0,len(train_lst),len(test_lst)), test_lst)\n",
        "plt.show()\n",
        "plt.plot(acc_lst)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "# model = NeuralNetwork().to(device)\n",
        "# model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# 38.9%, Avg loss: 0.725188  946s\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_loss = test(test_loader, (model,bincls), loss_fn)\n",
        "correct, test_loss = test(test_loader, (model,bincls), loss_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVdjUPcQO1Ee",
        "outputId": "39492ad7-c55a-4ca0-9caf-24e376165274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 15.8%, Avg loss: 0.924583 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title get know preds\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_dir = '/content/gsv/'\n",
        "\n",
        "size=3\n",
        "pred_lst=torch.empty((6,size,512),device=device)\n",
        "# get know preds\n",
        "from torchvision import transforms\n",
        "for x in range(6):\n",
        "    cls=x+1\n",
        "    filelist = np.array(os.listdir(img_dir+str(cls).zfill(2)))\n",
        "    clsfiles =filelist[np.random.randint(0, len(filelist), (size))]\n",
        "    for i, filename in enumerate(clsfiles):\n",
        "        img_file=os.path.join(img_dir, str(cls).zfill(2)+'/'+filename)\n",
        "        image = Image.open(img_file).convert(\"RGB\")\n",
        "        knw=transforms.ToTensor()(image).to(device).unsqueeze(0)\n",
        "        pred = model(knw)\n",
        "        # print(pred.shape) # [1, 512]\n",
        "        pred_lst[x][i]=pred\n",
        "print(pred_lst.shape) # [6, 3, 512]\n",
        "print(pred_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spq8Wy9oUlHO",
        "outputId": "303618bc-f0a4-4ab3-db54-1541237505e9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 3, 512])\n",
            "tensor([[[0.6953, 0.7724, 0.7501,  ..., 0.6733, 0.8651, 0.7300],\n",
            "         [0.6249, 0.7091, 0.7422,  ..., 0.6241, 0.7994, 0.6429],\n",
            "         [0.7246, 0.7467, 0.8165,  ..., 0.7507, 0.9288, 0.7241]],\n",
            "\n",
            "        [[0.6624, 0.6780, 0.7411,  ..., 0.6460, 0.8356, 0.6810],\n",
            "         [0.6479, 0.6958, 0.7414,  ..., 0.6546, 0.8542, 0.6489],\n",
            "         [0.5345, 0.5481, 0.6609,  ..., 0.5365, 0.7257, 0.5516]],\n",
            "\n",
            "        [[0.7189, 0.7468, 0.8103,  ..., 0.6916, 0.9092, 0.7441],\n",
            "         [0.6613, 0.7347, 0.7540,  ..., 0.6456, 0.8192, 0.7092],\n",
            "         [0.5204, 0.5337, 0.6496,  ..., 0.5333, 0.7200, 0.5258]],\n",
            "\n",
            "        [[0.5814, 0.6279, 0.6894,  ..., 0.5872, 0.7957, 0.6053],\n",
            "         [0.7469, 0.6885, 0.7818,  ..., 0.7023, 0.9330, 0.7751],\n",
            "         [0.8003, 0.7500, 0.8270,  ..., 0.7400, 0.9562, 0.8073]],\n",
            "\n",
            "        [[0.5369, 0.5235, 0.6358,  ..., 0.5235, 0.7166, 0.5707],\n",
            "         [0.6481, 0.6314, 0.7550,  ..., 0.6373, 0.8746, 0.6697],\n",
            "         [0.6392, 0.6140, 0.7433,  ..., 0.6253, 0.8434, 0.6668]],\n",
            "\n",
            "        [[0.6151, 0.6119, 0.7217,  ..., 0.6040, 0.8060, 0.6397],\n",
            "         [0.5861, 0.5883, 0.6817,  ..., 0.5906, 0.8071, 0.6050],\n",
            "         [0.5914, 0.5356, 0.6989,  ..., 0.5639, 0.8117, 0.6111]]],\n",
            "       device='cuda:0', grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img,label=next(iter(test_loader))\n",
        "# print(img.shape) # [16, 3, 400, 640]\n",
        "img=img.to(device)\n",
        "pimg = model(img)\n",
        "# print(pimg.shape) # [16, 512]\n",
        "# dpimg=pimg.expand(size,-1,-1)\n",
        "dpimg=pimg.unsqueeze(1).expand(-1,size,-1) # [16, 3, 512]\n",
        "# dpimg=pimg.expand(-1,size,512)\n",
        "# print(dpimg.shape) # [16, 3, 512] batch,size,hidden\n",
        "print(dpimg)\n",
        "\n",
        "\n",
        "# clsls=[]\n",
        "clsls=torch.empty(batch_size,6)\n",
        "# clsvote=torch.empty(batch_size)\n",
        "for x, dlst in enumerate(pred_lst): # kwn per cls\n",
        "    cls=x+1\n",
        "    # yy = torch.where(y[combi[:,0]]>y[combi[:,1]], 0., torch.where(y[combi[:,0]]<y[combi[:,1]], 1., 0.5))\n",
        "    # print(dlst.shape) # [3, 512]\n",
        "    dlst=dlst.unsqueeze(0).expand(batch_size,-1,-1) # [16, 3, 512]\n",
        "    pred = bincls(torch.cat((dlst, dpimg),-1)).squeeze() # [16, 3, 1]\n",
        "    # loss = loss_fn(pred, y)\n",
        "    # print(pred.shape, label.shape) # [16, 3], [16]\n",
        "    # clsls[x]=loss_fn(pred, label).sum()\n",
        "    clsls[:,x]=pred.sum(-1) # [16]\n",
        "    # # # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    # test_loss += loss_fn(pred, y).item()\n",
        "    # correct += ((pred*2).round() == y).type(torch.float).sum().item()\n",
        "\n",
        "torch.set_printoptions(precision=4)\n",
        "# torch.set_printoptions(profile='default')\n",
        "# print(label)\n",
        "print(clsls/size)\n",
        "print(clsls.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol2Jlc32BGYc",
        "outputId": "cfdf8861-81fb-4017-98e4-0be279ab00d3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.2047, 0.3870, 0.2975,  ..., 0.2427, 0.2582, 0.2955],\n",
            "         [0.2047, 0.3870, 0.2975,  ..., 0.2427, 0.2582, 0.2955],\n",
            "         [0.2047, 0.3870, 0.2975,  ..., 0.2427, 0.2582, 0.2955]],\n",
            "\n",
            "        [[1.2774, 1.3094, 1.3688,  ..., 1.3201, 1.6761, 1.2368],\n",
            "         [1.2774, 1.3094, 1.3688,  ..., 1.3201, 1.6761, 1.2368],\n",
            "         [1.2774, 1.3094, 1.3688,  ..., 1.3201, 1.6761, 1.2368]],\n",
            "\n",
            "        [[0.1924, 0.4473, 0.3157,  ..., 0.2722, 0.2568, 0.2669],\n",
            "         [0.1924, 0.4473, 0.3157,  ..., 0.2722, 0.2568, 0.2669],\n",
            "         [0.1924, 0.4473, 0.3157,  ..., 0.2722, 0.2568, 0.2669]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.3807, 0.5357, 0.5102,  ..., 0.4150, 0.5611, 0.4218],\n",
            "         [0.3807, 0.5357, 0.5102,  ..., 0.4150, 0.5611, 0.4218],\n",
            "         [0.3807, 0.5357, 0.5102,  ..., 0.4150, 0.5611, 0.4218]],\n",
            "\n",
            "        [[0.2838, 0.4154, 0.2905,  ..., 0.3016, 0.3218, 0.3429],\n",
            "         [0.2838, 0.4154, 0.2905,  ..., 0.3016, 0.3218, 0.3429],\n",
            "         [0.2838, 0.4154, 0.2905,  ..., 0.3016, 0.3218, 0.3429]],\n",
            "\n",
            "        [[0.8225, 0.7701, 0.9563,  ..., 0.7952, 1.0480, 0.8363],\n",
            "         [0.8225, 0.7701, 0.9563,  ..., 0.7952, 1.0480, 0.8363],\n",
            "         [0.8225, 0.7701, 0.9563,  ..., 0.7952, 1.0480, 0.8363]]],\n",
            "       device='cuda:0', grad_fn=<ExpandBackward0>)\n",
            "tensor([1, 3, 0, 0, 4, 1, 3, 1, 1, 3, 4, 0, 2, 2, 1, 5])\n",
            "tensor([[4.5254e-03, 6.3802e-03, 4.1890e-03, 5.8649e-03, 6.0601e-03, 7.5835e-03],\n",
            "        [9.9955e-01, 9.9969e-01, 9.9965e-01, 9.9974e-01, 9.9963e-01, 9.9979e-01],\n",
            "        [4.0457e-03, 5.7055e-03, 3.7442e-03, 5.2433e-03, 5.4196e-03, 6.7813e-03],\n",
            "        [9.2629e-02, 1.2374e-01, 8.9133e-02, 1.1967e-01, 1.1533e-01, 1.4777e-01],\n",
            "        [7.8207e-01, 8.3365e-01, 8.0852e-01, 8.5181e-01, 8.0997e-01, 8.7812e-01],\n",
            "        [1.0940e-02, 1.5368e-02, 1.0151e-02, 1.4176e-02, 1.4584e-02, 1.8278e-02],\n",
            "        [2.8151e-01, 3.4581e-01, 2.8659e-01, 3.5144e-01, 3.2217e-01, 4.0370e-01],\n",
            "        [1.4627e-04, 2.0673e-04, 1.3515e-04, 1.8959e-04, 1.9648e-04, 2.4562e-04],\n",
            "        [9.9944e-01, 9.9962e-01, 9.9957e-01, 9.9968e-01, 9.9955e-01, 9.9975e-01],\n",
            "        [1.7529e-01, 2.2390e-01, 1.7351e-01, 2.2355e-01, 2.0832e-01, 2.6617e-01],\n",
            "        [9.9801e-01, 9.9866e-01, 9.9847e-01, 9.9887e-01, 9.9838e-01, 9.9910e-01],\n",
            "        [5.5846e-02, 7.6125e-02, 5.2768e-02, 7.2226e-02, 7.1400e-02, 9.1043e-02],\n",
            "        [9.2625e-01, 9.4852e-01, 9.4114e-01, 9.5596e-01, 9.3867e-01, 9.6448e-01],\n",
            "        [1.7439e-01, 2.2253e-01, 1.7345e-01, 2.2254e-01, 2.0694e-01, 2.6394e-01],\n",
            "        [2.3332e-02, 3.2545e-02, 2.1758e-02, 3.0213e-02, 3.0799e-02, 3.8748e-02],\n",
            "        [9.6039e-01, 9.7283e-01, 9.6897e-01, 9.7693e-01, 9.6740e-01, 9.8146e-01]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "torch.Size([16, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_iter = iter(test_loader)\n",
        "img,label=next(test_iter)\n",
        "img=img.to(device)\n",
        "\n",
        "# img[0]\n",
        "pimg0 = model(img[0].unsqueeze(0))\n",
        "pimg1 = model(img[1].unsqueeze(0))\n",
        "pred = bincls(torch.cat((pimg0, pimg1),-1)).squeeze() # [16, 3, 1]\n",
        "print(pred)\n",
        "print(label[:2])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIah2_vI6BIP",
        "outputId": "60fb849d-e04a-4261-fb05-962ab6f643f4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8345, device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "tensor([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "img,label=next(iter(test_loader))\n",
        "img=\n",
        "with torch.no_grad():\n",
        "    # print(img.shape) # [16, 3, 400, 640]\n",
        "    img=img.to(device)\n",
        "    pimg = model(img)\n",
        "    for (X,X1), y in test_loader:\n",
        "        x0, x1, y = X.to(device), X1.to(device), y.to(device)\n",
        "        pred0 = model(x0)\n",
        "        pred1 = model(x1)\n",
        "        pred = bincls(torch.cat((pred0, pred1),-1)).squeeze()\n",
        "        predicted_labels = (pred*2).round()\n",
        "        print(y,predicted_labels)\n",
        "        y_true.extend(list(y.cpu()))\n",
        "        y_pred.extend(list(predicted_labels.cpu()))\n",
        "\n",
        "\n",
        "\n",
        "def triangle(bincls,pred,y,loss_fn):\n",
        "    combi = torch.combinations(torch.arange(0,y.shape[0]), with_replacement=True)\n",
        "    logits = bincls(torch.cat((pred[combi[:,0],:], pred[combi[:,1],:]),-1)).squeeze()\n",
        "    # yy = torch.where(y[combi[:,0]]>y[combi[:,1]], 0., torch.where(y[combi[:,0]]<y[combi[:,1]], 1., 0.5))\n",
        "    yy = torch.where(y[combi[:,0]]>y[combi[:,1]], 0., 1.)\n",
        "    loss = loss_fn(logits, yy)\n",
        "    return loss\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
        "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=['1','2','3','4','5','6',], yticklabels=['1','2','3','4','5','6',])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GWt4B_YoCxKB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "8ce2ee32-117e-49f0-bc47-3d02ad6bd77c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c11c1d9b431c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpred0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REiP7-nvhc4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c04b18-e94a-40ef-c53a-b239bb6b0d7f",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# @title save\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # pth='/content/drive/MyDrive/frame/vit.pth'\n",
        "# pth='/content/drive/MyDrive/frame/res55.pth'\n",
        "# pth='/content/drive/MyDrive/frame/resnet152.pth'\n",
        "\n",
        "torch.save(model.state_dict(), pth)\n",
        "# model.load_state_dict(torch.load(pth))\n",
        "# # model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # https://drive.google.com/file/d/1visTNvWmnuV7jAm2TBiAIIrNjbOAi1Fv/view?usp=share_link\n",
        "# !gdown 1visTNvWmnuV7jAm2TBiAIIrNjbOAi1Fv -O resnet152.pth\n",
        "\n",
        "# # t, modelsd, optimsd, scheduler = torch.load('/content/drive/MyDrive/frame/resnet152.pth').values()\n",
        "# t, modelsd, optimsd, scheduler = torch.load('/content/resnet152.pth').values()\n",
        "# model.load_state_dict(modelsd)\n",
        "# # optimizer.load_state_dict(optimsd)\n",
        "\n",
        "\n",
        "\n",
        "# # matt152 # https://drive.google.com/file/d/1MQ0xLfHbio458uEVbn2VyMpD3bij2A4J/view?usp=sharing\n",
        "# !gdown 1MQ0xLfHbio458uEVbn2VyMpD3bij2A4J -O res152.pth\n",
        "# model.load_state_dict(torch.load(\"res152.pth\"))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}