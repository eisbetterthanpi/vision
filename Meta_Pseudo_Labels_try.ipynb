{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/Meta_Pseudo_Labels_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9XrV9ZACgjm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Meta Pseudo Labels mar 2021 https://arxiv.org/pdf/2003.10580v4.pdf\n",
        "# https://github.com/kekmodel/MPL-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title download\n",
        "# # # google images unlabeled\n",
        "# !gdown 1ncx2DJ-GXqrQd6nL5UEmj6GLT4w-9qYs -O house.zip\n",
        "# !unzip /content/house.zip -d /\n",
        "# !rm -R /content/house/.ipynb_checkpoints\n",
        "\n",
        "# # # 70k+gmap\n",
        "# !gdown 1-CZp7TbhJLeRQpbKQCyT8ofGg89Yt137 -O gsv.zip\n",
        "# !unzip /content/gsv.zip -d /\n",
        "# !rm -R /content/gsv70kg/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv70kg/01/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv70kg/02/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv70kg/03/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv70kg/04/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv70kg/05/.ipynb_checkpoints\n",
        "# !rm -R /content/gsv70kg/06/.ipynb_checkpoints\n"
      ],
      "metadata": {
        "id": "z9AEoUWZekls",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title data\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "labeled_dir='/content/gsv70kg'\n",
        "\n",
        "labeled_data = datasets.ImageFolder(labeled_dir, transform=transform)\n",
        "torch.manual_seed(0)\n",
        "train_data, test_data = torch.utils.data.random_split(labeled_data, [.9,.1])\n",
        "train_data, _ = torch.utils.data.random_split(train_data, [.01,.99])\n",
        "test_data, _ = torch.utils.data.random_split(test_data, [.01,.99])\n",
        "finetune_dataset = train_data\n",
        "\n",
        "unlabel_dir='/content/house'\n",
        "# unlabel_data = datasets.ImageFolder(unlabel_dir, transform=transform)\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "class Datasetme(torch.utils.data.Dataset):\n",
        "    def __init__(self, dir, transform=None):\n",
        "        self.dir = dir\n",
        "        self.data = os.listdir(dir)\n",
        "        self.transform = transform\n",
        "    def __getitem__(self, index):\n",
        "        img_file = self.data[index]\n",
        "        img_file = os.path.join(self.dir, img_file)\n",
        "        image = Image.open(img_file).convert(\"RGB\")\n",
        "        if self.transform: image = self.transform(image)\n",
        "        return image\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "unlabel_data = Datasetme(unlabel_dir, transform=transform)\n",
        "unlabel_data, _ = torch.utils.data.random_split(unlabel_data, [.01,.99])\n",
        "\n",
        "\n",
        "batch_size = 16 # default 64/ mainargs128\n",
        "num_batches=int(np.ceil(len(train_data)/batch_size))\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "train_sampler = RandomSampler\n",
        "# labeled_loader = DataLoader(labeled_data, sampler=train_sampler(labeled_data), batch_size=batch_size, num_workers=4, drop_last=True)\n",
        "# unlabeled_loader = DataLoader(unlabel_data, sampler=train_sampler(unlabel_data), batch_size=batch_size * 7, num_workers=4, drop_last=True) # mu=7 ,coefficient of unlabeled batch size\n",
        "# test_loader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size, num_workers=4)\n",
        "\n",
        "labeled_loader = DataLoader(labeled_data, sampler=train_sampler(labeled_data), batch_size=batch_size, drop_last=True)\n",
        "unlabeled_loader = DataLoader(unlabel_data, sampler=train_sampler(unlabel_data), batch_size=batch_size * 7, drop_last=True) # mu=7 ,coefficient of unlabeled batch size\n",
        "test_loader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)\n",
        "\n",
        "del labeled_data, train_data, test_data, unlabel_data\n"
      ],
      "metadata": {
        "id": "1MAfJG1xTW3b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title torch augment\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        # self.transform = transforms.RandomApply([transforms.Compose([\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                transforms.RandomResizedCrop((400,640), scale=(0.7, 1.0), ratio=(0.8, 1.25), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                # transforms.RandomResizedCrop((32,32), scale=(0.7, 1.0), ratio=(0.8, 1.25), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(p=0.5), # 0.5\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,), # brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8\n",
        "                transforms.RandomGrayscale(p=0.2), # 0.2\n",
        "                # # transforms.RandomChoice(transforms.ColorJitter , transforms.RandomGrayscale(p=1.)\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # # transforms.RandomSolarize(threshold=130, p=0.5)\n",
        "                transforms.RandomErasing(p=1., scale=(0.1, 0.11), ratio=(1,1), value=(0.485, 0.456, 0.406)),\n",
        "                # transforms.ToTensor(), # ToTensored at dataset level, no need to ToTensor again\n",
        "                # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalised at dataset level. default 0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225\n",
        "                ])\n",
        "            # ], p=1.)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        dims = len(sample.shape)\n",
        "        if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "        # x1 = self.transform(sample)\n",
        "        return x1\n",
        "\n",
        "trs=TrainTransform()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6iYyVffJcYB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title utils\n",
        "# https://github.com/kekmodel/MPL-pytorch/blob/main/utils.py\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def create_loss_fn():\n",
        "    label_smoothing = 0 # default 0 / mainargs 0.15\n",
        "    # if label_smoothing > 0:\n",
        "    #     criterion = SmoothCrossEntropyV2(alpha=label_smoothing)\n",
        "    # else:\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    return criterion.to(device)\n",
        "\n",
        "from collections import OrderedDict\n",
        "def module_load_state_dict(model, state_dict):\n",
        "    try:\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            name = k[7:]  # remove `module.`\n",
        "            new_state_dict[name] = v\n",
        "        model.load_state_dict(new_state_dict)\n",
        "    except:\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            name = f'module.{k}'  # add `module.`\n",
        "            new_state_dict[name] = v\n",
        "        model.load_state_dict(new_state_dict)\n",
        "\n",
        "def model_load_state_dict(model, state_dict):\n",
        "    try: model.load_state_dict(state_dict)\n",
        "    except: module_load_state_dict(model, state_dict)\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    output = output.to(torch.device('cpu'))\n",
        "    target = target.to(torch.device('cpu'))\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.shape[0]\n",
        "    _, idx = output.sort(dim=1, descending=True)\n",
        "    pred = idx.narrow(1, 0, maxk).t()\n",
        "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(dim=0, keepdim=True)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "class SmoothCrossEntropy(nn.Module):\n",
        "    def __init__(self, alpha=0.1):\n",
        "        super(SmoothCrossEntropy, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        if self.alpha == 0:\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "        else:\n",
        "            num_classes = logits.shape[-1]\n",
        "            alpha_div_k = self.alpha / num_classes\n",
        "            target_probs = F.one_hot(labels, num_classes=num_classes).float() * (1. - self.alpha) + alpha_div_k\n",
        "            loss = (-(target_probs * torch.log_softmax(logits, dim=-1)).sum(dim=-1)).mean()\n",
        "        return loss\n",
        "\n",
        "class SmoothCrossEntropyV2(nn.Module):\n",
        "    \"\"\"NLL loss with label smoothing.\"\"\"\n",
        "    def __init__(self, label_smoothing=0.1):\n",
        "        super().__init__()\n",
        "        assert label_smoothing < 1.0\n",
        "        self.smoothing = label_smoothing\n",
        "        self.confidence = 1. - label_smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        if self.smoothing == 0:\n",
        "            loss = F.cross_entropy(x, target)\n",
        "        else:\n",
        "            logprobs = F.log_softmax(x, dim=-1)\n",
        "            nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "            nll_loss = nll_loss.squeeze(1)\n",
        "            smooth_loss = -logprobs.mean(dim=-1)\n",
        "            loss = (self.confidence * nll_loss + self.smoothing * smooth_loss).mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "# from main\n",
        "import math\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, num_wait_steps=0, num_cycles=0.5, last_epoch=-1):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_wait_steps:\n",
        "            return 0.0\n",
        "        if current_step < num_warmup_steps + num_wait_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps + num_wait_steps))\n",
        "        progress = float(current_step - num_warmup_steps - num_wait_steps) / float(max(1, num_training_steps - num_warmup_steps - num_wait_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
        "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
        "\n"
      ],
      "metadata": {
        "id": "q_bJYwwSDNNy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ModelEMA\n",
        "# expopnential moving average, smoothen model parameters\n",
        "# https://github.com/kekmodel/MPL-pytorch/blob/main/models.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from copy import deepcopy\n",
        "\n",
        "class ModelEMA(nn.Module):\n",
        "    def __init__(self, model, decay=0.9999, device=None):\n",
        "        super().__init__()\n",
        "        self.module = deepcopy(model)\n",
        "        self.module.eval()\n",
        "        self.decay = decay\n",
        "        self.device = device\n",
        "        if self.device is not None:\n",
        "            self.module.to(device=device)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.module(input)\n",
        "\n",
        "    def _update(self, model, update_fn):\n",
        "        with torch.no_grad():\n",
        "            for ema_v, model_v in zip(self.module.parameters(), model.parameters()):\n",
        "                if self.device is not None:\n",
        "                    model_v = model_v.to(device=self.device)\n",
        "                ema_v.copy_(update_fn(ema_v, model_v))\n",
        "            for ema_v, model_v in zip(self.module.buffers(), model.buffers()):\n",
        "                if self.device is not None:\n",
        "                    model_v = model_v.to(device=self.device)\n",
        "                ema_v.copy_(model_v)\n",
        "\n",
        "    def update_parameters(self, model):\n",
        "        self._update(model, update_fn=lambda e, m: self.decay * e + (1. - self.decay) * m)\n",
        "\n",
        "    def state_dict(self):\n",
        "        return self.module.state_dict()\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.module.load_state_dict(state_dict)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4J3GeedWa6QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title model\n",
        "\n",
        "num_classes = 6\n",
        "# if dataset == \"cifar10\": depth, widen_factor = 28, 2\n",
        "# elif dataset == 'cifar100': depth, widen_factor = 28, 8\n",
        "# teacher_model = WideResNet(num_classes=num_classes, depth=depth, widen_factor=widen_factor, dropout=0, dense_dropout=0.2)\n",
        "# student_model = WideResNet(num_classes=num_classes, depth=depth, widen_factor=widen_factor, dropout=0, dense_dropout=0.2)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "def get_resnet():\n",
        "    model = models.resnet34(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential( # og (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "        nn.Linear(num_ftrs, num_classes, bias=False),\n",
        "        nn.Softmax(dim=1),\n",
        "        )\n",
        "    # model = model.to(device)\n",
        "    model = torch.compile(model.to(device))\n",
        "    return model\n",
        "\n",
        "class Small(nn.Module):\n",
        "    def __init__(self, embed_dim, output_dim):\n",
        "        super(Small, self).__init__()\n",
        "        hidden_size=512\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_size), nn.ReLU(),\n",
        "            # nn.Linear(hidden_size, hidden_size), nn.ReLU(),\n",
        "            # nn.Linear(hidden_size, hidden_size), nn.ReLU(),\n",
        "            # nn.Linear(hidden_size, hidden_size), nn.ReLU(),\n",
        "            nn.Linear(hidden_size, output_dim, bias=False),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        logits = self.lin(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title ensemble\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Ensemble(nn.Module):\n",
        "    def __init__(self, embed_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim # 6\n",
        "        self.embed_dim = embed_dim\n",
        "        h_dim = 512\n",
        "        self.fwd = nn.Sequential(\n",
        "            nn.Linear(self.embed_dim, h_dim), nn.ReLU(),\n",
        "            # nn.Linear(h_dim, h_dim), nn.ReLU(),\n",
        "            # Block(h_dim, h_dim, 0.5),\n",
        "            Block(h_dim, h_dim),\n",
        "            Block(h_dim, h_dim),\n",
        "            Block(h_dim, h_dim),\n",
        "            nn.Linear(h_dim, self.output_dim, bias=False),\n",
        "            nn.Softmax(dim=1),\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        out = self.fwd(x)\n",
        "        return out\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, drop=None):\n",
        "        super().__init__()\n",
        "        if drop: self.fwd = nn.Sequential(nn.BatchNorm1d(in_dim), nn.Dropout(drop), nn.Linear(in_dim, out_dim), nn.ReLU(),)\n",
        "        else: self.fwd = nn.Sequential(nn.Linear(in_dim, out_dim), nn.ReLU(),)\n",
        "    def forward(self, x):\n",
        "        return x + self.fwd(x)\n",
        "\n",
        "# teacher_model = Ensemble(2048, 6).to(device)\n",
        "# teacher_model = torch.compile(Ensemble(2048, 6).to(device))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# teacher_model = Small(2048,6).to(device)\n",
        "teacher_model = torch.compile(Small(2048,6).to(device))\n",
        "\n",
        "\n",
        "# teacher_model = get_resnet()\n",
        "student_model = get_resnet()\n",
        "\n",
        "\n",
        "avg_student_model = None\n",
        "ema = 0.995 # default 0 / mainargs 0.995\n",
        "\n",
        "if ema > 0: avg_student_model = ModelEMA(student_model, ema)\n",
        "\n",
        "no_decay = ['bn']\n",
        "weight_decay = 5e-4 # default 0 / mainargs 5e-4\n",
        "teacher_parameters = [{'params': [p for n, p in teacher_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in teacher_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "student_parameters = [{'params': [p for n, p in student_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in student_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "# teacher_model.zero_grad()\n",
        "# student_model.zero_grad()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PVFBeYZgUya1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title big teacher\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "# !gdown 1ysJfdsvwMiWbCdkvFHwNqAUnJTtm6KbT -O bigTeacher.pth # res152adamw71.pth # ty\n",
        "\n",
        "model = models.resnet152(weights='DEFAULT') # 18 34 50 101 152\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential( # og (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "    # nn.Linear(num_ftrs, num_classes, bias=False),\n",
        "    # nn.Softmax(dim=1),\n",
        "    )\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "model = torch.compile(model.to(device))\n",
        "\n",
        "# model.load_state_dict(torch.load('/content/bigTeacher.pth'))\n",
        "# !pip install bitsandbytes\n",
        "_, modelsd, _,_ = torch.load('/content/bigTeacher.pth').values()\n",
        "model.load_state_dict(modelsd, strict=False)\n",
        "model.eval()\n",
        "print('uh')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n6C1jpb-WOk",
        "outputId": "b9e4d8ff-8406-4ed3-8e77-5e9a44b9f438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # 1.9, 1.7, 1.2\n",
        "# # im = torch.rand(16*15,3,400,680,device=device) #2.1, 1.8, 1.2\n",
        "# im = torch.rand(4,3,400,680,device=device) #2.1, 1.8, 1.2\n",
        "\n",
        "# torch.backends.cuda.matmul.allow_tf32 = True\n",
        "# torch.backends.cudnn.allow_tf32 = True\n",
        "# model.train()\n",
        "# with torch.cuda.amp.autocast():\n",
        "#     with torch.no_grad(): #\n",
        "#         out = model(im) # 1:2.7, 4:6.3, 8:12.8\n",
        "# # 16*15: 11.6\n",
        "\n",
        "# print(out.shape)\n",
        "# del out\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "# model = models.resnet152(weights='DEFAULT') # 18 34 50 101 152\n",
        "# model.fc = nn.Sequential()\n",
        "# model = model.to(device)\n",
        "\n",
        "# # 152:3.2\n",
        "# # im = torch.rand(4,3,400,680,device=device) #\n",
        "# # out = model(im) # 5.9\n",
        "\n",
        "# im = torch.rand(16,2048,device=device) #\n",
        "# out = teacher_model(im) # 5.9\n",
        "\n",
        "# torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "ABqGijQ6H27_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title main mpl train\n",
        "# ########## https://github.com/kekmodel/MPL-pytorch/blob/main/main.py\n",
        "# import random\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch.cuda import amp\n",
        "# from torch import nn\n",
        "# from torch.nn import functional as F\n",
        "\n",
        "# ema = 0.995 # default 0 / mainargs 0.995\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# random.seed(0)\n",
        "# np.random.seed(0)\n",
        "# torch.manual_seed(0)\n",
        "# torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# torch.backends.cuda.matmul.allow_tf32 = True\n",
        "# torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# t_scaler = amp.GradScaler()\n",
        "# s_scaler = amp.GradScaler()\n",
        "# def train(labeled_loader, unlabeled_loader, teacher_model, student_model,\n",
        "#         avg_student_model, criterion, t_optimizer, s_optimizer, t_scheduler, s_scheduler):\n",
        "#     labeled_iter = iter(labeled_loader)\n",
        "#     unlabeled_iter = iter(unlabeled_loader)\n",
        "\n",
        "#     # for author's code formula\n",
        "#     # moving_dot_product = torch.empty(1).to(device)\n",
        "#     # limit = 3.0**(0.5)  # 3 = 6 / (f_in + f_out)\n",
        "#     # nn.init.uniform_(moving_dot_product, -limit, limit)\n",
        "\n",
        "#     # eval_step = 10#1000\n",
        "#     # start_step=0\n",
        "#     # for step in range(start_step, total_steps):\n",
        "#     for step in range(len(unlabeled_loader)):\n",
        "#         teacher_model.train()\n",
        "#         student_model.train()\n",
        "\n",
        "#         try: images_l, targets = next(labeled_iter)\n",
        "#         except:\n",
        "#             labeled_iter = iter(labeled_loader)\n",
        "#             images_l, targets = next(labeled_iter)\n",
        "#         try: images_uw = next(unlabeled_iter) # images_uw, _ = next(unlabeled_iter)\n",
        "#         except:\n",
        "#             unlabeled_iter = iter(unlabeled_loader)\n",
        "#             images_uw = next(unlabeled_iter) # me\n",
        "#         images_l, targets = images_l.to(device), targets.to(device)\n",
        "#         # images_uw, images_us = images_uw.to(device), images_us.to(device)\n",
        "#         images_uw = images_uw.to(device)\n",
        "#         images_us = trs(images_uw)\n",
        "\n",
        "#         with amp.autocast():\n",
        "#             batch_size = images_l.shape[0]\n",
        "#             # print(images_l.shape, images_uw.shape, images_us.shape) # [16, 3, 400, 640], [112, 3, 400, 640], [112, 3, 400, 640] mu*batch_size\n",
        "#             t_images = torch.cat((images_l, images_uw, images_us))\n",
        "#             t_logits = teacher_model(t_images)\n",
        "#             t_logits_l = t_logits[:batch_size]\n",
        "#             t_logits_uw, t_logits_us = t_logits[batch_size:].chunk(2)\n",
        "#             del t_logits\n",
        "\n",
        "#             t_loss_l = criterion(t_logits_l, targets)\n",
        "\n",
        "#             temperature = 1 # default 1 / mainargs 0.7\n",
        "#             soft_pseudo_label = torch.softmax(t_logits_uw.detach() / temperature, dim=-1)\n",
        "#             max_probs, hard_pseudo_label = torch.max(soft_pseudo_label, dim=-1)\n",
        "\n",
        "#             threshold = 0.95 # default 0.95 / mainargs 0.6\n",
        "#             mask = max_probs.ge(threshold).float()\n",
        "#             t_loss_u = torch.mean(-(soft_pseudo_label * torch.log_softmax(t_logits_us, dim=-1)).sum(dim=-1) * mask)\n",
        "#             lambda_u = 8 # default 1 / mainargs 8 coefficient of unlabeled loss\n",
        "#             uda_steps = 10 # default 1 / mainargs 5000 warmup steps of lambda-u\n",
        "#             weight_u = lambda_u * min(1., (step + 1) / uda_steps)\n",
        "#             t_loss_uda = t_loss_l + weight_u * t_loss_u\n",
        "\n",
        "#             s_images = torch.cat((images_l, images_us))\n",
        "#             s_logits = student_model(s_images)\n",
        "#             s_logits_l = s_logits[:batch_size]\n",
        "#             s_logits_us = s_logits[batch_size:]\n",
        "#             del s_logits\n",
        "\n",
        "#             s_loss_l_old = F.cross_entropy(s_logits_l.detach(), targets)\n",
        "\n",
        "#             # print(\"s_logits_us, hard_pseudo_label: \", s_logits_us.shape, hard_pseudo_label.shape) # [448, 10] [224]\n",
        "#             s_loss = criterion(s_logits_us, hard_pseudo_label)\n",
        "\n",
        "#         s_scaler.scale(s_loss).backward()\n",
        "\n",
        "#         # if grad_clip > 0:\n",
        "#         s_scaler.unscale_(s_optimizer)\n",
        "#         nn.utils.clip_grad_norm_(student_model.parameters(), 1e9)\n",
        "\n",
        "#         s_scaler.step(s_optimizer)\n",
        "#         s_scaler.update()\n",
        "#         s_scheduler.step()\n",
        "\n",
        "#         if ema > 0: avg_student_model.update_parameters(student_model)\n",
        "\n",
        "#         with amp.autocast():\n",
        "#             with torch.no_grad():\n",
        "#                 s_logits_l = student_model(images_l)\n",
        "#             s_loss_l_new = F.cross_entropy(s_logits_l.detach(), targets)\n",
        "\n",
        "#             dot_product = s_loss_l_old - s_loss_l_new # theoretically correct formula (https://github.com/kekmodel/MPL-pytorch/issues/6)\n",
        "#             # dot_product = s_loss_l_new - s_loss_l_old # author's code formula\n",
        "#             # # moving_dot_product = moving_dot_product * 0.99 + dot_product * 0.01\n",
        "#             # # dot_product = dot_product - moving_dot_product\n",
        "\n",
        "#             _, hard_pseudo_label = torch.max(t_logits_us.detach(), dim=-1)\n",
        "#             t_loss_mpl = dot_product * F.cross_entropy(t_logits_us, hard_pseudo_label)\n",
        "\n",
        "#             # t_loss_mpl = torch.tensor(0.).to(device) # test\n",
        "#             t_loss = t_loss_uda + t_loss_mpl\n",
        "\n",
        "#         t_scaler.scale(t_loss).backward()\n",
        "\n",
        "#         # if grad_clip > 0:\n",
        "#         t_scaler.unscale_(t_optimizer)\n",
        "#         nn.utils.clip_grad_norm_(teacher_model.parameters(), 1e9)\n",
        "\n",
        "#         t_scaler.step(t_optimizer)\n",
        "#         t_scaler.update()\n",
        "#         t_scheduler.step()\n",
        "\n",
        "#         teacher_model.zero_grad()\n",
        "#         student_model.zero_grad()\n",
        "\n",
        "#         # if (step + 1) % eval_step == 0:\n",
        "#         #     # print(s_losses, t_losses, t_losses_l, t_losses_u, t_losses_mpl, mean_mask)\n",
        "#         #     test_model = avg_student_model if avg_student_model is not None else student_model\n",
        "#         #     test_loss, top1, top5 = evaluate(test_loader, test_model, criterion)\n",
        "#     return\n",
        "\n"
      ],
      "metadata": {
        "id": "wWBABdFBjZ9u",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title mpl try\n",
        "# https://github.com/kekmodel/MPL-pytorch/blob/main/main.py\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.cuda import amp\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "t_scaler = amp.GradScaler()\n",
        "s_scaler = amp.GradScaler()\n",
        "def train(labeled_loader, unlabeled_loader, teacher_model, student_model,\n",
        "        avg_student_model, criterion, t_optimizer, s_optimizer, t_scheduler, s_scheduler):\n",
        "    labeled_iter = iter(labeled_loader)\n",
        "    unlabeled_iter = iter(unlabeled_loader)\n",
        "    size = len(unlabeled_loader)\n",
        "\n",
        "    # for author's code formula\n",
        "    # moving_dot_product = torch.empty(1).to(device)\n",
        "    # limit = 3.0**(0.5)  # 3 = 6 / (f_in + f_out)\n",
        "    # nn.init.uniform_(moving_dot_product, -limit, limit)\n",
        "\n",
        "    teacher_model.train()\n",
        "    student_model.train()\n",
        "    # eval_step = 10#1000\n",
        "    # start_step=0\n",
        "    # for step in range(start_step, total_steps):\n",
        "    for step in range(len(unlabeled_loader)):\n",
        "\n",
        "        try: images_l, targets = next(labeled_iter)\n",
        "        except:\n",
        "            labeled_iter = iter(labeled_loader)\n",
        "            images_l, targets = next(labeled_iter)\n",
        "        try: images_uw = next(unlabeled_iter) # images_uw, _ = next(unlabeled_iter)\n",
        "        except:\n",
        "            unlabeled_iter = iter(unlabeled_loader)\n",
        "            images_uw = next(unlabeled_iter) # me\n",
        "        images_l, targets = images_l.to(device), targets.to(device)\n",
        "        images_uw = images_uw.to(device)\n",
        "        images_us = trs(images_uw)\n",
        "\n",
        "        with amp.autocast():\n",
        "            batch_size = images_l.shape[0]\n",
        "\n",
        "            t_images = torch.cat((images_l, images_us))\n",
        "            with torch.no_grad(): t_images = model(t_images) # reduced pml # big teacher\n",
        "            t_logits = teacher_model(t_images)\n",
        "            t_logits_l, t_logits_us = t_logits[:batch_size], t_logits[batch_size:]\n",
        "            del t_logits, t_images\n",
        "            torch.cuda.empty_cache()\n",
        "            with torch.no_grad(): # t_logits_uw no need grad\n",
        "                images_uw = model(images_uw) # reduced pml # big teacher\n",
        "                t_logits_uw = teacher_model(images_uw)\n",
        "            torch.cuda.empty_cache()\n",
        "            temperature = 1 # default 1 / mainargs 0.7\n",
        "            # soft_pseudo_label = torch.softmax(t_logits_uw.detach() / temperature, dim=-1)\n",
        "            soft_pseudo_label = torch.softmax(t_logits_uw / temperature, dim=-1)\n",
        "            max_probs, hard_pseudo_label = torch.max(soft_pseudo_label, dim=-1) # all no grads\n",
        "\n",
        "\n",
        "        with amp.autocast():\n",
        "            t_loss_l = criterion(t_logits_l, targets)\n",
        "        # t_scaler.scale(t_loss_l).backward() # me backward first\n",
        "\n",
        "        with amp.autocast():\n",
        "            threshold = 0.95 # default 0.95 / mainargs 0.6\n",
        "            mask = max_probs.ge(threshold).float()\n",
        "            t_loss_u = torch.mean(-(soft_pseudo_label * torch.log_softmax(t_logits_us, dim=-1)).sum(dim=-1) * mask)\n",
        "            lambda_u = 8 # default 1 / mainargs 8 coefficient of unlabeled loss\n",
        "            uda_steps = 10 # default 1 / mainargs 5000 warmup steps of lambda-u\n",
        "            weight_u = lambda_u * min(1., (step + 1) / uda_steps)\n",
        "            t_loss_uda = t_loss_l + weight_u * t_loss_u\n",
        "        # t_scaler.scale(weight_u * t_loss_u).backward()\n",
        "        del t_loss_l, t_loss_u, soft_pseudo_label\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "        with amp.autocast():\n",
        "            s_logits_us = student_model(images_us)\n",
        "            with torch.no_grad():\n",
        "                s_logits_l = student_model(images_l)\n",
        "            # s_loss_l_old = F.cross_entropy(s_logits_l.detach(), targets)\n",
        "            s_loss_l_old = F.cross_entropy(s_logits_l, targets)\n",
        "            s_loss = criterion(s_logits_us, hard_pseudo_label)\n",
        "        s_scaler.scale(s_loss).backward()\n",
        "        del s_logits_l, s_logits_us, hard_pseudo_label#, s_loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "        # if ((step + 1) % 4 == 0) or (step + 1 == size): # gradient accumulation\n",
        "        #     s_scaler.unscale_(s_optimizer) # if grad_clip > 0:\n",
        "        #     nn.utils.clip_grad_norm_(student_model.parameters(), 1e9)\n",
        "        #     s_scaler.step(s_optimizer)\n",
        "        #     s_scaler.update()\n",
        "        #     student_model.zero_grad()\n",
        "        #     if s_scheduler is not None:\n",
        "        #         s_scheduler.step()\n",
        "        #         # print(\"### lr: \", optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "\n",
        "        # if grad_clip > 0:\n",
        "        s_scaler.unscale_(s_optimizer)\n",
        "        nn.utils.clip_grad_norm_(student_model.parameters(), 1e9)\n",
        "        s_scaler.step(s_optimizer)\n",
        "        s_scaler.update()\n",
        "        s_scheduler.step()\n",
        "        student_model.zero_grad()\n",
        "        if ema > 0: avg_student_model.update_parameters(student_model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        with amp.autocast():\n",
        "            with torch.no_grad():\n",
        "                s_logits_l = student_model(images_l)\n",
        "            # s_loss_l_new = F.cross_entropy(s_logits_l.detach(), targets)\n",
        "            s_loss_l_new = F.cross_entropy(s_logits_l, targets)\n",
        "\n",
        "            dot_product = s_loss_l_old - s_loss_l_new # theoretically correct formula (https://github.com/kekmodel/MPL-pytorch/issues/6)\n",
        "            # dot_product = s_loss_l_new - s_loss_l_old # author's code formula\n",
        "            # # moving_dot_product = moving_dot_product * 0.99 + dot_product * 0.01\n",
        "            # # dot_product = dot_product - moving_dot_product\n",
        "\n",
        "            _, hard_pseudo_label = torch.max(t_logits_us.detach(), dim=-1)\n",
        "            t_loss_mpl = dot_product * F.cross_entropy(t_logits_us, hard_pseudo_label) # dot_product no grad\n",
        "\n",
        "            # t_loss_mpl = torch.tensor(0.).to(device) # test\n",
        "            t_loss = t_loss_uda + t_loss_mpl\n",
        "        t_scaler.scale(t_loss).backward()\n",
        "        print(\"t_loss, s_loss\", t_loss.item(), s_loss.item())\n",
        "        # t_scaler.scale(t_loss_mpl).backward()\n",
        "        del s_logits_l, dot_product, s_loss_l_old, s_loss_l_new, t_logits_us, hard_pseudo_label, t_loss, t_loss_uda, t_loss_mpl\n",
        "        del s_loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "        # if ((step + 1) % 4 == 0) or (step + 1 == size): # gradient accumulation\n",
        "        #     t_scaler.unscale_(t_optimizer) # if grad_clip > 0:\n",
        "        #     nn.utils.clip_grad_norm_(teacher_model.parameters(), 1e9)\n",
        "        #     t_scaler.step(t_optimizer)\n",
        "        #     t_scaler.update()\n",
        "        #     teacher_model.zero_grad()\n",
        "        #     if t_scheduler is not None:\n",
        "        #         t_scheduler.step()\n",
        "        #         # print(\"### lr: \", optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "\n",
        "        t_scaler.unscale_(t_optimizer) # if grad_clip > 0:\n",
        "        nn.utils.clip_grad_norm_(teacher_model.parameters(), 1e9)\n",
        "        t_scaler.step(t_optimizer)\n",
        "        t_scaler.update()\n",
        "        t_scheduler.step()\n",
        "        teacher_model.zero_grad()\n",
        "\n",
        "        # if (step + 1) % eval_step == 0:\n",
        "        #     # print(s_losses, t_losses, t_losses_l, t_losses_u, t_losses_mpl, mean_mask)\n",
        "        #     test_model = avg_student_model if avg_student_model is not None else student_model\n",
        "        #     test_loss, top1, top5 = evaluate(test_loader, test_model, criterion)\n",
        "    return\n",
        "\n"
      ],
      "metadata": {
        "id": "0V8rI3DFJK3Y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title strain eval\n",
        "\n",
        "def evaluate(test_loader, model, criterion, verbose=True):\n",
        "    size = len(test_loader.dataset)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for step, (images, targets) in enumerate(test_loader):\n",
        "            batch_size = images.shape[0]\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            with amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "        #     acc1, acc5 = accuracy(outputs, targets, (1, 5))\n",
        "        #     losses, top1, top5 = loss.item(), acc1[0], acc5[0]\n",
        "        # # return losses, top1, top5\n",
        "            correct += (outputs.argmax(1) == targets).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    try: wandb.log({\"test loss\": test_loss})\n",
        "    except: pass\n",
        "    if verbose: print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
        "    return correct, test_loss\n",
        "\n",
        "\n",
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "# https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/resnet_new.py\n",
        "from torch.utils.checkpoint import checkpoint, checkpoint_sequential\n",
        "\n",
        "trs=TrainTransform() # for image augmentation during train time\n",
        "# train function with automatic mixed precision\n",
        "def strain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "            x = trs(x) # image augmentation during train time to use gpu\n",
        "            pred = model(x) # default\n",
        "            loss = loss_fn(pred, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        if ((batch + 1) % 4 == 0) or (batch + 1 == len(dataloader)): # gradient accumulation\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "                # print(\"### lr: \", optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "        # print(model.state_dict()['_orig_mod.bn1.running_mean'][0])\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(train_loss)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % (size//(10* len(y))) == 0:\n",
        "        current = batch * len(x)\n",
        "        if verbose: print(f\"loss: {train_loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W9URMRghTLc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title wwwwwwwwwww\n",
        "\n",
        "criterion = create_loss_fn()\n",
        "\n",
        "from torch import optim\n",
        "# lr default 0.01/ mainargs 0.05\n",
        "# og:t0.05s0.05 , psl:t1e-3s3e-4, rpsl:t\n",
        "# t_optimizer = optim.SGD(teacher_parameters, lr=0.05, momentum=0.9, nesterov=True)\n",
        "# s_optimizer = optim.SGD(student_parameters, lr=0.05, momentum=0.9, nesterov=True)\n",
        "t_optimizer = optim.SGD(teacher_parameters, lr=1e-4, momentum=0.9, nesterov=True)\n",
        "s_optimizer = optim.SGD(student_parameters, lr=3e-4, momentum=0.9, nesterov=True)\n",
        "# optimizer = bnb.optim.AdamW(model.parameters(), lr=1e-5, betas=(0.9, 0.999), optim_bits=8)\n",
        "# optimizer = Lamb(model.parameters(), lr=1e-5, betas=(0.9, 0.999), eps=1e-08, weight_decay=3e-6)\n",
        "\n",
        "# 3e-5 27.9->25.0\n",
        "# 3e-3 27.9->26.5\n",
        "# 0.05 29.4 -> 22.1\n",
        "\n",
        "epochs = 10\n",
        "num_batches=len(train_loader)\n",
        "total_steps=int(num_batches*epochs)+1 # +1 to excluse uptick at the end of onecycle\n",
        "# total_steps=int(np.ceil(num_batches/4)*epochs +1) # /4 for when using grad accumulation\n",
        "# total_steps=30 # 300000\n",
        "warmup_steps = 10 # default 0 / mainargs 5000\n",
        "t_scheduler = get_cosine_schedule_with_warmup(t_optimizer, warmup_steps, total_steps)\n",
        "student_wait_steps = 3 # default 0 / mainargs 3000\n",
        "s_scheduler = get_cosine_schedule_with_warmup(s_optimizer, warmup_steps, total_steps, student_wait_steps)\n",
        "\n",
        "# scheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer, total_iters=int(np.ceil(num_batches/4)*3), power=1.0)\n",
        "# scheduler = PolynomialLR(optimizer, total_iters=4, power=1.0)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=10**(-1/2))\n",
        "\n",
        "\n",
        "# import time\n",
        "# start = time.time()\n",
        "\n",
        "pth='/content/mpl.pth' # ty\n",
        "for t in range(0,epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    t_lr=t_optimizer.param_groups[0][\"lr\"]\n",
        "    s_lr=s_optimizer.param_groups[0][\"lr\"]\n",
        "    print('t_lr,s_lr',t_lr,s_lr)\n",
        "    train(labeled_loader, unlabeled_loader, teacher_model, student_model,\n",
        "        avg_student_model, criterion, t_optimizer, s_optimizer, t_scheduler, s_scheduler)\n",
        "\n",
        "    # evaluate(test_loader, student_model, criterion)\n",
        "    evaluate(test_loader, avg_student_model, criterion)\n",
        "\n",
        "    checkpoint = {\n",
        "    'epoch': t+1,\n",
        "    'teacher_model': teacher_model.state_dict(),\n",
        "    'student_model': student_model.state_dict(),\n",
        "    'avg_student_model': avg_student_model.state_dict(),\n",
        "    't_optimizer': t_optimizer.state_dict(),\n",
        "    's_optimizer': s_optimizer.state_dict(),\n",
        "    't_scheduler': t_scheduler.state_dict(),\n",
        "    's_scheduler': s_scheduler.state_dict(),}\n",
        "    torch.save(checkpoint, pth)\n",
        "\n",
        "\n",
        "\n",
        "# finetune\n",
        "# model = student_model\n",
        "model = avg_student_model\n",
        "model.drop = nn.Identity()\n",
        "# labeled_loader = DataLoader(finetune_dataset, batch_size=128, num_workers=4, pin_memory=True) # batch_size=512\n",
        "labeled_loader = DataLoader(finetune_dataset, batch_size=128, pin_memory=True) # batch_size=512\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-5, momentum=0.9, weight_decay=0, nesterov=True)\n",
        "# scaler = amp.GradScaler()\n",
        "for epoch in range(1): #625\n",
        "    # train_ls = strain(labeled_loader, model, loss_fn, optimizer, scheduler)\n",
        "    train_ls = strain(labeled_loader, model, criterion, optimizer)\n",
        "    evaluate(test_loader, student_model, criterion)\n",
        "\n",
        "\n",
        "# 16m28s\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "Aw0nwnUAh2Of",
        "outputId": "4e265d71-aba6-4cbd-bdd4-6ea2ec8db455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "t_lr,s_lr 0.0 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8700c9900d66>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0ms_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't_lr,s_lr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     train(labeled_loader, unlabeled_loader, teacher_model, student_model,\n\u001b[0m\u001b[1;32m     44\u001b[0m         avg_student_model, criterion, t_optimizer, s_optimizer, t_scheduler, s_scheduler)\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-bd4a4a516ba1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_loader, unlabeled_loader, teacher_model, student_model, avg_student_model, criterion, t_optimizer, s_optimizer, t_scheduler, s_scheduler)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mt_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_us\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reduced pml # big teacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mt_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mt_logits_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_logits_us\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamo_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mdynamic_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mdynamic_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*runtime_args)\u001b[0m\n\u001b[1;32m   2834\u001b[0m         \u001b[0mfull_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2835\u001b[0m         \u001b[0mfull_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2836\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2838\u001b[0m     \u001b[0;31m# Just for convenience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_boxed_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boxed_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36mruntime_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_original_view_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m             all_outs = call_func_with_args(\n\u001b[0m\u001b[1;32m   1901\u001b[0m                 \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m                 \u001b[0margs_with_synthetic_bases\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36mcall_func_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_boxed_call\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0;31m# TODO: Please remove soon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(new_inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mALIGNMENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mnew_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_preserve_strides\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torchinductor_root/rq/crqpbfkbzcilgrprkiidm6v5gmt7doeceqdmhvogn7qdqjyiqnk3.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0mtriton__16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg108_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m131072\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m131072\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0marg108_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m         \u001b[0mbuf112\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m         \u001b[0massert_size_stride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mbuf111\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 122.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_lst)\n",
        "plt.plot(np.linspace(0,len(train_lst),len(test_lst)), test_lst)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "7iy-IheodNpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}