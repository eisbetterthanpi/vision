{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/vision/blob/main/selenium_house.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2v7M0yYbpoE_"
      },
      "outputs": [],
      "source": [
        "# @title setup\n",
        "# https://colab.research.google.com/github/kaliiiiiiiiii/Selenium-Profiles/blob/master/google-colab/selenium_profiles.ipynb\n",
        "\n",
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium\n",
        "\n",
        "# Install xvfb\n",
        "apt install -y xvfb\n",
        "\n",
        "# Install Selenium-Profiles\n",
        "pip uninstall -y selenium_profiles\n",
        "pip install --no-cache-dir selenium_profiles>=2.2.6\n",
        "\n",
        "# pip install https://github.com/kaliiiiiiiiii/Selenium-Profiles/archive/refs/heads/dev.zip # dev-branch\n",
        "\n",
        "# install python packages\n",
        "pip install google-colab-shell\n",
        "pip install webdriver-manager\n",
        "pip install Pyvirtualdisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iXj3Y3t3Q1Sc"
      },
      "outputs": [],
      "source": [
        "# @title service\n",
        "# https://stackoverflow.com/questions/76428999/selenium-chrome-webdriver-stopped-working\n",
        "# https://stackoverflow.com/questions/76409097/driver-webdriver-chrome-issues-with-a-selenium-approach-how-to-work-aro\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install chromium chromium-driver\n",
        "!pip3 install selenium\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "service = Service(executable_path=\"chromedriver\")\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--blink-settings=imagesEnabled=false') # me\n",
        "# options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\n",
        "driver = webdriver.Chrome(service=service, options=options)\n",
        "\n",
        "url = \"https://www.google.com/search?q=Semi-Detached+House+bungalow+modern+-plan+-interior+-illustration+-news+-model+-3D\"\n",
        "driver.get(url)  # test fingerprint\n",
        "# print(driver.title)\n",
        "driver.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9MiZCtgEFWS",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title scrape google\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "import requests\n",
        "import math\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Semi-Detached House bungalow modern -plan -interior -illustration -news -model -3D\n",
        "# url=\"https://www.google.com/search?sxsrf=AB5stBjzK4Qjah_pvMXlxkPxv3P1VZb1nQ:1688463777227&q=Semi-Detached+House+bungalow+modern+-plan+-interior+-illustration+-news+-model+-3D&tbm=isch&sa=X&ved=2ahUKEwiWh6Hd4fT_AhUp1jgGHb3WCAkQ0pQJegQIChAB&biw=1286&bih=876&dpr=1\"\n",
        "# terrace modern design \"properties\" -youtube -plan -interior -illustration -news -model -3D\n",
        "# url = \"https://www.google.com/search?q=terrace+modern+design+%22properties%22+-youtube+-plan+-interior+-illustration+-news+-model+-3D&tbm=isch&safe=active&chips=q:terrace+modern+design+properties+-youtube+-plan+-interior+-illustration+-news+-model+-3d,online_chips:3bdrm+townhouse\"\n",
        "# terrace home modern design\n",
        "# url = \"https://www.google.com/search?sxsrf=AB5stBiZ6cUkUivPpaWz3iSX09llLBFmqg:1688459159623&q=terrace+home+modern+design&tbm=isch&sa=X&ved=&biw=1286&bih=876&dpr=1#imgrc=o-90EBgQu5d1eM\"\n",
        "# similar\n",
        "url = \"https://www.google.com/search?q=Semi-Detached%20House%20-youtube%20-plan%20-interior%20-illustration%20-news%20-model%20-3D%20&tbm=isch&safe=active&tbs=rimg:CQxEH_1bPaD3IYQ0GT2Q_163gtsgIRCgIIABAAOgQIARAAVdWgbT7AAgDYAgDgAgA&hl=en-US&sa=X&ved=0CBoQuIIBahgKEwiY55v8r4aAAxUAAAAAHQAAAAAQ0AI\"\n",
        "\n",
        "# driver.get(url)\n",
        "\n",
        "# reject = driver.find_elements(By.XPATH,\"*//button[@aria-label='Reject all']\")#[0]#.click()\n",
        "# if reject: reject[0].click()\n",
        "\n",
        "# hits = driver.find_elements(By.XPATH,\"*//a[@class='wXeWr islib nfEiy']\")\n",
        "# print(len(hits))\n",
        "# # print(len(img_urls))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eSAAiOkzLVXx"
      },
      "outputs": [],
      "source": [
        "# @title funcs\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "def newdriver():\n",
        "    service = Service(executable_path=\"chromedriver\")\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--blink-settings=imagesEnabled=false') # me dont load images\n",
        "    # options.add_argument(\"--disable-gpu\") # me against SessionNotCreatedException: Timed out receiving message from renderer\n",
        "    driver = webdriver.Chrome(service=service, options=options)\n",
        "    return driver\n",
        "\n",
        "# def newdriver():\n",
        "#     time.sleep(1)\n",
        "#     return \"done\"\n",
        "\n",
        "import signal\n",
        "import time\n",
        "def timeout_handler(num, stack): raise Exception(\"timeout\")\n",
        "\n",
        "def new_driver():\n",
        "    for i in range(30):\n",
        "        signal.signal(signal.SIGALRM, timeout_handler)\n",
        "        signal.alarm(2)\n",
        "        try: return newdriver()\n",
        "        except Exception as ex: pass\n",
        "        finally: signal.alarm(0)\n",
        "\n",
        "# print(new_driver())\n",
        "# print(newdriver())\n",
        "\n",
        "\n",
        "# driver = new_driver()\n",
        "# driver.get(url)\n",
        "# reject = driver.find_elements(By.XPATH,\"*//button[@aria-label='Reject all']\")#[0]#.click()\n",
        "# if reject: reject[0].click()\n",
        "# # # driver.quit()\n",
        "\n",
        "def scroll_end(driver):\n",
        "    end = driver.find_elements(By.XPATH,'''*//div[@data-endedmessage=\"Looks like you've reached the end\"]''')[0]#.click()\n",
        "    while end.get_attribute(\"data-status\") != \"3\": # =5, =3 when reach end\n",
        "        more = driver.find_elements(By.XPATH,\"*//input[@value='Show more results']\")[0]#.click()\n",
        "        if more.is_displayed(): more.click()\n",
        "        # height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # scroll down\n",
        "\n",
        "\n",
        "# start = time.time()\n",
        "# scroll_end(driver)\n",
        "# end = time.time()\n",
        "# print(end-start) # 23.4sec 11.77s 14.43s\n",
        "# start=end\n",
        "\n",
        "\n",
        "# getting img url by clicking in, not reliable\n",
        "#     # try: img_src = driver.find_elements(By.XPATH,\"*//img[@jsname='kn3ccd']\")[0].get_attribute(\"src\")\n",
        "#     # except: continue\n",
        "#     # img_src = driver.find_elements(By.XPATH,\"*//a[@class='Du2c7e']\")[0].get_attribute(\"href\")\n",
        "#     # img_src = driver.find_elements(By.XPATH,\"*//a[@class='Du2c7e']/img\")[0].get_attribute(\"src\")\n",
        "def click_all(driver):\n",
        "    see_more=[]\n",
        "    hits = driver.find_elements(By.XPATH,\"*//a[@class='wXeWr islib nfEiy']\")\n",
        "    driver.execute_script(\"hits = document.getElementsByClassName('wXeWr islib nfEiy')\")\n",
        "    print(len(hits)) # 780\n",
        "    # for i, x in enumerate(hits):\n",
        "    for i in range(len(hits)):\n",
        "        # hits[i].click()\n",
        "        driver.execute_script(\"hits[\"+str(i)+\"].click();\")\n",
        "        try:\n",
        "            WebDriverWait(driver, 3).until(EC.presence_of_element_located((By.XPATH, \"*//a[@aria-label='See more Related content']\")))\n",
        "            see_mor = driver.find_elements(By.XPATH,\"*//a[@aria-label='See more Related content']\")[0].get_attribute(\"href\")\n",
        "        except: see_mor=\"_\"\n",
        "        see_more.append(see_mor)\n",
        "    return see_more\n",
        "# start = time.time()\n",
        "# see_more = click_all(driver)\n",
        "# end = time.time()\n",
        "# print(end-start) # [i]:894.96sec , js:820sec=13m40s 801.75s 725.8 , no images 661=11m1s 741.8, 7, eager778., none 756 ,eager 846, eager no gpu801 870\n",
        "# start=end\n",
        "\n",
        "from urllib.parse import unquote\n",
        "import re\n",
        "def get_imgurls(driver):\n",
        "    pro=driver.page_source\n",
        "    # pro=driver.execute_script(\"return document.documentElement.outerHTML\")\n",
        "    pro = unquote(pro)\n",
        "    pro = pro.encode().decode('unicode-escape') # try to remove \\\\u00\n",
        "    # pattern = r\"https://(?:(?!\\\").)*\\.jpg\" # start with https:// , no \" , end with .jpg # https://stackoverflow.com/a/67540659/13359815\n",
        "    pattern = r\"(?<=href=\\\"/imgres\\?imgurl=)(?:(?!&amp;).)*(?=&amp;)\" # start with href=\"/imgres?imgurl= , no &amp; , end with &amp; # https://stackoverflow.com/a/3926546/13359815\n",
        "    # pattern = r\"https://(?:(?!\\\").)*(?=\\\")\" # start with https:// , no \" , end with \" # all urls\n",
        "    # pattern = r\"(?<=\\],\\[\\\")https://(?:(?!\\\").)*(?=\\\")\" # start with ],[\" then https:// , no \" , end with \" # all imgs? fast\n",
        "    m = re.findall(pattern, pro)\n",
        "    return m\n",
        "\n",
        "# start = time.time()\n",
        "# m = get_imgurls(driver)\n",
        "# end = time.time()\n",
        "# print(end-start)\n",
        "# start=end\n",
        "\n",
        "import time\n",
        "def get_skip(id=0, tt=20, dx=20):\n",
        "    now = time.time()\n",
        "    cyc = tt*dx\n",
        "    curr = now %(cyc)\n",
        "    want = id*dx\n",
        "    skp = (want-curr)%cyc\n",
        "    return skp\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gfq92eKNdguJ"
      },
      "outputs": [],
      "source": [
        "# @title check driver state\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "driver.get_screenshot_as_file(\"canvas.png\")\n",
        "image = Image.open('canvas.png').convert(\"RGB\")\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.axis('off')\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "print(driver.page_source)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoqickZSJ-Sj"
      },
      "source": [
        "## wwwwwwwww"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEhH9rngzUFX"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/a/69881106/13359815\n",
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnNNJTfuzX4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c0882d9-e954-4d25-b120-e0b5ed095240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9j1Xns4WEL9",
        "outputId": "44b3c32a-d440-4973-8cc3-b56b1accbde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title setup pandas\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xX3OZdVlWQCM"
      },
      "outputs": [],
      "source": [
        "# @title save to pandas\n",
        "\n",
        "df_explore = pd.read_excel(\"/content/drive/MyDrive/explore_url.xlsx\", engine='openpyxl') # central img and seemor\n",
        "df_home = pd.read_excel(\"/content/drive/MyDrive/home_urls.xlsx\", engine='openpyxl') # finalgood img urls\n",
        "df_scrape = pd.read_excel(\"/content/drive/MyDrive/toscrape.xlsx\", engine='openpyxl') # search urls to scrape\n",
        "\n",
        "#  = pandas.concat([objs, ])\n",
        "\n",
        "# import time\n",
        "# start = time.time()\n",
        "\n",
        "\n",
        "# df_all.to_excel('/content/drive/MyDrive/properties_batch.xlsx', index=False, header=False)\n",
        "\n",
        "\n",
        "# @title pandas row\n",
        "import pandas as pd\n",
        "\n",
        "# df = pd.DataFrame()\n",
        "data = {'url':[], 'sm':[]}\n",
        "df = pd.DataFrame(data)\n",
        "# display(df)\n",
        "\n",
        "\n",
        "for i, url in enumerate(m):\n",
        "# for i, url in enumerate(m[:5]):\n",
        "    if url in df['url'].values:\n",
        "        # print(url, see_more[i])\n",
        "        continue\n",
        "    df.at[i, 'url'] = url\n",
        "    df.at[i, 'sm'] = see_more[i]\n",
        "\n",
        "# https://imgmy.waa2.com/home/160123/bungalow-for-sale-9a689ec9bd1db5caaea6d0343196e998_thumb.jpg\n",
        "\n",
        "# print(df['url'].values)\n",
        "display(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEiHXRiUWRf7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title toscrape urls\n",
        "\n",
        "# Semi-Detached House bungalow modern -plan -interior -illustration -news -model -3D\n",
        "# Semi-Detached House bungalow modern -plan -interior -illustration -news -model -3D\n",
        "# terrace modern design \"properties\" -youtube -plan -interior -illustration -news -model -3D\n",
        "# terrace home modern design\n",
        "\n",
        "# Semi-Detached House bungalow modern\n",
        "# Semi-Detached House modern\n",
        "# bungalow modern\n",
        "# Detached House modern\n",
        "# terrace modern design \"properties\"\n",
        "\n",
        "\n",
        "a1=['Semi-Detached House', 'Detached House', 'terrace House', 'bungalow']\n",
        "a2=['modern ', '']\n",
        "a3=['''\"properties\" ''', '']\n",
        "\n",
        "import itertools\n",
        "a = itertools.product(a1, a2, a3)\n",
        "for x in a:\n",
        "    # print(x)\n",
        "    # print(' '.join(x))\n",
        "    search = ' '.join(x).replace('  ',' ')\n",
        "    # search='''\\\n",
        "    # terrace modern design \"properties\"\\\n",
        "    # '''\n",
        "    # print(search)\n",
        "    exclude = \"-youtube -plan -interior -illustration -news -model -3D\"\n",
        "    query = (search+exclude).replace(' ','+')\n",
        "    # print(query)\n",
        "    url = \"https://www.google.com/search?as_st=y&tbm=isch&as_q=\"+query+\"&as_epq=&as_oq=&as_eq=&cr=&as_sitesearch=&safe=active&tbs=isz:lt,islt:qsvga,itp:photo,ic:color,iar:w\"\n",
        "    print(url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4czE-C-EQEf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title wwwwwwwww\n",
        "import pandas as pd\n",
        "\n",
        "def to_save(df, id=0):\n",
        "    print(id,'done')\n",
        "    with pd.ExcelWriter('/content/drive/MyDrive/explore_url.xlsx', mode='a', engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
        "        startrow = len(list(list(writer.sheets.values())[0].rows))\n",
        "        df.to_excel(writer, header=None, index=None, startrow=startrow)\n",
        "\n",
        "\n",
        "def get_search(sid=0, num=5):\n",
        "    if num <= 0: return\n",
        "    df_scrape = pd.read_excel(\"/content/drive/MyDrive/toscrape.xlsx\", engine='openpyxl') # search urls to scrape\n",
        "    done_idx = df_scrape['done'].count()\n",
        "    print(\"done_idx\",done_idx)\n",
        "    # df_scrape.loc[done_idx, 'done'] = 1\n",
        "    df_scrape.loc[done_idx:done_idx+num, 'done'] = 1\n",
        "    df_scrape.to_excel('/content/drive/MyDrive/toscrape.xlsx', index=False)\n",
        "    searchurls = df_scrape.loc[done_idx:done_idx+num, 'search_url'].tolist()\n",
        "    return searchurls\n",
        "\n",
        "\n",
        "def nin(): # time is right\n",
        "    global uq\n",
        "    if uq: return\n",
        "    uq=True\n",
        "    skip = get_skip(id=id, tt=5, dx=30)\n",
        "    time.sleep(skip)\n",
        "    global urlq\n",
        "    searchurls = get_search(sid=id, num=5-len(urlq))\n",
        "    if searchurls: urlq.extend(searchurls)\n",
        "    uq=False\n",
        "\n",
        "\n",
        "def pon(): # time is right\n",
        "    global sq\n",
        "    if sq: return\n",
        "    sq=True\n",
        "    skip = get_skip(id=id, tt=5, dx=30)\n",
        "    time.sleep(skip)\n",
        "    global mlist, slist\n",
        "    data = {'url':mlist, 'sm':slist}\n",
        "    df = pd.DataFrame(data)\n",
        "    to_save(df, id=id)\n",
        "    mlist, slist = [], []\n",
        "    sq=False\n",
        "\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "driver = new_driver()\n",
        "e = ThreadPoolExecutor(30)\n",
        "\n",
        "id=0 # M0 B1 S2 A3 t4\n",
        "\n",
        "sq=False\n",
        "uq=False\n",
        "mlist, slist = [], []\n",
        "urlq = []\n",
        "while True:\n",
        "    ufuture = e.submit(nin)\n",
        "    if len(urlq)==0: ufuture.result() # need to wait\n",
        "    url = urlq.pop(0)\n",
        "    print(url)\n",
        "\n",
        "    try: driver.get(url)\n",
        "    except Exception as ex:\n",
        "        print(url, ex)\n",
        "    reject = driver.find_elements(By.XPATH,\"*//button[@aria-label='Reject all']\")#[0]#.click()\n",
        "    if reject: reject[0].click()\n",
        "    try: scroll_end(driver)\n",
        "    except: continue\n",
        "    see_more = click_all(driver)\n",
        "    m = get_imgurls(driver)\n",
        "    print(id, len(m), len(see_more))\n",
        "\n",
        "    mlist.extend(m)\n",
        "    slist.extend(see_more)\n",
        "    sfuture = e.submit(pon)\n",
        "\n",
        "\n",
        "# if a['Names'].str.contains('Mel').any():\n",
        "# mel_exists = (df['names'] == 'Mel').any()\n",
        "# mel_exists2 = 'Mel' in df['names'].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCCo1NfudrEM"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\");\n",
        "    document.querySelector(\"#ok\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcxIaOn46O6A",
        "outputId": "5755407c-45a9-4655-bc41-06f0764af4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Int64Index([2, 4, 5, 6, 7, 8], dtype='int64')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "data = {'url':[7,4,7,657,63,864,5,435,6], 'sm':[1,1,0,1,0,0,0,0,0]}\n",
        "df1 = pd.DataFrame(data)\n",
        "dft = df1.loc[df1['sm'] != 1]\n",
        "# display(dft)\n",
        "print(dft.index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPowYP8WNxxa",
        "outputId": "7f4a6756-714f-4d97-a46a-bc3199e4f02b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "df_scrape = pd.read_excel(\"/content/drive/MyDrive/toscrape.xlsx\", engine='openpyxl') # search urls to scrape\n",
        "tt_search = df_scrape['search_url'].count()\n",
        "done_idx = df_scrape['done'].count()\n",
        "print(done_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/explore_url_15MBd.xlsx\", engine='openpyxl')\n",
        "df[-1] = df['see_mor'].apply(lambda x: 1 if x == '_' else 0)\n",
        "# df[-1] = df['see_mor'].apply(lambda x: x == '_')\n",
        "df.sort_values(by=[-1])\n",
        "\n",
        "# p = df[df['see_mor']=='_'].count()\n",
        "# print(p)\n",
        "display(df)\n",
        "# print(df.columns)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kF5XxikOgdVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f= lambda x: 1 if x == '_' else 0\n",
        "\n",
        "print(f(\"uihj\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJL1MZlpna_h",
        "outputId": "353d2c5f-5226-455c-bb45-36fc48644718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYUSiG6Nha55",
        "outputId": "e9582592-8ac1-47fa-82a8-2465fc4bb6e8",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141791\n"
          ]
        }
      ],
      "source": [
        "# @title remove duplicates\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/explore_url.xlsx\", engine='openpyxl')\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/explore_url_15MBd.xlsx\", engine='openpyxl')\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/explore_url_d2.xlsx\", engine='openpyxl')\n",
        "df = df.drop_duplicates(subset=\"img_url\")\n",
        "rows = df['img_url'].count()\n",
        "print(rows)\n",
        "# df.to_excel('/content/drive/MyDrive/explore_url.xlsx', index=None)\n",
        "df.to_excel('/content/drive/MyDrive/explore_url_d3.xlsx', index=None)\n",
        "# https://media.daft.ie/eyJidWNrZXQiOiJtZWRpYW1hc3Rlci1zM2V1IiwiZWRpdHMiOnsicmVzaXplIjp7ImZpdCI6ImNvdmVyIiwid2lkdGgiOjE0NDAsImhlaWdodCI6OTYwfX0sIm91dHB1dEZvcm1hdCI6ImpwZWciLCJrZXkiOiI2LzUvNjUzZTY0YTc0NTRhNzQ1N2ZmZWE0OGM3N2QwYWEyODQuanBnIn0=?signature=48bb875ff21beb34743ba4f09e5bc6979a041031ab0d77a83545c550cb776fb2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEBAGmxYX4yV"
      },
      "outputs": [],
      "source": [
        "df_scrape = pd.read_excel(\"/content/drive/MyDrive/toscrape.xlsx\", engine='openpyxl') # search urls to scrape\n",
        "# tt_search = df_scrape['search_url'].count()\n",
        "done_idx = df_scrape['done'].count()\n",
        "print(done_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OxwhfZlW8h52"
      },
      "outputs": [],
      "source": [
        "# @title xlxs operation\n",
        "df_scrape = pd.read_excel(\"/content/drive/MyDrive/toscrape.xlsx\", engine='openpyxl') # search urls to scrape\n",
        "# print(df_scrape.columns)\n",
        "# df_scrape.loc[:, 'done'] = None\n",
        "# df_scrape.drop(columns=[2], inplace=True)\n",
        "# df_scrape.drop(columns=2, inplace=True)\n",
        "# df_scrape.drop([2],axis=1)\n",
        "display(df_scrape)\n",
        "df_scrape.to_excel('/content/drive/MyDrive/toscrape.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkdGmMCTTVhN"
      },
      "source": [
        "## from clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Essjj9NyJuls"
      },
      "outputs": [],
      "source": [
        "!pip install Pillow --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IBRVTY9lbGm8"
      },
      "outputs": [],
      "source": [
        "# @title setup / model\n",
        "# https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb\n",
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "# from pkg_resources import packaging\n",
        "# print(\"Torch version:\", torch.__version__)\n",
        "import clip\n",
        "# clip.available_models()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model, preprocess = clip.load(\"ViT-B/32\") # preprocess: normalize intensity using dataset mean and sd then resize and center-crop to conform to the model expects.\n",
        "# model.cuda().eval()\n",
        "model.to(device).eval()\n",
        "input_resolution = model.visual.input_resolution # 224\n",
        "context_length = model.context_length # 77\n",
        "vocab_size = model.vocab_size # 49408\n",
        "# print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\") # 151,277,313\n",
        "# clip.tokenize(\"Hello World!\") # case-insensitive tokenizer, padded to become 77 tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HBgCanxi8JKw"
      },
      "outputs": [],
      "source": [
        "# @title test texts\n",
        "images=[]\n",
        "og_img=[]\n",
        "\n",
        "# [76,]\n",
        "gl=[251,95,175,685,688]+list(range(5))\n",
        "c=250\n",
        "# for i in range(c,c+15):\n",
        "for i in gl:\n",
        "    # response = requests.get(m[i], stream=True)\n",
        "    # try: response = requests.get(m[i], stream=True)\n",
        "    try: response = requests.get(ulst[i], stream=True)\n",
        "    except: continue\n",
        "    # img = Image.open(response.raw)\n",
        "    try: img = Image.open(response.raw)\n",
        "    except: continue\n",
        "    images.append(preprocess(img))\n",
        "    og_img.append(img)\n",
        "\n",
        "# texts=['an image of the exterior facade of a modern house','an image of the exterior facade of a house','the interior of a house','an image with text words','a collage']\n",
        "# texts=['a modern design house architecture','an image of the front exterior facade of a house','the interior of a house','a thumbnail containing english text/ words','a leaflet/ advertisement containing english text/ words','a collage']\n",
        "# texts=['a modern design house architecture','a photograph of the front exterior of a house','the interior of a house','a thumbnail containing english text/ words','a leaflet/ advertisement containing english text/ words','a collage', 'a wall']\n",
        "# texts=['a modern design house architecture','a photograph of the front exterior of a house','the interior of a house','a thumbnail containing english text/ words OR a leaflet/ advertisement containing english text/ words','a collage', 'a wall']\n",
        "# texts=['a modern design house architecture','a photograph of the front exterior of a house','the interior of a house indoors furniture','a thumbnail/ leaflet/ advertisement containing english text/ words/ text overlay','a collage of multiple images', 'a wall']\n",
        "# texts=['a modern design house architecture','a photograph of the front exterior of a house','the interior of a house with indoors furniture','a thumbnail/ leaflet/ advertisement containing english text/ words/ text overlay','a collage of multiple images/ aerial view', 'a wall/ construction site']\n",
        "texts=['a modern design house architecture','a photograph of the front exterior of a house','the interior of a house with indoors furniture','a thumbnail/ leaflet/ advertisement containing english text/ words/ text overlay','a collage of multiple images/ aerial view', 'a closeup of a single big wall']\n",
        "\n",
        "# housing facade, house front\n",
        "\n",
        "# interior of a\n",
        "# facade of a modern house\n",
        "# text/ words\n",
        "\n",
        "\n",
        "# normalize images, tokenize text input, forward pass model to get image text features\n",
        "image_input = torch.tensor(np.stack(images)).to(device)\n",
        "text_tokens = clip.tokenize([\"This is \" + desc for desc in texts]).to(device)\n",
        "# text_tokens = clip.tokenize(texts).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(image_input).float()\n",
        "    text_features = model.encode_text(text_tokens).float()\n",
        "\n",
        "# Calculating cosine similarity: normalize features and calculate dot product of each pair.\n",
        "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n",
        "# print(similarity)\n",
        "\n",
        "count = len(texts)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.figure(figsize=(20, 14))\n",
        "plt.figure(figsize=(30, 14))\n",
        "plt.imshow(similarity, vmin=0.1, vmax=0.3)\n",
        "# plt.colorbar()\n",
        "plt.yticks(range(count), texts, fontsize=18)\n",
        "plt.xticks([])\n",
        "for i, image in enumerate(og_img):\n",
        "    plt.imshow(image, extent=(i - 0.5, i + 0.5, -1.6, -0.6), origin=\"lower\")\n",
        "for x in range(similarity.shape[1]):\n",
        "    for y in range(similarity.shape[0]):\n",
        "        plt.text(x, y, f\"{similarity[y, x]:.2f}\", ha=\"center\", va=\"center\", size=12)\n",
        "\n",
        "for side in [\"left\", \"top\", \"right\", \"bottom\"]:\n",
        "    plt.gca().spines[side].set_visible(False)\n",
        "\n",
        "plt.xlim([-0.5, len(og_img) - 0.5])\n",
        "# plt.ylim([count + 0.5, -2])\n",
        "plt.ylim([count - 0.5, -1.5]) # bottom, top margin\n",
        "plt.show()\n",
        "# plt.title(\"Cosine similarity between text and image features\", size=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hBTkUZDJ8Rs-"
      },
      "outputs": [],
      "source": [
        "# @title base get similarity\n",
        "\n",
        "images=[]\n",
        "og_img=[]\n",
        "\n",
        "c=110\n",
        "for i in range(c,c+10):\n",
        "    img,label=data[i]\n",
        "    images.append(preprocess(img))\n",
        "    og_img.append(img)\n",
        "\n",
        "texts=['a modern design house architecture','an image of the front exterior facade of a house','the interior of a house','a thumbnail containing english text/ words','a leaflet/ advertisement containing english text/ words','a collage']\n",
        "\n",
        "\n",
        "# normalize images, tokenize text input, forward pass model to get image text features\n",
        "image_input = torch.tensor(np.stack(images)).to(device)\n",
        "text_tokens = clip.tokenize([\"This is \" + desc for desc in texts]).to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(image_input).float()\n",
        "    text_features = model.encode_text(text_tokens).float()\n",
        "\n",
        "# Calculating cosine similarity: normalize features and calculate dot product of each pair.\n",
        "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "# similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n",
        "\n",
        "similarity = text_features @ image_features.T\n",
        "print(similarity)\n",
        "\n",
        "# blur 0.23\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyN3PISBlubh"
      },
      "outputs": [],
      "source": [
        "# uuu=m[1]\n",
        "uuu=\"https://jcpropertiesmalta.com/wp-content/uploads/2022/09/m1e-1740x960-c-center.jpg\"\n",
        "print(uuu)\n",
        "response = requests.get(uuu, stream=True)\n",
        "image = Image.open(response.raw)\n",
        "plt.imshow(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPiFrqLftk64",
        "outputId": "f8fb3665-a099-4210-9e0c-a4741c17dddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141791\n",
            "141791\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# with pd.ExcelWriter('/content/drive/MyDrive/explore_url.xlsx', mode='a', engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
        "#     startrow = len(list(list(writer.sheets.values())[0].rows))\n",
        "#     df.to_excel(writer, header=None, index=None, startrow=startrow)\n",
        "\n",
        "# df_explore = pd.read_excel(\"/content/drive/MyDrive/explore_url.xlsx\", engine='openpyxl') # central img and seemor\n",
        "df_explore = pd.read_excel(\"/content/drive/MyDrive/explore_url_d3.xlsx\", engine='openpyxl') # central img and seemor\n",
        "# df_home = pd.read_excel(\"/content/drive/MyDrive/home_urls.xlsx\", engine='openpyxl') # finalgood img urls\n",
        "# df_scrape = pd.read_excel(\"/content/drive/MyDrive/toscrape.xlsx\", engine='openpyxl') # search urls to scrape\n",
        "\n",
        "# df_explore[2048:,:] # 30720\n",
        "m = df_explore.loc[:,'img_url'].tolist()\n",
        "see_more = df_explore.loc[:,'see_mor'].tolist()\n",
        "\n",
        "print(len(m))\n",
        "print(len(see_more))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j_xML2VFcfT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title collect\n",
        "# use clip to get similarity scores for all images\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "\n",
        "# texts=['a modern design house architecture','an image of the front exterior facade of a house','the interior of a house','a thumbnail containing english text/ words','a leaflet/ advertisement containing english text/ words','a collage']\n",
        "# texts=['a modern design house architecture','a photograph of the front exterior of a house','the interior of a house indoors furniture','a thumbnail/ leaflet/ advertisement containing english text/ words/ text overlay','a collage of multiple images', 'a wall']\n",
        "# texts=['a modern design house architecture','a photograph of the front exterior of a house','the interior of a house with indoors furniture','a thumbnail/ leaflet/ advertisement containing english text/ words/ text overlay','a collage of multiple images/ aerial view', 'a wall/ construction site']\n",
        "texts=['a modern design house architecture','a photograph of the front exterior of a modern house','the interior of a house with indoors furniture','a thumbnail/ leaflet/ advertisement containing english text/ words/ text overlay','a collage of multiple images/ aerial view', 'a closeup of a single big wall']\n",
        "\n",
        "text_tokens = clip.tokenize([\"This is \" + desc for desc in texts]).to(device)\n",
        "with torch.no_grad(): text_features = model.encode_text(text_tokens).float()\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "import io\n",
        "import requests\n",
        "def get_img(uuu):\n",
        "    for _ in range(3):\n",
        "        try:\n",
        "            response = requests.get(uuu, stream=True, timeout=5)\n",
        "            image = Image.open(response.raw).convert('RGB')\n",
        "            image = preprocess(image)\n",
        "            return uuu, image\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "    print(\"fail\", uuu)\n",
        "    return\n",
        "\n",
        "# batch_size = 1024\n",
        "# from concurrent.futures import ThreadPoolExecutor\n",
        "# import time\n",
        "# uall = []\n",
        "# small = []\n",
        "# sall = torch.empty(0, device=device)\n",
        "# # for i in range(0, len(m), batch_size):\n",
        "# for i in [0]:\n",
        "#     # i=0\n",
        "#     print(i,\"###########\")\n",
        "#     start = time.time()\n",
        "#     # e = ThreadPoolExecutor(batch_size) # 19.788sec\n",
        "#     e = ThreadPoolExecutor(min(batch_size, len(m))) # 21sec\n",
        "\n",
        "#     # result = e.map(get_img, m[i*batch_size: min((i+1)*batch_size, len(m))])\n",
        "#     # # result = e.map(get_img, m)\n",
        "#     # result = list(filter(lambda item: item is not None, result))\n",
        "\n",
        "#     # future = [e.submit(get_img, uuu) for uuu in m[i*batch_size: min((i+1)*batch_size, len(m))]]\n",
        "#     future = [e.submit(get_img, uuu) for uuu in m[i: min(i+batch_size, len(m))]]\n",
        "#     # result = [f.result() for f in future if f.result() is not None]\n",
        "#     ulst = [f.result()[0] for f in future if f.result() is not None]\n",
        "#     images = [f.result()[1] for f in future if f.result() is not None]\n",
        "#     # imgidx = [i for i in range(len(future)) if future[i].result() is not None] # only use for indexing m\n",
        "#     # print(len(ulst))\n",
        "#     smlist = [see_more[i] for i, f in enumerate(future) if f.result() is not None]\n",
        "\n",
        "\n",
        "#     end = time.time()\n",
        "#     print(end-start)\n",
        "#     start=end\n",
        "\n",
        "\n",
        "#     images = torch.tensor(np.stack(images)).to(device)\n",
        "#     # print(images.shape)\n",
        "#     # img= preprocess(images).to(device).unsqueeze(0)\n",
        "#     with torch.no_grad():\n",
        "#         image_features = model.encode_image(images).float()\n",
        "#     image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "#     similarity = text_features @ image_features.T\n",
        "#     # print(similarity.squeeze())\n",
        "\n",
        "#     uall.extend(ulst)\n",
        "#     small.extend(smlist)\n",
        "#     sall = torch.cat((sall, similarity.squeeze().T))\n",
        "\n",
        "\n",
        "# # print(sall)\n",
        "# # # 19.6s, 25.88s 28.5s\n",
        "\n",
        "# print(len(uall))\n",
        "# print(len(small))\n",
        "# print(len(sall))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P1ubEgNLM2Z1"
      },
      "outputs": [],
      "source": [
        "# @title filter\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "def clip_filter(sall, s_s=False):\n",
        "    great, good, interior, word, collage, wall, left = [],[],[],[],[],[],[]\n",
        "    great_s, good_s, interior_s, word_s, collage_s, wall_s, left_s = [],[],[],[],[],[],[]\n",
        "    # ['a modern design house architecture','an image of the front exterior facade of a house','the interior of a house','a thumbnail containing english text/ words','a leaflet/ advertisement containing english text/ words','a collage']\n",
        "    length = len(sall[0])\n",
        "    for idx, similarity in enumerate(sall):\n",
        "        modern = similarity[0]\n",
        "        house = similarity[1]\n",
        "        inter = similarity[2]\n",
        "        text = similarity[3]\n",
        "        colge = similarity[4]\n",
        "        wal = similarity[5]\n",
        "\n",
        "        if inter>=0.26: # 0.27\n",
        "        # if 0.25<=inter and inter<=0.26: # 0.27\n",
        "            interior.append(idx)\n",
        "            interior_s.append(similarity)\n",
        "        elif text>=0.20:\n",
        "            word.append(idx)\n",
        "            word_s.append(similarity)\n",
        "        elif colge>=0.21:\n",
        "            collage.append(idx)\n",
        "            collage_s.append(similarity)\n",
        "        elif wal>=0.21: # 0.21\n",
        "        # elif wal-house>=-0.03:\n",
        "        # elif -0.03<=wal-house and wal-house<=-0.02:\n",
        "            wall.append(idx)\n",
        "            wall_s.append(similarity)\n",
        "\n",
        "        # elif house<0.23 or (length-2)*house-similarity[2:].sum()<0.01 or house-iter<0.01 or house-text<0.01 or house-ad<0.01 or house-colge<0.01:\n",
        "        elif house<0.23 or (length-2)*house-similarity[2:].sum()<0.01:# or house-iter<0.01 or house-text<0.01 or house-ad<0.01 or house-colge<0.01:\n",
        "            left.append(idx)\n",
        "            # print((length-2)*house-similarity[2:].sum())\n",
        "            left_s.append((length-2)*house-similarity[2:].sum())\n",
        "            # left_s.append(similarity)\n",
        "        elif modern>=0.27: # great\n",
        "            great.append(idx)\n",
        "            great_s.append(similarity)\n",
        "        else: # good\n",
        "            good.append(idx)\n",
        "            good_s.append(similarity)\n",
        "        # print(similarity[1:].sum()-similarity[0])\n",
        "    if s_s: return great_s, good_s, interior_s, word_s, collage_s, wall_s, left_s\n",
        "    return great, good, interior, word, collage, wall, left\n",
        "# great, good, interior, word, collage, wall, left = clip_filter(sall)\n",
        "# great_s, good_s, interior_s, word_s, collage_s, wall_s, left_s = clip_filter(sall, True)\n",
        "\n",
        "# print(\"sall\",len(sall))\n",
        "# print(\"great\",len(great))\n",
        "# print(\"good\",len(good))\n",
        "# print(\"interior\",len(interior))\n",
        "# print(\"word\",len(word))\n",
        "# print(\"collage\",len(collage))\n",
        "# print(\"wall\",len(wall))\n",
        "# print(\"left\",len(left))\n",
        "# print(len(good)+len(great))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi-b0DnbB94n",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title collect all\n",
        "\n",
        "batch_size = 1024 # 16\n",
        "\n",
        "# e = ThreadPoolExecutor(batch_size)\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "for i in range(0, len(m), batch_size):\n",
        "    uall = []\n",
        "    small = []\n",
        "    sall = torch.empty(0, device=device)\n",
        "    # i=0\n",
        "    print(i,\"###########\")\n",
        "    start = time.time()\n",
        "    e = ThreadPoolExecutor(min(batch_size, len(m))) #\n",
        "\n",
        "    future = [e.submit(get_img, uuu) for uuu in m[i: min(i+batch_size, len(m))]]\n",
        "    # result = [f.result() for f in future if f.result() is not None]\n",
        "    ulst = [f.result()[0] for f in future if f.result() is not None]\n",
        "    images = [f.result()[1] for f in future if f.result() is not None]\n",
        "    # imgidx = [i for i in range(len(future)) if future[i].result() is not None] # only use for indexing m\n",
        "    # print(len(ulst))\n",
        "    smlist = [see_more[i] for i, f in enumerate(future) if f.result() is not None]\n",
        "\n",
        "\n",
        "    end = time.time()\n",
        "    print(end-start)\n",
        "    start=end\n",
        "\n",
        "    images = torch.tensor(np.stack(images)).to(device)\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(images).float()\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    similarity = text_features @ image_features.T\n",
        "\n",
        "    uall.extend(ulst)\n",
        "    small.extend(smlist)\n",
        "    sall = torch.cat((sall, similarity.squeeze().T))\n",
        "    print(\"len(ulst)\",len(ulst))\n",
        "    great, good, interior, word, collage, wall, left = clip_filter(sall)\n",
        "\n",
        "    # # save to final\n",
        "    data = {'img_url':[uall[i] for i in good+great]}\n",
        "    df = pd.DataFrame(data)\n",
        "    # display(df)\n",
        "    with pd.ExcelWriter('/content/drive/MyDrive/final_urls.xlsx', mode='a', engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
        "        startrow = len(list(list(writer.sheets.values())[0].rows))\n",
        "        df.to_excel(writer, header=None, index=None, startrow=startrow)\n",
        "\n",
        "    # # add to scrape\n",
        "    # data = {'search_url':[small[i] for i in good+great]}\n",
        "    # df = pd.DataFrame(data)\n",
        "    # # display(df)\n",
        "    # with pd.ExcelWriter('/content/drive/MyDrive/toscrape.xlsx', mode='a', engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
        "    #     startrow = len(list(list(writer.sheets.values())[0].rows))\n",
        "    #     df.to_excel(writer, header=None, index=None, startrow=startrow)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NR2txF0jkQ7-"
      },
      "outputs": [],
      "source": [
        "# @title display imgs\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(),])\n",
        "def ind_img(idx):\n",
        "    for t in range(3):\n",
        "        try:\n",
        "            # response = requests.get(m[idx], stream=True) # for checking only\n",
        "            response = requests.get(uall[idx], stream=True)\n",
        "            image = Image.open(response.raw).convert('RGB')\n",
        "            image = transform(image)\n",
        "            # print(idx, uall[idx])\n",
        "            return image\n",
        "        except Exception as e:\n",
        "            print(e, idx)\n",
        "            continue\n",
        "    print(idx, m[idx])\n",
        "    # print(idx, uall[idx])\n",
        "    return\n",
        "\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "def ind2img(indlst):\n",
        "    e = ThreadPoolExecutor(len(indlst))\n",
        "    # result = e.map(ind_img, indlst) # 8/2.7sec 7/2.5\n",
        "    # result = list(filter(lambda item: item is not None, result))\n",
        "\n",
        "    future = [e.submit(ind_img, ind) for ind in indlst] # 5/2.2sec 7/2.4\n",
        "    result = [f.result() for f in future if f.result() is not None]\n",
        "    # print(None in result)\n",
        "    # [print(x.shape) for x in result]\n",
        "    # print(np.stack(result).shape)\n",
        "    images = torch.tensor(np.stack(result))#.to(device)\n",
        "    return images\n",
        "\n",
        "\n",
        "c=0\n",
        "start = time.time()\n",
        "import torchvision\n",
        "# print(\"great\")\n",
        "# imshow(torchvision.utils.make_grid(ind2img(great)))\n",
        "imshow(torchvision.utils.make_grid(ind2img(great[c:c+64])))\n",
        "print(\"good\")\n",
        "imshow(torchvision.utils.make_grid(ind2img(good[c:c+64])))\n",
        "# print(\"interior\")\n",
        "# imshow(torchvision.utils.make_grid(ind2img(interior)))\n",
        "# print(\"word\")\n",
        "# imshow(torchvision.utils.make_grid(ind2img(word[c:c+64])))\n",
        "# # # # imshow(torchvision.utils.make_grid(ind2img(word)))\n",
        "# print(\"wall\")\n",
        "# imshow(torchvision.utils.make_grid(ind2img(wall[c:c+64])))\n",
        "# # # imshow(torchvision.utils.make_grid(ind2img(wall)))\n",
        "# print(\"left\")\n",
        "# imshow(torchvision.utils.make_grid(ind2img(left[c:c+64])))\n",
        "# print(\"collage\")\n",
        "# imshow(torchvision.utils.make_grid(ind2img(collage)))\n",
        "# imshow(torchvision.utils.make_grid(ind2img(list(range(len(uall))))))\n",
        "# imshow(torchvision.utils.make_grid(ind2img(list(range(c*64,(c+1)*64)))))\n",
        "\n",
        "\n",
        "# for c in range(11):\n",
        "#     print(c)\n",
        "#     imshow(torchvision.utils.make_grid(ind2img(list(range(c*64,(c+1)*64)))))\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)\n",
        "start=end\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CawC57Q9QMKk",
        "outputId": "bf8e5f28-261e-4a83-c5da-fbec7d8fa299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "688\n",
            "https://buysellcyprus.com/images/small/1/91/091/3-bedroom-detached-house-for-sale-peyia-paphos-855091-photo-722034.jpg\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# print(great[:64])\n",
        "# word[2:5] 17=95,48=175\n",
        "# wall[57:59] 57=685, 58=688\n",
        "\n",
        "# ind = great[28]\n",
        "# ind = word[48]\n",
        "ind = wall[58]\n",
        "print(ind)\n",
        "uuu = uall[ind]\n",
        "print(uuu)\n",
        "# print(good[6])\n",
        "# print(wall[33]) # 18,19,33\n",
        "# print(wall_s[33])\n",
        "\n",
        "# response = requests.get(uuu, stream=True)\n",
        "# image = Image.open(response.raw)\n",
        "# image = transform(image)\n",
        "# # print(image.shape)\n",
        "# plt.imshow(image)\n",
        "# print(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0_grtabroaS"
      },
      "outputs": [],
      "source": [
        "# great, good, interior, word, collage, wall, left\n",
        "\n",
        "# print(wall_s[:,5])\n",
        "for i, x in enumerate(wall_s[:64]):\n",
        "    # print(i, x[5].item(), (x[1]-x[5]).item())\n",
        "    print(i, x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcK3BYSFQXg1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "data = {'img_url':[uall[i] for i in good+great]}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "# skip = get_skip(id=id, tt=tt, dx=dx)\n",
        "# # print(id, \"skip\", skip)\n",
        "# time.sleep(skip)\n",
        "# # df_home = pd.read_excel(\"/content/drive/MyDrive/home_urls.xlsx\", engine='openpyxl') # good img urls\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/home_urls.xlsx', mode='a', engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
        "    # df.to_excel(writer, header=None, index=None, startrow=len(df.index))\n",
        "    startrow = len(list(list(writer.sheets.values())[0].rows))\n",
        "    df.to_excel(writer, header=None, index=None, startrow=startrow)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg_yG5AOMf3D",
        "outputId": "2a061ea2-bed7-4177-d971-6c38aec65cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content/gsv70k/01/01. 20 BUTTERFLY AVE 2022-03.jpg', '/content/gsv70k/01/01. 9 JLN LABU AYER 2019-05.jpg', '/content/gsv70k/01/01. 7 LUCKY CRES 2022-09.jpg', '/content/gsv70k/01/01. 1A GUILLEMARD RD 2022-04.jpg', '/content/gsv70k/01/01. 102 JLN KURAS 2019-08.jpg', '/content/gsv70k/01/01. 38 PEACH GDN 2022-10.jpg', '/content/gsv70k/01/01. 30 JLN ASAS 2022-11.jpg', '/content/gsv70k/01/01. 17 ELITE TER 2022-09.jpg', '/content/gsv70k/01/01. 8 HAIG AVE 2022-05.jpg', '/content/gsv70k/01/01. 22 LIMAU GDN 2022-09.jpg', '/content/gsv70k/01/01. 92A GUILLEMARD RD 2022-09.jpg', '/content/gsv70k/01/01. 94 BRANKSOME RD 2022-03.jpg', '/content/gsv70k/01/01. 4 FIDELIO ST 2023-01.jpg', '/content/gsv70k/01/01. 132 MARSHALL RD 2022-10.jpg', '/content/gsv70k/01/01. 54 LICHI AVE 2018-03.jpg', '/content/gsv70k/01/01. 17 NAROOMA RD 2022-09.jpg', '/content/gsv70k/01/01. 22A BRIGHTON AVE 2019-04.jpg', '/content/gsv70k/01/01. 24 ROBERTS LN 2022-10.jpg', '/content/gsv70k/01/01. 442 MACPHERSON RD 2022-03.jpg', '/content/gsv70k/01/01. 23 JLN MENGKUDU 2011-03.jpg', '/content/gsv70k/01/01. 61 JLN SETIA 2018-01.jpg', '/content/gsv70k/01/01. 18 LI PO AVE 2019-08.jpg', '/content/gsv70k/01/01. 48 WEST COAST LN 2022-05.jpg', '/content/gsv70k/01/01. 9A JLN HJ SALAM 2022-09.jpg', '/content/gsv70k/01/01. 6 COLCHESTER GR 2022-03.jpg', '/content/gsv70k/01/01. 441 PUNGGOL RD 2022-08.jpg', '/content/gsv70k/01/01. 7 HAPPY AVE CENTRAL 2022-03.jpg', '/content/gsv70k/01/01. 255 MACPHERSON RD 2020-10.jpg', '/content/gsv70k/01/01. 161 HILLCREST RD 2015-04.jpg', '/content/gsv70k/01/01. 393 GUILLEMARD RD 2020-02.jpg', '/content/gsv70k/01/01. 38 FABER TER 2022-02.jpg', '/content/gsv70k/01/01. 697 UP CHANGI RD EAST 2022-10.jpg', '/content/gsv70k/01/01. 8 JLN NOVENA SELATAN 2022-05.jpg', '/content/gsv70k/01/01. 2 MAYFLOWER PL 2021-06.jpg', '/content/gsv70k/01/01. 379 GUILLEMARD RD 2022-09.jpg', '/content/gsv70k/01/01. 60 GREENLEAF DR 2022-11.jpg', '/content/gsv70k/01/01. 2 NAMLY DR 2019-06.jpg', '/content/gsv70k/01/01. 15 JLN BINGKA 2008-12.jpg', '/content/gsv70k/01/01. 545 PASIR PANJANG RD 2021-11.jpg', '/content/gsv70k/01/01. 30 BIN TONG PK 2022-03.jpg', '/content/gsv70k/01/01. 41 SOMMERVILLE RD 2013-01.jpg', '/content/gsv70k/01/01. 92 GUILLEMARD RD 2022-09.jpg', '/content/gsv70k/01/01. 6 MERINO CRES 2022-02.jpg', '/content/gsv70k/01/01. 45 ONAN RD 2022-10.jpg', '/content/gsv70k/01/01. 399A GUILLEMARD RD 2018-04.jpg', '/content/gsv70k/01/01. 8 HOLLAND GR TER 2022-09.jpg', '/content/gsv70k/01/01. 5 HOW SUN RD 2022-03.jpg', '/content/gsv70k/01/01. 4D DYSON RD 2023-04.jpg', '/content/gsv70k/01/01. 257A BT TIMAH RD 2023-04.jpg', '/content/gsv70k/01/01. 87 JLN GELENGGANG 2022-08.jpg', '/content/gsv70k/01/01. 4 LAKME ST 2022-09.jpg', '/content/gsv70k/01/01. 8 NORFOLK RD 2023-01.jpg', '/content/gsv70k/01/01. 10 LINDEN DR 2023-03.jpg', '/content/gsv70k/01/01. 671 EAST COAST RD 2023-01.jpg', '/content/gsv70k/01/01. 103 JLN PARI BURONG 2022-09.jpg', '/content/gsv70k/01/01. 22 JLN KETUMBIT 2022-09.jpg', '/content/gsv70k/01/01. 33 JLN LEPAS 2022-09.jpg', '/content/gsv70k/01/01. 82 JLN PARI BURONG 2022-09.jpg', '/content/gsv70k/01/01. 13A EDEN GR 2021-11.jpg', '/content/gsv70k/01/01. 3 CHIAP GUAN AVE 2022-04.jpg', '/content/gsv70k/01/01. 75 JLN ASAS 2022-11.jpg', '/content/gsv70k/01/01. 2 JLN SHAER 2022-05.jpg', '/content/gsv70k/01/01. 60 CARDIFF GR 2022-03.jpg', '/content/gsv70k/01/01. 77 JLN ASAS 2020-09.jpg']\n"
          ]
        }
      ],
      "source": [
        "def file2img(img_files):\n",
        "    imgs=[]\n",
        "    for img_file in img_files:\n",
        "        image = Image.open(img_file).convert(\"RGB\")\n",
        "        image=transforms.ToTensor()(image)\n",
        "        imgs.append(image)\n",
        "    return imgs\n",
        "\n",
        "\n",
        "# imshow(torchvision.utils.make_grid(file2img(good[c:c+64])))\n",
        "\n",
        "imshow(torchvision.utils.make_grid(great[c:c+64]))\n",
        "# imshow(torchvision.utils.make_grid(file2img(great[c:c+64])))\n",
        "# imshow(torchvision.utils.make_grid(file2img(good[c:c+64])))\n",
        "# imshow(torchvision.utils.make_grid(file2img(interior)))\n",
        "# imshow(torchvision.utils.make_grid(file2img(word[c:c+64])))\n",
        "# # imshow(torchvision.utils.make_grid(file2img(left[c:c+100]),nrow=10))\n",
        "# imshow(torchvision.utils.make_grid(file2img(left[c:c+64])))\n",
        "\n",
        "\n",
        "print(obscured[c:c+64])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WhiFg75l4Ax"
      },
      "outputs": [],
      "source": [
        "for i,x in enumerate(left_s):\n",
        "    print(i, x.item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = pd.read_excel(\"/content/drive/MyDrive/final_urls.xlsx\", engine='openpyxl')\n"
      ],
      "metadata": {
        "id": "g7c1R9HiEbBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_lst = df_final.iloc[:,0].tolist()\n",
        "print(len(url_lst))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2T3WYm3EdfE",
        "outputId": "c481f9b3-0404-4350-98fc-4ab9014a9d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title download func\n",
        "import io\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "def download(uuu, name):\n",
        "    for _ in range(3):\n",
        "        try:\n",
        "            response = requests.get(uuu, stream=True, timeout=5)\n",
        "            image = Image.open(response.raw).convert('RGB')\n",
        "            # image = preprocess(image)\n",
        "            # width, height = im.size\n",
        "            # print(width, height)\n",
        "            im = image.resize((640, 400))\n",
        "            # im = im.convert('RGB')\n",
        "            im.save(\"/content/house/\"+str(name)+\".jpg\")\n",
        "            return uuu, image\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "    print(\"fail\", uuu)\n",
        "    return\n",
        "\n"
      ],
      "metadata": {
        "id": "F8nt3ujeONV7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uuu=url_lst[0]\n",
        "download(uuu,0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omMi4w-vPSPI",
        "outputId": "efb29654-17c5-4a1f-fc9c-6c94c06d3654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('https://media.istockphoto.com/id/178365226/tr/foto%C4%9Fraf/semi-detached-red-brick-houses.jpg?s=612x612&w=0&k=20&c=Ed-9msmO2U6yXoYDX8AmETotb3A6qMlImtsul-0vozM=',\n",
              " <PIL.Image.Image image mode=RGB size=612x406 at 0x7ABF77AA51E0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title download all\n",
        "\n",
        "batch_size = 1024 # 16\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "for i in range(0, len(url_lst), batch_size):\n",
        "    print(i,\"###########\")\n",
        "    start = time.time()\n",
        "    e = ThreadPoolExecutor(min(batch_size, len(url_lst))) #\n",
        "\n",
        "    future = [e.submit(download, uuu, i+name) for name, uuu in enumerate(url_lst[i: min(i+batch_size, len(url_lst))])]\n",
        "    result = [f.result() for f in future if f.result() is not None]\n",
        "\n",
        "    # if i>=1: break\n",
        "    end = time.time()\n",
        "    print(end-start)\n",
        "    start=end\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FAQoMFUCFBBt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls -a /content/house\n",
        "# !ls\n",
        "\n",
        "!rm -R /content/house/.ipynb_checkpoints\n",
        "\n",
        "!zip -r /content/drive/MyDrive/house.zip /content/house\n"
      ],
      "metadata": {
        "id": "3IJ6h2whkKpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir(\"/content/house\")))"
      ],
      "metadata": {
        "id": "1o_7o8Q-mzyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c466e9-49b6-4b3d-bd8f-f5ca0c5f0a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title make new folders\n",
        "import os\n",
        "for x in range(1,7):\n",
        "    fol = '/content/house/0'+str(x)\n",
        "    if not os.path.exists(fol):\n",
        "        os.makedirs(fol)"
      ],
      "metadata": {
        "id": "DL7t6SGS_Vta",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title resize imgs\n",
        "# from clip cleaner https://colab.research.google.com/drive/1AIe81Erx9kai4zmwR_59jcuRRZu6XQAl#scrollTo=y4EJBjkWq3yn\n",
        "# gmap: 1024,648 ; api: 640, 400\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "c=0\n",
        "for x in range(1,7):\n",
        "    fol = '/content/gmap/0'+str(x)\n",
        "    gfol = '/content/ggmap/0'+str(x)\n",
        "    files=os.listdir(fol)\n",
        "    for file in files:\n",
        "        # print(file)\n",
        "        im = Image.open(fol+'/'+file)\n",
        "        width, height = im.size\n",
        "        # print(width, height)\n",
        "        im = im.resize((640, 400))\n",
        "        im = im.convert('RGB')\n",
        "        im.save(gfol+'/'+file)\n",
        "        # print(fol+'/'+file)\n",
        "        # print(gfol+'/'+file)\n",
        "        # c+=1\n",
        "        # if c>5: break\n"
      ],
      "metadata": {
        "id": "ZALozrR7AKvI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4EJBjkWq3yn",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title move files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# allfiles = os.listdir(source)\n",
        "# for f in allfiles:\n",
        "#     src_path = os.path.join(source, f)\n",
        "#     dst_path = os.path.join(destination, f)\n",
        "#     shutil.copyfile(src_path, dst_path)\n",
        "\n",
        "\n",
        "c=0\n",
        "source = '/content/gmap_clean/'\n",
        "destination = '/content/gsv70k_clip/'\n",
        "for x in range(1,7):\n",
        "    allfiles = os.listdir(source+'0'+str(x))\n",
        "    # # for src_path in good:\n",
        "    for f in allfiles:\n",
        "        # f=src_path.split('/')[-1]\n",
        "\n",
        "        src_path = source+f[:2]+'/' +f\n",
        "        dst_path = destination+f[:2]+'/' +f\n",
        "        # print(src_path, dst_path)\n",
        "        shutil.copyfile(src_path, dst_path)\n",
        "        # c+=1\n",
        "        # if c>5: break\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wEQk_AKKXLth",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "cellView": "form",
        "outputId": "b7ad366c-ad21-486c-e4df-a204841c4b32"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1cec2f106bb3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for img_file, blurrness in zip(img_file_list, blurrness_list):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# if x in [34,40,62]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#     continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'url_lst' is not defined"
          ]
        }
      ],
      "source": [
        "# @title house main\n",
        "\n",
        "\n",
        "\n",
        "# for img_file, blurrness in zip(img_file_list, blurrness_list):\n",
        "for x,filename in enumerate(url_lst):\n",
        "    # if x in [34,40,62]:\n",
        "    #     continue\n",
        "    print(x)\n",
        "\n",
        "    try:\n",
        "        i = df_all.index[df_all['Filename'] == filename][0]\n",
        "    except: i = df_all.index[df_all['Filename'] == filename.replace('-','/').replace('_','/')][0]\n",
        "    # print(i)\n",
        "    # df_all.at[i, 'glat'] = olat\n",
        "    # df_all.at[i, 'glng'] = olng\n",
        "    df_all.at[i, 'gdate'] = date\n",
        "    df_all.at[i, 'name'] = filename\n",
        "    # print(loc)\n",
        "\n",
        "    cls=filename.split('. ')[0]\n",
        "    filename=filename.replace(\"/\", \"-\")\n",
        "\n",
        "    pic_dir = file_dir+'/'+cls+'/'+filename + ' ' + date + '.jpg'\n",
        "\n",
        "    with open(pic_dir, 'wb') as pic_file:\n",
        "        pic_file.write(pic_content)\n",
        "    # image = Image.open(pic_dir).convert(\"RGB\")\n",
        "    # plt.figure(figsize=(5, 4))\n",
        "    # plt.axis('off')\n",
        "    # plt.imshow(image)\n",
        "    # plt.show()\n",
        "\n",
        "    # t+=1\n",
        "    # if t >=5: break\n",
        "\n",
        "df_all.to_excel('/content/drive/MyDrive/properties_batch.xlsx', index=False, header=False)\n",
        "\n",
        "# No Street View imagery available here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g9OsdK83act"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.mkdir(\"/content/ggmap_frombad\")\n",
        "# for x in range(1,7):\n",
        "#     os.mkdir(\"/content/ggmap_frombad/0\"+str(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hCz6smbtcVMk"
      },
      "outputs": [],
      "source": [
        "# @title trash\n",
        "\n",
        "# def vfilter(sall):\n",
        "#     length=6\n",
        "#     aidx = torch.arange(len(sall))\n",
        "#     # torch.where(sall[2]>=0.26,aidx)\n",
        "#     # interior = aidx[a[:, 0] - a[:, 1] > 300]\n",
        "#     # interior = aidx[a[:, 2] >= 0.26]\n",
        "#     intf = torch.tensor([sall[:, 2] >= 0.26])\n",
        "#     print(intf.shape, intf)\n",
        "#     interior, sall = aidx[intf], sall[~intf,:]\n",
        "#     texf = torch.tensor([aidx[:, 3] >= 0.20])\n",
        "#     word, aidx = aidx[texf], aidx[~texf]\n",
        "#     colf = torch.tensor([aidx[:, 4] >= 0.21])\n",
        "#     collage, aidx = aidx[colf], aidx[~colf]\n",
        "#     walf = torch.tensor([aidx[:, 5] >= 0.21])\n",
        "#     wall, aidx = aidx[walf], aidx[~walf]\n",
        "#     houf = torch.tensor([aidx[:, 1] >= 0.23 | (length-2)*aidx[:, 1] - aidx[:,2:].sum() < 0.01])\n",
        "#     left, aidx = aidx[houf], aidx[~houf]\n",
        "#     modf = torch.tensor([aidx[:, 0] >= 0.27])\n",
        "#     great, good = aidx[modf], aidx[~modf]\n",
        "#     return great, good, interior, word, collage, wall, left\n",
        "\n",
        "# # print(sall.shape)\n",
        "# great, good, interior, word, collage, wall, left = vfilter(sall)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}